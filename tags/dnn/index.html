<h1>This is taxonomy template!</h1><div class=res-cons><h3 class=archive-title>包含标签
<span class=keyword>DNN</span></h3><article class=post><header><h1 class=post-title><a href=https://blog.villsi.net/post/2023/efficientdnns/ target=_blank>EfficientDNNs</a></h1></header><div class="d-block small"><div class="d-inline pe-3"><i class="bi bi-calendar3 pe-2"></i><time>2023-08-03</time></div><div class="d-inline pe-3"><i class="bi bi-book pe-1"></i>
<span>6420 字</span></div><div class=d-inline><i class="bi bi-alarm pe-1"></i>
<span>31 分钟</span></div></div><div class="d-none d-xl-block small"><div class="d-md-inline ps-2"><i class="bi bi-hash"></i>
<span>Deep Learning</span></div><div class="d-md-inline ps-2"><i class="bi bi-hash"></i>
<span>DNN</span></div></div><div class=post-content>A collection of recent methods on DNN compression and acceleration. There are mainly 5 kinds of methods for efficient DNNs:
neural architecture re-design or search (NAS) maintain accuracy, less cost (e.g., #Params, #FLOPs, etc.): MobileNet, ShuffleNet etc. maintain cost, more accuracy: Inception, ResNeXt, Xception etc. pruning (including structured and unstructured) quantization matrix/low-rank decomposition knowledge distillation (KD) Note, this repo is more about pruning (with lottery ticket hypothesis or LTH as a sub-topic), KD, and quantization.……<p class=readmore><a href=https://blog.villsi.net/post/2023/efficientdnns/ target=_blank></a></p></div></article></div>