<!doctype html><html lang=zh><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.121.2"><link rel=preconnect href=https://cdn.jsdelivr.net><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css2?display=swap&family=Inter:wght@300;400;500&family=Noto+Sans+SC:wght@300;400;500&family=Noto+Sans+JP:wght@300;400;500&family=Fira+Code:wght@300;400;500"><title>Learn Data Science - 03 Histograms | 上海红茶馆</title>
<meta name=author content="我喜欢煎蛋卷"><meta name=description content="This Repository Consists of Free Resources needed for a person to learn Data Science from the beginning to end. This repository is divided into four main Parts. And This post contains histograms."><meta name=keywords content="Github,Programming"><link rel=icon href=https://img.villsi.net/2023/12/efabaf2039214b5692c50465a865f8c1.webp sizes=any><link rel=icon sizes=192x192 href=https://img.villsi.net/2023/12/efabaf2039214b5692c50465a865f8c1.webp><link rel=icon sizes=512x512 href=https://img.villsi.net/2023/12/efabaf2039214b5692c50465a865f8c1.webp><link rel=apple-touch-icon sizes=180x180 href=https://img.villsi.net/2023/12/efabaf2039214b5692c50465a865f8c1.webp><meta property="og:title" content="Learn Data Science - 03 Histograms | 上海红茶馆"><meta name=twitter:title content="Learn Data Science - 03 Histograms | 上海红茶馆"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.villsi.net/post/2023/learn-data-science-for-free_03/"><meta property="og:description" content="This Repository Consists of Free Resources needed for a person to learn Data Science from the beginning to end. This repository is divided into four main Parts. And This post contains histograms."><meta name=twitter:description content="This Repository Consists of Free Resources needed for a person to learn Data Science from the beginning to end. This repository is divided into four main Parts. And This post contains histograms."><meta property="og:image" content="https://img.villsi.net/2023/12/fd029546dac00eb0a7db2781444cb6c2.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://img.villsi.net/2023/12/fd029546dac00eb0a7db2781444cb6c2.jpg"><meta property="article:published_time" content="2023-12-03T19:00:00+08:00"><meta property="article:modified_time" content="2023-12-08T02:18:45+08:00"><link rel=alternate type=application/atom+xml href=https://blog.villsi.net/index.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha2/dist/css/bootstrap.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.0/font/bootstrap-icons.css><link rel=stylesheet href=https://blog.villsi.net/assets/main.min.css><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/twemoji@14.0.2/dist/twemoji.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/quicklink@2.3.0/dist/quicklink.umd.js></script><script defer src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha2/dist/js/bootstrap.bundle.min.js></script><script defer src=https://blog.villsi.net/assets/main.min.js></script></head><body data-theme=auto data-section=single><header class="header shadow-sm"><nav class="navbar container"><div class=navbar__brand><a class="link-underline link-underline-opacity-0 navbar__item" href=https://blog.villsi.net><h1>上海红茶馆</h1></a></div><div class=navbar__menu><div class=navbar__start><a class="link-underline link-underline-opacity-0 navbar__item navbar__item--active" href=https://blog.villsi.net/post/>文章</a><a class="link-underline link-underline-opacity-0 navbar__item" href=https://blog.villsi.net/tagcloud/>标签</a><a class="link-underline link-underline-opacity-0 navbar__item" href=https://blog.villsi.net/code/>笔记</a><a class="link-underline link-underline-opacity-0 navbar__item" href=https://blog.villsi.net/friends/>友链</a><a class="link-underline link-underline-opacity-0 navbar__item" href=https://blog.villsi.net/echart/>关于</a><a class="link-underline link-underline-opacity-0 navbar__item" href=https://blog.villsi.net/playlist/>番剧</a></div><div class="navbar__end d-none d-lg-block"><div class=navbar__hitokoto><div id=hitokoto><a href=# id=hitokoto_text>:D 获取中...</a></div><script src="https://v1.hitokoto.cn/?encode=js&select=%23hitokoto" defer></script></div></div></nav></header><main class=main><div class=container><div class="row g-3"><div class=col-lg-9><div class=content><div class=header-image><div class="post__image ratio ratio-21x9"><div class=image-overlay></div><a href=https://blog.villsi.net/post/2023/learn-data-science-for-free_03/><img class="img-fluid mx-auto d-block" loading=lazy src=https://picsum.photos/seed/Learn%20Data%20Science%20-%2003%20Histograms/1600/1200 alt=博客文章头图></a></div><div class="post__title text-truncate"><h1>Learn Data Science - 03 Histograms</h1><div class="single-meta flex-layout"><div class="justify-content-between meta"><div class=meta__left><span class=meta__catrgory><i class="bi bi-text-left"></i>
<span>Uncategorized</span>
</span><span class=meta__date><i class="bi bi-calendar3"></i>
<span><time>2023-12-03</time></span>
</span><span class="meta__words d-none d-sm-inline"><i class="bi bi-book"></i>
<span>3452 字</span>
</span><span class="meta__minutes d-none d-md-inline"><i class="bi bi-alarm"></i>
<span>17 分钟</span></span></div><div class="meta__right d-none d-xl-block"><span class=meta__tags><i class="bi bi-hash"></i>
<span>Github</span>
<i class="bi bi-hash"></i>
<span>Programming</span></span></div></div></div></div></div><div class="card post"><div class=post__content><article class="card-body markdown"><p>Histograms are representation of distribution of numerical data. The procedure consists of binnng the numeric values using range divisions i.e, the entire range in which the data varies is split into several fixed intervals. Count or frequency of occurences of the numbers in the range of the bins are represented.</p><p><a href=https://en.wikipedia.org/wiki/Histogram target=_blank rel=noopener>Histograms</a></p><p><a href=/42204a3db084da60bc6344d3a0038295_13288078981977813325.png target=view_window><picture><source type=image/webp srcset=/42204a3db084da60bc6344d3a0038295_13288078981977813325.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/42204a3db084da60bc6344d3a0038295_13288078981977813325.png alt=plot loading=lazy></picture></a></p><p>In python, <strong>Pandas</strong>,<strong>Matplotlib</strong>,_<em>Seaborn</em> can be used to create Histograms.</p><h2 id=5-percentiles--outliers>5 Percentiles & outliers</h2><h3 id=percentiles>Percentiles</h3><p>Percentiles are numberical measures in statistics, which represents how much or what percentage of data falls below a given number or instance in a numerical data distribution.</p><p>For instance, if we say 70 percentile, it represents, 70% of the data in the ditribution are below the given numerical value.</p><p><a href=https://en.wikipedia.org/wiki/Percentile target=_blank rel=noopener>Percentiles</a></p><h3 id=outliers>Outliers</h3><p>Outliers are data points(numerical) which have significant differences with other data points. They differ from majority of points in the distribution. Such points may cause the central measures of distribution, like mean, and median. So, they need to be detected and removed.</p><p><a href=https://www.itl.nist.gov/div898/handbook/prc/section1/prc16.htm target=_blank rel=noopener>Outliers</a></p><p>_<em>Box Plots</em> can be used detect Outliers in the data. They can be created using _<em>Seaborn</em> library</p><p><a href=/1*105IeKBRGtyPyMy3-WQ8hw_12404978207580839276.png target=view_window><picture><source type=image/webp srcset=/1*105IeKBRGtyPyMy3-WQ8hw_12404978207580839276.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/1*105IeKBRGtyPyMy3-WQ8hw_12404978207580839276.png alt=Image_Box_Plot loading=lazy></picture></a></p><h2 id=6-probability-theory>6 Probability theory</h2><p>_<em>Probability</em> is the likelihood of an event in a Random experiment. For instance, if a coin is tossed, the chance of getting a head is 50% so, probability is 0.5.</p><p><strong>Sample Space</strong>: It is the set of all possible outcomes of a Random Experiment.
<strong>Favourable Outcomes</strong>: The set of outcomes we are looking for in a Random Experiment</p><p><strong>Probability = (Number of Favourable Outcomes) / (Sample Space)</strong></p><p>_<em>Probability theory</em> is a branch of mathematics that is associated with the concept of probability.</p><p><a href=https://towardsdatascience.com/basic-probability-theory-and-statistics-3105ab637213 target=_blank rel=noopener>Basics of Probability</a></p><h2 id=7-bayes-theorem>7 Bayes theorem</h2><h3 id=conditional-probability>Conditional Probability:</h3><p>It is the probability of one event occurring, given that another event has already occurred. So, it gives a sense of relationship between two events and the probabilities of the occurences of those events.</p><p>It is given by:</p><p>_<em>P( A | B )</em> : Probability of occurence of A, after B occured.</p><p>The formula is given by:</p><p><a href=/05329239efcccd443b435cbc486136d1_10452115304807142808.svg target=view_window><picture><source type=image/webp srcset=/05329239efcccd443b435cbc486136d1_10452115304807142808.svg><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/05329239efcccd443b435cbc486136d1_10452115304807142808.svg alt=formula loading=lazy></picture></a></p><p>So, P(A|B) is equal to Probablity of occurence of A and B, divided by Probability of occurence of B.</p><p><a href=https://en.wikipedia.org/wiki/Conditional_probability target=_blank rel=noopener>Guide to Conditional Probability</a></p><h3 id=bayes-theorem>Bayes Theorem</h3><p>Bayes theorem provides a way to calculate conditional probability. Bayes theorem is widely used in machine learning most in Bayesian Classifiers.</p><p>According to Bayes theorem the probability of A, given that B has already occurred is given by Probability of A multiplied by the probability of B given A has already occurred divided by the probability of B.</p><p><strong>P(A|B) = P(A).P(B|A) / P(B)</strong></p><p><a href=https://machinelearningmastery.com/bayes-theorem-for-machine-learning/ target=_blank rel=noopener>Guide to Bayes Theorem</a></p><h2 id=8-random-variables>8 Random variables</h2><p>Random variable are the numeric outcome of an experiment or random events. They are normally a set of values.</p><p>There are two main types of Random Variables:</p><p><strong>Discrete Random Variables</strong>: Such variables take only a finite number of distinct values</p><p><strong>Continous Random Variables</strong>: Such variables can take an infinite number of possible values.</p><h2 id=9-cumul-dist-fn-cdf>9 Cumul Dist Fn (CDF)</h2><p>In probability theory and statistics, the cumulative distribution function (CDF) of a real-valued random variable <strong>X</strong>, or just distribution function of <strong>X</strong>, evaluated at <strong>x</strong>, is the probability that _<em>X</em> will take a value less than or equal to <strong>x</strong>.</p><p>The cumulative distribution function of a real-valued random variable X is the function given by:</p><p><a href=/4df8aa927f199ea9d16695d46d4715dd_260284376908556703.svg target=view_window><picture><source type=image/webp srcset=/4df8aa927f199ea9d16695d46d4715dd_260284376908556703.svg><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/4df8aa927f199ea9d16695d46d4715dd_260284376908556703.svg alt=CDF loading=lazy></picture></a></p><p>Resource:</p><p><a href=https://en.wikipedia.org/wiki/Cumulative_distribution_function target=_blank rel=noopener>Wikipedia</a></p><h2 id=10-continuous-distributions>10 Continuous distributions</h2><p>A continuous distribution describes the probabilities of the possible values of a continuous random variable. A continuous random variable is a random variable with a set of possible values (known as the range) that is infinite and uncountable.</p><h2 id=11-skewness>11 Skewness</h2><p>Skewness is the measure of assymetry in the data distribution or a random variable distribution about its mean.</p><p>Skewness can be positive, negative or zero.</p><p><a href=/0600ac289e345da1ef01e8c6c741ef19_17226038366885081276.png target=view_window><picture><source type=image/webp srcset=/0600ac289e345da1ef01e8c6c741ef19_17226038366885081276.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/0600ac289e345da1ef01e8c6c741ef19_17226038366885081276.png alt="skewed image" loading=lazy></picture></a></p><p><strong>Negative skew</strong>: Distribution Concentrated in the right, left tail is longer.</p><p><strong>Positive skew</strong>: Distribution Concentrated in the left, right tail is longer.</p><p>Variation of central tendency measures are shown below.</p><p><a href=/fe53927be3978f7b81f2a14d348f9b69_4875863126982964344.png target=view_window><picture><source type=image/webp srcset=/fe53927be3978f7b81f2a14d348f9b69_4875863126982964344.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/fe53927be3978f7b81f2a14d348f9b69_4875863126982964344.png alt=cet loading=lazy></picture></a></p><p>Data Distribution are often Skewed which may cause trouble during processing the data. <strong>Skewed Distribution can be converted to Symmetric Distribution, taking Log of the distribution</strong>.</p><h5 id=skew-distribution>Skew Distribution</h5><p><a href=/36c34023dd6502d7306d44e464e57ba4_13699025648013721237.png target=view_window><picture><source type=image/webp srcset=/36c34023dd6502d7306d44e464e57ba4_13699025648013721237.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/36c34023dd6502d7306d44e464e57ba4_13699025648013721237.png alt=Skew loading=lazy></picture></a></p><h5 id=log-of-the-skew-distribution>Log of the Skew Distribution.</h5><p><a href=https:/img.villsi.net/2023/12/04d8dec17cc662a83ba6a64852932ba8.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/04d8dec17cc662a83ba6a64852932ba8.png alt=log loading=lazy></a></p><p><a href=https://en.wikipedia.org/wiki/Skewness target=_blank rel=noopener>Guide to Skewness</a></p><h2 id=12-anova>12 ANOVA</h2><p>ANOVA stands for <strong>analysis of variance</strong>.</p><p>It is used to compare among groups of data distributions.</p><p>Often we are provided with huge data. They are too huge to work with. The total data is called the <strong>Population</strong>.</p><p>In order to work with them, we pick random smaller groups of data. They are called <strong>Samples</strong>.</p><p>ANOVA is used to compare the variance among these groups or samples.</p><p>Variance of group is given by:</p><p><a href=https:/img.villsi.net/2023/12/298ae4a51add29296a0a610f6d2e5ecf.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/298ae4a51add29296a0a610f6d2e5ecf.png alt=var loading=lazy></a></p><p>The differences in the collected samples are observed using the differences between the means of the groups. We often use the _<em>t-test</em> to compare the means and also to check if the samples belong to the same population,</p><p>Now, t-test can only be possible among two groups. But, often we get more groups or samples.</p><p>If we try to use t-test for more than two groups we have to perform t-tests multiple times, once for each pair. This is where ANOVA is used.</p><p>ANOVA has two components:</p><p><strong>1.Variation within each group</strong></p><p><strong>2.Variation between groups</strong></p><p>It works on a ratio called the <strong>F-Ratio</strong></p><p>It is given by:</p><p><a href=https:/img.villsi.net/2023/12/973382ff4dea0e412ade24c34019fe50.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/973382ff4dea0e412ade24c34019fe50.png alt=F-ratio loading=lazy></a></p><p>F ratio shows how much of the total variation comes from the variation between groups and how much comes from the variation within groups. If much of the variation comes from the variation between groups, it is more likely that the mean of groups are different. However, if most of the variation comes from the variation within groups, then we can conclude the elements in a group are different rather than entire groups. The larger the F ratio, the more likely that the groups have different means.</p><p>Resources:</p><p><a href=https://statistics.laerd.com/statistical-guides/one-way-anova-statistical-guide.php target=_blank rel=noopener>Defnition</a></p><p><a href=https://towardsdatascience.com/anova-analysis-of-variance-explained-b48fee6380af target=_blank rel=noopener>GUIDE 1</a></p><p><a href=https://medium.com/@StepUpAnalytics/anova-one-way-vs-two-way-6b3ff87d3a94 target=_blank rel=noopener>Details</a></p><h2 id=13-prob-den-fn-pdf>13 Prob Den Fn (PDF)</h2><p>It stands for probability density function.</p><p><strong>In probability theory, a probability density function (PDF), or density of a continuous random variable, is a function whose value at any given sample (or point) in the sample space (the set of possible values taken by the random variable) can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample.</strong></p><p>The probability density function (PDF) P(x) of a continuous distribution is defined as the derivative of the (cumulative) distribution function D(x).</p><p>It is given by the integral of the function over a given range.</p><p><a href=https://img.villsi.net/2023/12/0fceca13c8036a5e6d16bc2d59f02627. target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https://img.villsi.net/2023/12/0fceca13c8036a5e6d16bc2d59f02627. alt=PDF loading=lazy></a></p><h2 id=14-central-limit-theorem>14 Central Limit theorem</h2><h2 id=15-monte-carlo-method>15 Monte Carlo method</h2><h2 id=16-hypothesis-testing>16 Hypothesis Testing</h2><h3 id=types-of-curves>Types of curves</h3><p>We need to know about two distribution curves first.</p><p>Distribution curves reflect the probabilty of finding an instance or a sample of a population at a certain value of the distribution.</p><p><strong>Normal Distribution</strong></p><p><a href=/3f69f968f47069d76037364fa94459d6_10888796824915308044.jpg target=view_window><picture><source type=image/webp srcset=/3f69f968f47069d76037364fa94459d6_10888796824915308044.jpg><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/3f69f968f47069d76037364fa94459d6_10888796824915308044.jpg alt="normal distribution" loading=lazy></picture></a></p><p>The normal distribution represents how the data is distributed. In this case, most of the data samples in the distribution are scattered at and around the mean of the distribution. A few instances are scattered or present at the long tail ends of the distribution.</p><p>Few points about Normal Distributions are:</p><ol><li><p>The curve is always Bell-shaped. This is because most of the data is found around the mean, so the proababilty of finding a sample at the mean or central value is more.</p></li><li><p>The curve is symmetric</p></li><li><p>The area under the curve is always 1. This is because all the points of the distribution must be present under the curve</p></li><li><p>For Normal Distribution, Mean and Median lie on the same line in the distribution.</p></li></ol><p><strong>Standard Normal Distribution</strong></p><p>This type of distribution are normal distributions which following conditions.</p><ol><li><p>Mean of the distribution is 0</p></li><li><p>The Standard Deviation of the distribution is equal to 1.</p></li></ol><p>The idea of Hypothesis Testing works completely on the data distributions.</p><h3 id=hypothesis-testing>Hypothesis Testing</h3><p>Hypothesis testing is a statistical method that is used in making statistical decisions using experimental data. Hypothesis Testing is basically an assumption that we make about the population parameter.</p><p>For example, say, we take the hypothesis that boys in a class are taller than girls.</p><p>The above statement is just an assumption on the population of the class.</p><p>_<em>Hypothesis</em> is just an assumptive proposal or statement made on the basis of observations made on a set of information or data.</p><p>We initially propose two mutually exclusive statements based on the population of the sample data.</p><p>The initial one is called <strong>NULL HYPOTHESIS</strong>. It is denoted by H0.</p><p>The second one is called <strong>ALTERNATE HYPOTHESIS</strong>. It is denoted by H1 or Ha. It is used as a contrary to Null Hypothesis.</p><p>Based on the instances of the population we accept or reject the NULL Hypothesis and correspondingly we reject or accept the ALTERNATE Hypothesis.</p><h4 id=level-of-significance>Level of Significance</h4><p>It is the degree which we consider to decide whether to accept or reject the NULL hypothesis. When we consider a hypothesis on a population, it is not the case that 100% or all instances of the population abides the assumption, so we decide a <strong>level of significance as a cutoff degree, i.e, if our level of significance is 5%, and (100-5)% = 95% of the data abides by the assumption, we accept the Hypothesis.</strong></p><p><strong>It is said with 95% confidence, the hypothesis is accepted</strong></p><p><a href=https:/img.villsi.net/2023/12/c558077b5eac53e21303cfc4540528c5.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/c558077b5eac53e21303cfc4540528c5.png alt=curve loading=lazy></a></p><p>The non-reject region is called <strong>acceptance region or beta region</strong>. The rejection regions are called <strong>critical or alpha regions</strong>. _<em>alpha</em> denotes the <strong>level of significance</strong>.</p><p>If level of significance is 5%. the two alpha regions have (2.5+2.5)% of the population and the beta region has the 95%.</p><p>The acceptance and rejection gives rise to two kinds of errors:</p><p>_<em>Type-I Error:</em> NULL Hypothesis is true, but wrongly Rejected.</p><p>_<em>Type-II Error:</em> NULL Hypothesis if false but is wrongly accepted.</p><p><a href=/2e41da5381bfb50f23567f1233df64e6_13968004333280306151.jpg target=view_window><picture><source type=image/webp srcset=/2e41da5381bfb50f23567f1233df64e6_13968004333280306151.jpg><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/2e41da5381bfb50f23567f1233df64e6_13968004333280306151.jpg alt=hypothesis loading=lazy></picture></a></p><h3 id=tests-for-hypothesis>Tests for Hypothesis</h3><p><strong>One Tailed Test</strong>:</p><p><a href=/acc48a5819d289b41631952c3436d568_5471487243547306589.png target=view_window><picture><source type=image/webp srcset=/acc48a5819d289b41631952c3436d568_5471487243547306589.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/acc48a5819d289b41631952c3436d568_5471487243547306589.png alt=One-tailed loading=lazy></picture></a></p><p>This is a test for Hypothesis, where the rejection region is only one side of the sampling distribution. The rejection region may be in right tail end or in the left tail end.</p><p>The idea is if we say our level of significance is 5% and we consider a hypothesis &ldquo;Hieght of Boys in a class is &lt;=6 ft&rdquo;. We consider the hypothesis true if atmost 5% of our population are more than 6 feet. So, this will be one-tailed as the test condition only restricts one tail end, the end with hieght > 6ft.</p><p><a href=/4fb71d4289ea0273f6744cd403cfbedd_9672683831314229940.png target=view_window><picture><source type=image/webp srcset=/4fb71d4289ea0273f6744cd403cfbedd_9672683831314229940.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/4fb71d4289ea0273f6744cd403cfbedd_9672683831314229940.png alt="Two Tailed" loading=lazy></picture></a></p><p>In this case, the rejection region extends at both tail ends of the distribution.</p><p>The idea is if we say our level of significance is 5% and we consider a hypothesis &ldquo;Hieght of Boys in a class is !=6 ft&rdquo;.</p><p>Here, we can accept the NULL hyposthesis iff atmost 5% of the population is less than or greater than 6 feet. So, it is evident that the crirtical region will be at both tail ends and the region is 5% / 2 = 2.5% at both ends of the distribution.</p><h2 id=17-p-value>17 p-Value</h2><p>Before we jump into P-values we need to look at another important topic in the context: Z-test.</p><h3 id=z-test>Z-test</h3><p>We need to know two terms: <strong>Population and Sample.</strong></p><p>_<em>Population</em> describes the entire available data distributed. So, it refers to all records provided in the dataset.</p><p>_<em>Sample</em> is said to be a group of data points randomly picked from a population or a given distribution. The size of the sample can be any number of data points, given by <strong>sample size.</strong></p><p>_<em>Z-test</em> is simply used to determine if a given sample distribution belongs to a given population.</p><p>Now,for Z-test we have to use _<em>Standard Normal Form</em> for the standardized comparison measures.</p><p><a href=https:/img.villsi.net/2023/12/4a5c4ab18bbbe4c636e5a74f1ad36acc.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/4a5c4ab18bbbe4c636e5a74f1ad36acc.png alt=std1 loading=lazy></a></p><p>As we already have seen, standard normal form is a normal form with mean=0 and standard deviation=1.</p><p>The _<em>Standard Deviation</em> is a measure of how much differently the points are distributed around the mean.</p><p><a href=/f1a2d3148848fa00e63ec49a654b3191_11862406429175790586.png target=view_window><picture><source type=image/webp srcset=/f1a2d3148848fa00e63ec49a654b3191_11862406429175790586.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/f1a2d3148848fa00e63ec49a654b3191_11862406429175790586.png alt=std2 loading=lazy></picture></a></p><p>It states that approximately 68% , 95% and 99.7% of the data lies within 1, 2 and 3 standard deviations of a normal distribution respectively.</p><p>Now, to convert the normal distribution to standard normal distribution we need a standard score called Z-Score.
It is given by:</p><p><a href=https:/img.villsi.net/2023/12/4558e986726427f7fc5bc166802a0c9a.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/4558e986726427f7fc5bc166802a0c9a.png alt=Z-score loading=lazy></a></p><p>x = value that we want to standardize</p><p>µ = mean of the distribution of x</p><p>σ = standard deviation of the distribution of x</p><p>We need to know another concept <strong>Central Limit Theorem</strong>.</p><h5 id=central-limit-theorem>Central Limit Theorem</h5><p><em>The theorem states that the mean of the sampling distribution of the sample means is equal to the population mean irrespective if the distribution of population where sample size is greater than 30.</em></p><p>And</p><p><em>The sampling distribution of sampling mean will also follow the normal distribution.</em></p><p>So, it states, if we pick several samples from a distribution with the size above 30, and pick the static sample means and use the sample means to create a distribution, the mean of the newly created sampling distribution is equal to the original population mean.</p><p>According to the theorem, if we draw samples of size N, from a population with population mean μ and population standard deviation σ, the condition stands:</p><p><a href=https:/img.villsi.net/2023/12/a93c1b30dde00a90169a2128ec1fd1f0.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/a93c1b30dde00a90169a2128ec1fd1f0.png alt=std3 loading=lazy></a></p><p>i.e, mean of the distribution of sample means is equal to the sample means.</p><p>The standard deviation of the sample means is give by:</p><p><a href=/a5bc084adb8fa205384068cb8339f6dd_9188634228011174805.png target=view_window><picture><source type=image/webp srcset=/a5bc084adb8fa205384068cb8339f6dd_9188634228011174805.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/a5bc084adb8fa205384068cb8339f6dd_9188634228011174805.png alt=std4 loading=lazy></picture></a></p><p>The above term is also called standard error.</p><p>We use the theory discussed above for Z-test. If the sample mean lies close to the population mean, we say that the sample belongs to the population and if it lies at a distance from the population mean, we say the sample is taken from a different population.</p><p>To do this we use a formula and check if the z statistic is greater than or less than 1.96 (considering two tailed test, level of significance = 5%)</p><p><a href=https:/img.villsi.net/2023/12/f6335d6d9baad22dfd591fe7d5bccce1.gif target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/f6335d6d9baad22dfd591fe7d5bccce1.gif alt=los loading=lazy></a></p><p><a href=https:/img.villsi.net/2023/12/7f83827c1fa86fef461ef7516c78cdbb.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/7f83827c1fa86fef461ef7516c78cdbb.png alt=std5 loading=lazy></a></p><p>The above formula gives Z-static</p><p>z = z statistic</p><p>X̄ = sample mean</p><p>μ = population mean</p><p>σ = population standard deviation</p><p>n = sample size</p><p>Now, as the Z-score is used to standardize the distribution, it gives us an idea how the data is distributed overall.</p><h3 id=p-values>P-values</h3><p>It is used to check if the results are statistically significant based on the significance level.</p><p>Say, we perform an experiment and collect observations or data. Now, we make a hypothesis (NULL hypothesis) primary, and a second hypothesis, contradictory to the first one called the alternative hypothesis.</p><p>Then we decide a level of significance which serve as a threshold for our null hypothesis. The P value actually gives the probability of the statement. Say, the p-value of our alternative hypothesis is 0.02, it means the probability of alternate hypothesis happenning is 2%.</p><p>Now, the level of significance into play to decide if we can allow 2% or p-value of 0.02. It can be said as a level of endurance of the null hypothesis. If our level of significance is 5% using a two tailed test, we can allow 2.5% on both ends of the distribution, we accept the NULL hypothesis, as level of significance > p-value of alternate hypothesis.</p><p>But if the p-value is greater than level of significance, we tell that the result is _<em>statistically significant, and we reject NULL hypothesis.</em> .</p><p>Resources:</p><ol><li><p><a href=https://medium.com/analytics-vidhya/everything-you-should-know-about-p-value-from-scratch-for-data-science-f3c0bfa3c4cc target=_blank rel=noopener>https://medium.com/analytics-vidhya/everything-you-should-know-about-p-value-from-scratch-for-data-science-f3c0bfa3c4cc</a></p></li><li><p><a href=https://towardsdatascience.com/p-values-explained-by-data-scientist-f40a746cfc8 target=_blank rel=noopener>https://towardsdatascience.com/p-values-explained-by-data-scientist-f40a746cfc8</a></p></li><li><p><a href=https://medium.com/analytics-vidhya/z-test-demystified-f745c57c324c target=_blank rel=noopener>https://medium.com/analytics-vidhya/z-test-demystified-f745c57c324c</a></p></li></ol><h2 id=18-chi2-test>18 Chi2 test</h2><p>Chi2 test is extensively used in data science and machine learning problems for feature selection.</p><p>A chi-square test is used in statistics to test the independence of two events. So, it is used to check for independence of features used. Often dependent features are used which do not convey a lot of information but adds dimensionality to a feature space.</p><p>It is one of the most common ways to examine relationships between two or more categorical variables.</p><p>It involves calculating a number, called the chi-square statistic - χ2. Which follows a chi-square distribution.</p><p>It is given as the summation of the difference of the expected values and observed value divided by the observed value.</p><p><a href=https:/img.villsi.net/2023/12/1dfbfa846038e11a2c03c9df425ba76a.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/1dfbfa846038e11a2c03c9df425ba76a.png alt=Chi2 loading=lazy></a></p><p>Resources:</p><p><a href=investopedia.com/terms/c/chi-square-statistic.asp target=_blank rel=noopener>Definitions</a></p><p><a href=https://towardsdatascience.com/chi-square-test-for-feature-selection-in-machine-learning-206b1f0b8223 target=_blank rel=noopener>Guide 1</a></p><p><a href=https://medium.com/swlh/what-is-chi-square-test-how-does-it-work-3b7f22c03b01 target=_blank rel=noopener>Guide 2</a></p><p><a href=https://medium.com/@kuldeepnpatel/chi-square-test-of-independence-bafd14028250 target=_blank rel=noopener>Example of Operation</a></p><h2 id=19-estimation>19 Estimation</h2><h2 id=20-confid-int-ci>20 Confid Int (CI)</h2><h2 id=21-mle>21 MLE</h2><h2 id=22-kernel-density-estimate>22 Kernel Density estimate</h2><p>In statistics, kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable. Kernel density estimation is a fundamental data smoothing problem where inferences about the population are made, based on a finite data sample.</p><p>Kernel Density estimate can be regarded as another way to represent the probability distribution.</p><p><a href=/65f376edaeb8fc0f0bd06a5e7d5807a7_2987920426901486766.png target=view_window><picture><source type=image/webp srcset=/65f376edaeb8fc0f0bd06a5e7d5807a7_2987920426901486766.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/65f376edaeb8fc0f0bd06a5e7d5807a7_2987920426901486766.png alt=KDE1 loading=lazy></picture></a></p><p>It consists of choosing a kernel function. There are mostly three used.</p><ol><li><p>Gaussian</p></li><li><p>Box</p></li><li><p>Tri</p></li></ol><p>The kernel function depicts the probability of finding a data point. So, it is highest at the centre and decreases as we move away from the point.</p><p>We assign a kernel function over all the data points and finally calculate the density of the functions, to get the density estimate of the distibuted data points. It practically adds up the Kernel function values at a particular point on the axis. It is as shown below.</p><p><a href=/6a5b18d5c9fc797e12ca8cb181576060_3095007592463348520.png target=view_window><picture><source type=image/webp srcset=/6a5b18d5c9fc797e12ca8cb181576060_3095007592463348520.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/6a5b18d5c9fc797e12ca8cb181576060_3095007592463348520.png alt="KDE 2" loading=lazy></picture></a></p><p>Now, the kernel function is given by:</p><p><a href=https:/img.villsi.net/2023/12/5e74720f85201bb29b4427048110cb00.svg target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/5e74720f85201bb29b4427048110cb00.svg alt=kde3 loading=lazy></a></p><p>where K is the kernel — a non-negative function — and h > 0 is a smoothing parameter called the bandwidth.</p><p>The &lsquo;h&rsquo; or the bandwidth is the parameter, on which the curve varies.</p><p><a href=/0f0acb3b13b97171ba0c0e5743447cf4_8737646574549427179.png target=view_window><picture><source type=image/webp srcset=/0f0acb3b13b97171ba0c0e5743447cf4_8737646574549427179.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/0f0acb3b13b97171ba0c0e5743447cf4_8737646574549427179.png alt=kde4 loading=lazy></picture></a></p><p>Kernel density estimate (KDE) with different bandwidths of a random sample of 100 points from a standard normal distribution. Grey: true density (standard normal). Red: KDE with h=0.05. Black: KDE with h=0.337. Green: KDE with h=2.</p><p>Resources:</p><p><a href="https://www.youtube.com/watch?v=x5zLaWT5KPs" target=_blank rel=noopener>Basics</a></p><p><a href=https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html target=_blank rel=noopener>Advanced</a></p><h2 id=23-regression>23 Regression</h2><p>Regression tasks deal with predicting the value of a _<em>dependent variable</em> from a set of <strong>independent variables.</strong></p><p>Say, we want to predict the price of a car. So, it becomes a dependent variable say Y, and the features like engine capacity, top speed, class, and company become the independent variables, which helps to frame the equation to obtain the price.</p><p>If there is one feature say x. If the dependent variable y is linearly dependent on x, then it can be given by <strong>y=mx+c</strong>, where the m is the coefficient of the independent in the equation, c is the intercept or bias.</p><p>The image shows the types of regression</p><p><a href=/4bdec412db0b8776068882cb97e56512_1597835912003783166.png target=view_window><picture><source type=image/webp srcset=/4bdec412db0b8776068882cb97e56512_1597835912003783166.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/4bdec412db0b8776068882cb97e56512_1597835912003783166.png alt=types loading=lazy></picture></a></p><p><a href=https://towardsdatascience.com/a-deep-dive-into-the-concept-of-regression-fb912d427a2e target=_blank rel=noopener>Guide to Regression</a></p><h2 id=24-covariance>24 Covariance</h2><h3 id=variance>Variance</h3><p>The variance is a measure of how dispersed or spread out the set is. If it is said that the variance is zero, it means all the elements in the dataset are same. If the variance is low, it means the data are slightly dissimilar. If the variance is very high, it means the data in the dataset are largely dissimilar.</p><p>Mathematically, it is a measure of how far each value in the data set is from the mean.</p><p>Variance (sigma^2) is given by summation of the square of distances of each point from the mean, divided by the number of points</p><p><a href=https:/img.villsi.net/2023/12/8a714541eae7c13a4cd24fb78cee252b.png target=view_window><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=https:/img.villsi.net/2023/12/8a714541eae7c13a4cd24fb78cee252b.png alt="formula var" loading=lazy></a></p><h3 id=covariance>Covariance</h3><p>Covariance gives us an idea about the degree of association between two considered random variables. Now, we know random variables create distributions. Distribution are a set of values or data points which the variable takes and we can easily represent as vectors in the vector space.</p><p>For vectors covariance is defined as the dot product of two vectors. The value of covariance can vary from positive infinity to negative infinity. If the two distributions or vectors grow in the same direction the covariance is positive and vice versa. The Sign gives the direction of variation and the Magnitude gives the amount of variation.</p><p>Covariance is given by:</p><p><a href=/7b602f70712689c60cf78323086051ca_12541140265238362211.png target=view_window><picture><source type=image/webp srcset=/7b602f70712689c60cf78323086051ca_12541140265238362211.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/7b602f70712689c60cf78323086051ca_12541140265238362211.png alt=cov_form loading=lazy></picture></a></p><p>where Xi and Yi denotes the i-th point of the two distributions and X-bar and Y-bar represent the mean values of both the distributions, and n represents the number of values or data points in the distribution.</p><h2 id=25-correlation>25 Correlation</h2><p>Covariance measures the total relation of the variables namely both direction and magnitude. Correlation is a scaled measure of covariance. It is dimensionless and independent of scale. It just shows the strength of variation for both the variables.</p><p>Mathematically, if we represent the distribution using vectors, correlation is said to be the cosine angle between the vectors. The value of correlation varies from +1 to -1. +1 is said to be a strong positive correlation and -1 is said to be a strong negative correlation. 0 implies no correlation, or the two variables are independent of each other.</p><p>Correlation is given by:</p><p><a href=/31c48370bc9ef1e1b71390899192b7ee_10103895082969317728.png target=view_window><picture><source type=image/webp srcset=/31c48370bc9ef1e1b71390899192b7ee_10103895082969317728.png><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/31c48370bc9ef1e1b71390899192b7ee_10103895082969317728.png alt=corr loading=lazy></picture></a></p><p>Where:</p><p>ρ(X,Y) – the correlation between the variables X and Y</p><p>Cov(X,Y) – the covariance between the variables X and Y</p><p>σX – the standard deviation of the X-variable</p><p>σY – the standard deviation of the Y-variable</p><p>Standard deviation is given by square roo of variance.</p><h2 id=26-pearson-coeff>26 Pearson coeff</h2><h2 id=27-causation>27 Causation</h2><h2 id=28-least2-fit>28 Least2-fit</h2><h2 id=29-euclidian-distance>29 Euclidian Distance</h2><p><strong>Eucladian Distance is the most used and standard measure for the distance between two points.</strong></p><p>It is given as the square root of sum of squares of the difference between coordinates of two points.</p><p><strong>The Euclidean distance between two points in Euclidean space is a number, the length of a line segment between the two points. It can be calculated from the Cartesian coordinates of the points using the Pythagorean theorem, and is occasionally called the Pythagorean distance.</strong></p><p><em><em>In the Euclidean plane, let point p have Cartesian coordinates (p</em>{1},p</em>{2}) and let point q have coordinates (q_{1},q_{2}). Then the distance between p and q is given by:__</p><p><a href=/36994bf2494173c6378f37bd9dc630cb_9108279935865852018.svg target=view_window><picture><source type=image/webp srcset=/36994bf2494173c6378f37bd9dc630cb_9108279935865852018.svg><img class="img-fluid mx-auto d-block rounded shadow-sm data-zoomable" src=/36994bf2494173c6378f37bd9dc630cb_9108279935865852018.svg alt=eucladian loading=lazy></picture></a></p></article></div><div class="license markdown"><blockquote>本站内容采用 CC BY-NC-SA 4.0 许可，请注明出处；商业转载请联系作者授权。</blockquote></div></div><hr><div class="card comment-area"><script async crossorigin=anonymous src=https://giscus.app/client.js data-repo=villsi/villsi.github.io data-repo-id=R_kgDOKvi-KA data-category=评论 data-category-id=DIC_kwDOKvi-KM4CbUNT data-mapping=title data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy></script></div></div></div><div class=col-lg-3><aside class=sidebar_sticky><section><div class="card card-body mb-3 widget search"><div class=search__input><input type=text id=search-input></div><div class="search__ctrl btn btn-primary" id=search-btn title=搜索><i class="bi bi-search"></i></div></div></section><section><div class="card card-body mb-3 widget info"><div class=info__avatar><img class="img-fluid rounded mx-auto d-block" loading=lazy src=https://img.villsi.net/2023/12/fd029546dac00eb0a7db2781444cb6c2.jpg alt=头像></div><div class=info__meta><div class=info__metaName>我喜欢煎蛋卷</div><div class=info__metaWord>或许是不知梦的缘故，流离之人追逐幻影。</div></div><div class=info__counter><div class=info__counterItem><span class=info__counterData>308</span>
<span class=info__counterName>千字数</span></div><div class=info__counterItem><span class=info__counterData>36</span>
<span class=info__counterName>文章数</span></div><div class=info__counterItem><span class=info__counterData>15</span>
<span class=info__counterName>标签数</span></div></div></div></section><section class="d-none d-sm-block"><div class="card card-body mb-3 widget social"><a class=social__item href=https://github.com/villsi target=_blank rel=noopener title=GitHub><i class="bi bi-github"></i>
</a><a class=social__item href=https://twitter.com/villsi target=_blank rel=noopener title=Twitter><i class="bi bi-twitter"></i>
</a><a class=social__item href=https://steamcommunity.com/id/villsi/ target=_blank rel=noopener title=Steam><i class="bi bi-steam"></i></a></div></section><section class="d-none d-lg-block"><div class="card card-body mb-3 widget kofi"><a href=https://ko-fi.com/villsi target=_blank rel=noopener><img class="img-fluid rounded mx-auto d-block" loading=lazy src=https://img.villsi.net/2023/12/0046a7767d3b415ce9a93776641a6548.png alt=赞助图片></a></div></section><section class="d-none d-sm-block"><div class="card mb-3 categories"><div class=card-header><i class="bi bi-layers" aria-hidden=true></i>
<span class="text-uppercase fw-bold">Categories</span></div><div class=card-body><ul><li><a class="link-underline-primary link-offset-3 link-underline-opacity-0 link-underline-opacity-75-hover" href=https://blog.villsi.net/categories/blog/>Blog (1)</a></li><li><a class="link-underline-primary link-offset-3 link-underline-opacity-0 link-underline-opacity-75-hover" href=https://blog.villsi.net/categories/uncategorized/>Uncategorized (15)</a></li><li><a class="link-underline-primary link-offset-3 link-underline-opacity-0 link-underline-opacity-75-hover" href=https://blog.villsi.net/categories/%E5%8D%9A%E5%AE%A2%E8%A3%85%E4%BF%AE/>博客装修 (1)</a></li><li><a class="link-underline-primary link-offset-3 link-underline-opacity-0 link-underline-opacity-75-hover" href=https://blog.villsi.net/categories/%E8%B7%91%E5%9B%A2%E8%AE%B0%E5%BD%95/>跑团记录 (10)</a></li></ul></div></div></section><section class="d-none d-sm-block"><div class="card mb-3 widget hot_tags"><div class=card-header><i class="bi bi-tag" aria-hidden=true></i>
<span class="text-uppercase fw-bold">Tag Cloud</span></div><div class=card-body><div class=tagcloud><a href=https://blog.villsi.net/tags/blog/ title=blog class="text-muted link-underline-primary link-underline-opacity-0"><span>blog</span>
<sup><small>2</small></sup>
</a><a href=https://blog.villsi.net/tags/cloudflare/ title=Cloudflare class="text-muted link-underline-primary link-underline-opacity-0"><span>Cloudflare</span>
<sup><small>1</small></sup>
</a><a href=https://blog.villsi.net/tags/deep-learning/ title="Deep Learning" class="text-muted link-underline-primary link-underline-opacity-0"><span>Deep Learning</span>
<sup><small>1</small></sup>
</a><a href=https://blog.villsi.net/tags/dnn/ title=DNN class="text-muted link-underline-primary link-underline-opacity-0"><span>DNN</span>
<sup><small>1</small></sup>
</a><a href=https://blog.villsi.net/tags/game/ title=Game class="text-muted link-underline-primary link-underline-opacity-0"><span>Game</span>
<sup><small>1</small></sup>
</a><a href=https://blog.villsi.net/tags/github/ title=Github class="text-muted link-underline-primary link-underline-opacity-0"><span>Github</span>
<sup><small>9</small></sup>
</a><a href=https://blog.villsi.net/tags/katex/ title=Katex class="text-muted link-underline-primary link-underline-opacity-0"><span>Katex</span>
<sup><small>1</small></sup>
</a><a href=https://blog.villsi.net/tags/markdown/ title=Markdown class="text-muted link-underline-primary link-underline-opacity-0"><span>Markdown</span>
<sup><small>4</small></sup>
</a><a href=https://blog.villsi.net/tags/obsidian/ title=Obsidian class="text-muted link-underline-primary link-underline-opacity-0"><span>Obsidian</span>
<sup><small>1</small></sup>
</a><a href=https://blog.villsi.net/tags/programming/ title=Programming class="text-muted link-underline-primary link-underline-opacity-0"><span>Programming</span>
<sup><small>8</small></sup>
</a><a href=https://blog.villsi.net/tags/trpg/ title=TRPG class="text-muted link-underline-primary link-underline-opacity-0"><span>TRPG</span>
<sup><small>10</small></sup>
</a><a href=https://blog.villsi.net/tags/typora/ title=Typora class="text-muted link-underline-primary link-underline-opacity-0"><span>Typora</span>
<sup><small>1</small></sup>
</a><a href=https://blog.villsi.net/tags/%E5%86%B0%E9%A3%8E%E8%B0%B7/ title=冰风谷 class="text-muted link-underline-primary link-underline-opacity-0"><span>冰风谷</span>
<sup><small>10</small></sup>
</a><a href=https://blog.villsi.net/tags/%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/ title=经验总结 class="text-muted link-underline-primary link-underline-opacity-0"><span>经验总结</span>
<sup><small>1</small></sup>
</a><a href=https://blog.villsi.net/tags/%E9%9A%8F%E6%89%8B%E6%91%98%E5%BD%95/ title=随手摘录 class="text-muted link-underline-primary link-underline-opacity-0"><span>随手摘录</span>
<sup><small>1</small></sup></a></div></div></div></section><section><div class="card card-body mb-3 widget toc markdown" id=toc-overlay><nav id=TableOfContents><ul><li><a href=#5-percentiles--outliers>5 Percentiles & outliers</a><ul><li><a href=#percentiles>Percentiles</a></li><li><a href=#outliers>Outliers</a></li></ul></li><li><a href=#6-probability-theory>6 Probability theory</a></li><li><a href=#7-bayes-theorem>7 Bayes theorem</a><ul><li><a href=#conditional-probability>Conditional Probability:</a></li><li><a href=#bayes-theorem>Bayes Theorem</a></li></ul></li><li><a href=#8-random-variables>8 Random variables</a></li><li><a href=#9-cumul-dist-fn-cdf>9 Cumul Dist Fn (CDF)</a></li><li><a href=#10-continuous-distributions>10 Continuous distributions</a></li><li><a href=#11-skewness>11 Skewness</a><ul><li></li></ul></li><li><a href=#12-anova>12 ANOVA</a></li><li><a href=#13-prob-den-fn-pdf>13 Prob Den Fn (PDF)</a></li><li><a href=#14-central-limit-theorem>14 Central Limit theorem</a></li><li><a href=#15-monte-carlo-method>15 Monte Carlo method</a></li><li><a href=#16-hypothesis-testing>16 Hypothesis Testing</a><ul><li><a href=#types-of-curves>Types of curves</a></li><li><a href=#hypothesis-testing>Hypothesis Testing</a></li><li><a href=#tests-for-hypothesis>Tests for Hypothesis</a></li></ul></li><li><a href=#17-p-value>17 p-Value</a><ul><li><a href=#z-test>Z-test</a></li><li><a href=#p-values>P-values</a></li></ul></li><li><a href=#18-chi2-test>18 Chi2 test</a></li><li><a href=#19-estimation>19 Estimation</a></li><li><a href=#20-confid-int-ci>20 Confid Int (CI)</a></li><li><a href=#21-mle>21 MLE</a></li><li><a href=#22-kernel-density-estimate>22 Kernel Density estimate</a></li><li><a href=#23-regression>23 Regression</a></li><li><a href=#24-covariance>24 Covariance</a><ul><li><a href=#variance>Variance</a></li><li><a href=#covariance>Covariance</a></li></ul></li><li><a href=#25-correlation>25 Correlation</a></li><li><a href=#26-pearson-coeff>26 Pearson coeff</a></li><li><a href=#27-causation>27 Causation</a></li><li><a href=#28-least2-fit>28 Least2-fit</a></li><li><a href=#29-euclidian-distance>29 Euclidian Distance</a></li></ul></nav></div></section></aside></div></div></div></main><footer class=footer><section class=footbox><div class="container foot"><div class=copyright><p>Copyright &copy; 2018 - 2024
<a class="link-light link-underline link-underline-opacity-0" href=https://villsi.net target=_blank rel=noopener>上海红茶馆
</a>|
<a class="link-light link-underline link-underline-opacity-0" href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank rel=noopener>CC BY-NC-SA 4.0</a></p></div><div class=foot_nav><nav class=navbar__bottom><ul><li class="menu-item menu-item-type-taxonomy menu-item-object-category"><a class="link-light link-underline link-underline-opacity-0" href=https://blog.villsi.net/post/>文章</a></li><li class="menu-item menu-item-type-taxonomy menu-item-object-category"><a class="link-light link-underline link-underline-opacity-0" href=https://blog.villsi.net/tagcloud/>标签</a></li><li class="menu-item menu-item-type-taxonomy menu-item-object-category"><a class="link-light link-underline link-underline-opacity-0" href=https://blog.villsi.net/code/>笔记</a></li><li class="menu-item menu-item-type-taxonomy menu-item-object-category"><a class="link-light link-underline link-underline-opacity-0" href=https://blog.villsi.net/friends/>友链</a></li><li class="menu-item menu-item-type-taxonomy menu-item-object-category"><a class="link-light link-underline link-underline-opacity-0" href=https://blog.villsi.net/echart/>关于</a></li><li class="menu-item menu-item-type-taxonomy menu-item-object-category"><a class="link-light link-underline link-underline-opacity-0" href=https://blog.villsi.net/playlist/>番剧</a></li></ul></nav><div class=beian><a class="link-light link-underline link-underline-opacity-0" href=https://github.com/villsi/ target=_blank rel=noopener>TEST</a></div></div></div></section><button class=scrollupBtn title=返回顶部>
<i class="bi bi-chevron-up"></i></button></footer></body></html>