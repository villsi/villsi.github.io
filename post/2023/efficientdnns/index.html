<!doctype html><html lang=zh><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.123.0"><link rel=preconnect href=https://cdn.jsdelivr.net><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css2?display=swap&family=Inter:wght@300;400;500&family=Noto+Sans+SC:wght@300;400;500&family=Noto+Sans+JP:wght@300;400;500&family=Fira+Code:wght@300;400;500"><title>EfficientDNNs | 上海红茶馆</title>
<meta name=author content="我喜欢煎蛋卷"><meta name=description content="A collection of recent methods on DNN compression and acceleration. This repo is more about pruning (with lottery ticket hypothesis or LTH as a sub-topic), KD, and quantization."><meta name=keywords content='Deep Learning,DNN'><link rel=icon href=https://img.villsi.net/2024/01/6774b317d88c2bd3f564143548d8683e.png sizes=any><link rel=icon sizes=192x192 href=https://img.villsi.net/2024/01/6774b317d88c2bd3f564143548d8683e.png><link rel=icon sizes=512x512 href=https://img.villsi.net/2024/01/6774b317d88c2bd3f564143548d8683e.png><link rel=apple-touch-icon sizes=180x180 href=https://img.villsi.net/2024/01/6774b317d88c2bd3f564143548d8683e.png><meta property="og:title" content="EfficientDNNs | 上海红茶馆"><meta name=twitter:title content="EfficientDNNs | 上海红茶馆"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.villsi.net/post/2023/efficientdnns/"><meta property="og:description" content="A collection of recent methods on DNN compression and acceleration. This repo is more about pruning (with lottery ticket hypothesis or LTH as a sub-topic), KD, and quantization."><meta name=twitter:description content="A collection of recent methods on DNN compression and acceleration. This repo is more about pruning (with lottery ticket hypothesis or LTH as a sub-topic), KD, and quantization."><meta property="og:image" content="https://img.villsi.net/2023/12/fd029546dac00eb0a7db2781444cb6c2.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://img.villsi.net/2023/12/fd029546dac00eb0a7db2781444cb6c2.jpg"><meta property="article:published_time" content="2023-08-03T23:00:00+08:00"><meta property="article:modified_time" content="2023-11-29T11:33:50+08:00"><link rel=alternate type=application/atom+xml href=https://blog.villsi.net/index.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha2/dist/css/bootstrap.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.0/font/bootstrap-icons.css><link rel=stylesheet href=https://blog.villsi.net/assets/main.min.css><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/twemoji@14.0.2/dist/twemoji.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/quicklink@2.3.0/dist/quicklink.umd.js></script><script defer src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha2/dist/js/bootstrap.bundle.min.js></script><script defer src=https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js></script><script defer src=https://blog.villsi.net/assets/main.min.js></script></head><body data-theme=auto data-section=single><header class=header id=my-header><nav class="navbar shadow-sm fixed-top navbar-expand-md navbar-light bg-light"><div class="container p-0"><a class=navbar-brand href=https://blog.villsi.net/><img src=https://img.villsi.net/2024/01/6774b317d88c2bd3f564143548d8683e.png alt=Logo width=40 height=40 class=align-middle>
<span class="d-inline align-middle">上海红茶馆</span>
</a><button class="navbar-toggler border border-0" type=button data-bs-toggle=collapse data-bs-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav me-auto mb-2 mb-md-0 fw-normal"><li class=nav-item><a class="nav-link ms-4 text-center active" href=https://blog.villsi.net/post/>文章</a></li><li class=nav-item><a class="nav-link ms-4 text-center" href=https://blog.villsi.net/tagcloud/>标签</a></li><li class=nav-item><a class="nav-link ms-4 text-center" href=https://blog.villsi.net/code/>笔记</a></li><li class=nav-item><a class="nav-link ms-4 text-center" href=https://blog.villsi.net/echart/>关于</a></li><li class=nav-item><a class="nav-link ms-4 text-center" href=https://blog.villsi.net/playlist/>番剧</a></li></ul></div></div></nav></header><main class="main fix-padding-top"><div class=container><div class="row g-3"><div class="col-xl-2 col-lg-3 px-0 d-none d-lg-block"><aside class="sticky-top fix-sidebar-top"><div class=sidebar_sticky><section class="d-none d-sm-block"><div class="card shadow-sm border-0 card-body mb-3"><div class="pb-1 text-center"><img class="img-fluid rounded w-50" loading=lazy src=https://img.villsi.net/2023/12/fd029546dac00eb0a7db2781444cb6c2.jpg alt=头像></div><div class="pb-2 text-center"><div class=text-primary>我喜欢煎蛋卷</div><div class="text-secondary fst-italic fw-lighter small">Per aspera ad astra.</div></div><div class="pb-2 small text-center row m-0"><div class="col px-0"><div class=text-primary>308</div><div class=text-secondary>千字</div></div><div class="col px-0"><div class=text-primary>37</div><div class=text-secondary>文章</div></div><div class="col px-0"><div class=text-primary>15</div><div class=text-secondary>标签</div></div></div><div class=btn-group role=group><a class="btn btn-link link-dark p-0" href=https://github.com/villsi target=_blank rel=noopener title=GitHub><i class="bi bi-github"></i>
</a><a class="btn btn-link link-dark p-0" href=https://twitter.com/villsi target=_blank rel=noopener title=Twitter><i class="bi bi-twitter"></i>
</a><a class="btn btn-link link-dark p-0" href=https://steamcommunity.com/id/villsi/ target=_blank rel=noopener title=Steam><i class="bi bi-steam"></i></a></div></div></section><section class="d-none d-sm-block"><div class="card shadow-sm border-0 mb-3"><div class="card-header bg-white border-light-subtle"><span class="text-uppercase fw-medium">Categories</span></div><div class="card-body py-2"><ul class="list-group list-group-flush small"><li class="list-group-item d-flex justify-content-between align-items-center px-0 border-light-subtle"><a class="text-truncate link-underline-primary link-offset-0 link-underline-opacity-0 link-underline-opacity-75-hover" href=https://blog.villsi.net/categories/blog/>Blog
</a><span class="badge bg-primary rounded-pill">2</span></li><li class="list-group-item d-flex justify-content-between align-items-center px-0 border-light-subtle"><a class="text-truncate link-underline-primary link-offset-0 link-underline-opacity-0 link-underline-opacity-75-hover" href=https://blog.villsi.net/categories/uncategorized/>Uncategorized
</a><span class="badge bg-primary rounded-pill">15</span></li><li class="list-group-item d-flex justify-content-between align-items-center px-0 border-light-subtle"><a class="text-truncate link-underline-primary link-offset-0 link-underline-opacity-0 link-underline-opacity-75-hover" href=https://blog.villsi.net/categories/%E5%8D%9A%E5%AE%A2%E8%A3%85%E4%BF%AE/>博客装修
</a><span class="badge bg-primary rounded-pill">1</span></li><li class="list-group-item d-flex justify-content-between align-items-center px-0 border-light-subtle"><a class="text-truncate link-underline-primary link-offset-0 link-underline-opacity-0 link-underline-opacity-75-hover" href=https://blog.villsi.net/categories/%E8%B7%91%E5%9B%A2%E8%AE%B0%E5%BD%95/>跑团记录
</a><span class="badge bg-primary rounded-pill">10</span></li></ul></div></div></section><section class="d-none d-sm-block"><div class="card shadow-sm border-0 mb-3"><div class="card-header bg-white border-light-subtle"><span class="text-uppercase fw-medium">Tag Cloud</span></div><div class=card-body><div class=grid><a href=https://blog.villsi.net/tags/blog/ title=Blog class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">Blog</span>
</a><a href=https://blog.villsi.net/tags/cloudflare/ title=Cloudflare class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">Cloudflare</span>
</a><a href=https://blog.villsi.net/tags/deep-learning/ title="Deep Learning" class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">Deep Learning</span>
</a><a href=https://blog.villsi.net/tags/dnn/ title=DNN class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">DNN</span>
</a><a href=https://blog.villsi.net/tags/game/ title=Game class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">Game</span>
</a><a href=https://blog.villsi.net/tags/github/ title=GitHub class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">GitHub</span>
</a><a href=https://blog.villsi.net/tags/katex/ title=Katex class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">Katex</span>
</a><a href=https://blog.villsi.net/tags/markdown/ title=Markdown class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">Markdown</span>
</a><a href=https://blog.villsi.net/tags/obsidian/ title=Obsidian class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">Obsidian</span>
</a><a href=https://blog.villsi.net/tags/programming/ title=Programming class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">Programming</span>
</a><a href=https://blog.villsi.net/tags/trpg/ title=TRPG class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">TRPG</span>
</a><a href=https://blog.villsi.net/tags/typora/ title=Typora class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">Typora</span>
</a><a href=https://blog.villsi.net/tags/%E5%86%B0%E9%A3%8E%E8%B0%B7/ title=冰风谷 class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">冰风谷</span>
</a><a href=https://blog.villsi.net/tags/%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/ title=经验总结 class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">经验总结</span>
</a><a href=https://blog.villsi.net/tags/%E9%9A%8F%E6%89%8B%E6%91%98%E5%BD%95/ title=随手摘录 class="btn btn-sm btn-outline-primary py-0 my-1"><span class="d-flex text-uppercase fw-light small">随手摘录</span></a></div></div></div></section></aside></div><div class="col-xl-8 col-lg-9 px-3"><div class=content><div class="card mb-3 shadow-sm border-0 overflow-hidden"><div class=header-image><div class="ratio ratio-21x9 overflow-hidden bg-black"><a href=https://blog.villsi.net/post/2023/efficientdnns/><img class="card-img-top opacity-50" loading=lazy src=https://picsum.photos/seed/EfficientDNNs/1600/1200 alt=博客文章头图></a><div class="card-img-overlay row align-items-center"><div class="text-light text-center"><h2>EfficientDNNs</h2><div><div class="d-block small"><div class="d-inline pe-3"><i class="bi bi-calendar3 pe-2"></i><time>2023-08-03</time></div><div class="d-inline pe-3"><i class="bi bi-book pe-1"></i>
<span>6420 字</span></div><div class=d-inline><i class="bi bi-alarm pe-1"></i>
<span>31 分钟</span></div></div><div class="d-none d-xl-block small"><div class="d-md-inline ps-2"><i class="bi bi-hash"></i>
<span>Deep Learning</span></div><div class="d-md-inline ps-2"><i class="bi bi-hash"></i>
<span>DNN</span></div></div></div></div></div></div></div><article class="card-body markdown"><p>A collection of recent methods on DNN compression and acceleration. There are mainly 5 kinds of methods for efficient DNNs:</p><ul><li>neural architecture re-design or search (NAS)<ul><li>maintain accuracy, less cost (e.g., #Params, #FLOPs, etc.): MobileNet, ShuffleNet etc.</li><li>maintain cost, more accuracy: Inception, ResNeXt, Xception etc.</li></ul></li><li>pruning (including structured and unstructured)</li><li>quantization</li><li>matrix/low-rank decomposition</li><li>knowledge distillation (KD)</li></ul><p>Note, this repo is more about pruning (with lottery ticket hypothesis or LTH as a sub-topic), KD, and quantization. For other topics like NAS, see more comprehensive collections (## Related Repos and Websites) at the end of this file. Welcome to send a pull request if you&rsquo;d like to add any pertinent papers.</p><p>Other repos:</p><ul><li>LTH (lottery ticket hypothesis) and its broader version, <em>pruning at initialization (PaI)</em>, now is at the frontier of network pruning. We single out the PaI papers to <a href=https://github.com/MingSun-Tse/Awesome-Pruning-at-Initialization target=_blank rel=noopener>this repo</a>. Welcome to check it out!</li><li><a href=https://github.com/MingSun-Tse/Awesome-Efficient-ViT target=_blank rel=noopener>Awesome-Efficient-ViT</a> for a curated list of efficient vision transformers.</li></ul><blockquote><p>About abbreviation: In the list below, <code>o</code> for oral, <code>s</code> for spotlight, <code>b</code> for best paper, <code>w</code> for workshop.</p></blockquote><h2 id=surveys>Surveys</h2><ul><li>1993-TNN-<a href="https://ieeexplore.ieee.org/abstract/document/248452?casa_token=eJan5NO1DxwAAAAA:chz9BYf22tIO4RHt6nC_x4nbTeTslXiLMrvQElnrXZGbg9fn4c-Alonhq8UYWhT86gXFGO2_" target=_blank rel=noopener>Pruning Algorithms &ndash; A survey</a></li><li>2017-Proceedings of the IEEE-<a href=https://ieeexplore.ieee.org/document/8114708 target=_blank rel=noopener>Efficient Processing of Deep Neural Networks: A Tutorial and Survey</a> [<a href="https://www.morganclaypool.com/doi/pdfplus/10.2200/S01004ED1V01Y202004CAC050?casa_token=rnnqUJmipDEAAAAA:fOs90gKOCbMDqjZlGdc25dCi3H4L0gT1tkEqhNL1eNBpV8h36cvQet9WK0qVRqs9M6irYxbH" target=_blank rel=noopener>2020 Book: Efficient Processing of Deep Neural Networks</a>]</li><li>2017.12-<a href=https://arxiv.org/abs/1712.08934 target=_blank rel=noopener>A survey of FPGA-based neural network accelerator</a></li><li>2018-FITEE-<a href=https://link.springer.com/article/10.1631/FITEE.1700789 target=_blank rel=noopener>Recent Advances in Efficient Computation of Deep Convolutional Neural Networks</a></li><li>2018-IEEE Signal Processing Magazine-<a href=https://ieeexplore.ieee.org/abstract/document/8253600 target=_blank rel=noopener>Model compression and acceleration for deep neural networks: The principles, progress, and challenges</a>. <a href=https://arxiv.org/abs/1710.09282 target=_blank rel=noopener>Arxiv extension</a></li><li>2018.8-<a href=https://arxiv.org/abs/1808.04752 target=_blank rel=noopener>A Survey on Methods and Theories of Quantized Neural Networks</a></li><li>2019-JMLR-<a href=http://www.jmlr.org/papers/volume20/18-598/18-598.pdf target=_blank rel=noopener>Neural Architecture Search: A Survey</a></li><li>2020-MLSys-<a href=https://arxiv.org/abs/2003.03033 target=_blank rel=noopener>What is the state of neural network pruning</a></li><li>2019.02-<a href=https://arxiv.org/pdf/1902.09574.pdf target=_blank rel=noopener>The State of Sparsity in Deep Neural Networks</a></li><li>2021-TPAMI-<a href=https://arxiv.org/abs/2004.05937 target=_blank rel=noopener>Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks</a></li><li>2021-IJCV-<a href=https://arxiv.org/abs/2006.05525 target=_blank rel=noopener>Knowledge Distillation: A Survey</a></li><li>2020-Proceedings of the IEEE-<a href=https://ieeexplore.ieee.org/abstract/document/9043731 target=_blank rel=noopener>Model Compression and Hardware Acceleration for Neural Networks: A Comprehensive Survey</a></li><li>2020-Pattern Recognition-<a href="https://www.sciencedirect.com/science/article/pii/S0031320320300856?casa_token=Foe2l0h1AXUAAAAA:z7DaP-QSVCNApUpTsrftp3f2SBfcNj2AH_B0cbzPH4r8BR-cGSns16p1-CQtY7vXuexlPd_Y" target=_blank rel=noopener>Binary neural networks: A survey</a></li><li>2021-TPDS-<a href=https://arxiv.org/abs/2002.03794 target=_blank rel=noopener>The Deep Learning Compiler: A Comprehensive Survey</a></li><li>2021-JMLR-<a href=https://arxiv.org/abs/2102.00554 target=_blank rel=noopener>Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks</a></li><li>2022-IJCAI-<a href=https://arxiv.org/abs/2103.06460 target=_blank rel=noopener>Recent Advances on Neural Network Pruning at Initialization</a></li><li>2021.6-<a href=https://arxiv.org/abs/2106.08962 target=_blank rel=noopener>Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better</a></li></ul><h2 id=papers-pruning-and-quantization>Papers [Pruning and Quantization]</h2><p><strong>1980s,1990s</strong></p><ul><li>1988-NIPS-<a href=https://proceedings.neurips.cc/paper/1988/file/9fc3d7152ba9336a670e36d0ed79bc43-Paper.pdf target=_blank rel=noopener>A back-propagation algorithm with optimal use of hidden units</a></li><li>1988-NIPS-<a href=https://papers.nips.cc/paper/1988/file/07e1cd7dca89a1678042477183b7ac3f-Paper.pdf target=_blank rel=noopener>Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment</a></li><li>1988-NIPS-<a href=https://papers.nips.cc/paper/1988/file/1d7f7abc18fcb43975065399b0d1e48e-Paper.pdf target=_blank rel=noopener>What Size Net Gives Valid Generalization?</a></li><li>1989-NIPS-<a href=https://proceedings.neurips.cc/paper/1989/hash/85d8ce590ad8981ca2c8286f79f59954-Abstract.html target=_blank rel=noopener>Dynamic Behavior of Constained Back-Propagation Networks</a></li><li>1988-NIPS-<a href=https://papers.nips.cc/paper/1988/file/1c9ac0159c94d8d0cbedc973445af2da-Paper.pdf target=_blank rel=noopener>Comparing Biases for Minimal Network Construction with Back-Propagation</a></li><li>1989-NIPS-<a href=https://papers.nips.cc/paper/1989/file/6c9882bbac1c7093bd25041881277658-Paper.pdf target=_blank rel=noopener>Optimal Brain Damage</a></li><li>1990-NN-<a href=https://ieeexplore.ieee.org/abstract/document/80236 target=_blank rel=noopener>A simple procedure for pruning back-propagation trained neural networks</a></li><li>1993-ICNN-<a href="https://ieeexplore.ieee.org/abstract/document/298572?casa_token=8a8fUVuadHEAAAAA:tgRbetEERx1Bdh6RCa27mok9SAPNc8Y33qy2ScdTNOCs_ajHlaUv4_nnvDNJp3jZbb13uouD" target=_blank rel=noopener>Optimal Brain Surgeon and general network pruning</a></li></ul><p><strong>2000s</strong></p><ul><li>2001-JMLR-<a href=https://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf target=_blank rel=noopener>Sparse Bayesian learning and the relevance vector machine</a></li><li>2007-Book-<a href target=_blank rel=noopener>The minimum description length principle</a></li></ul><p><strong>2011</strong></p><ul><li>2011-JMLR-<a href=http://www.jmlr.org/papers/v12/huang11b.html target=_blank rel=noopener>Learning with Structured Sparsity</a></li><li>2011-NIPSw-<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.308.2766" target=_blank rel=noopener>Improving the speed of neural networks on CPUs</a></li></ul><p><strong>2013</strong></p><ul><li>2013-NIPS-<a href=http://papers.nips.cc/paper/5025-predicting-parameters-in-deep-learning target=_blank rel=noopener>Predicting Parameters in Deep Learning</a></li><li>2013.08-<a href=https://arxiv.org/abs/1308.3432 target=_blank rel=noopener>Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation</a></li></ul><p><strong>2014</strong></p><ul><li>2014-BMVC-<a href=https://arxiv.org/abs/1405.3866 target=_blank rel=noopener>Speeding up convolutional neural networks with low rank expansions</a></li><li>2014-INTERSPEECH-<a href=https://www.isca-speech.org/archive/interspeech_2014/i14_1058.html target=_blank rel=noopener>1-Bit Stochastic Gradient Descent and its Application to Data-Parallel Distributed Training of Speech DNNs</a></li><li>2014-NIPS-<a href=http://papers.nips.cc/paper/5544-exploiting-linear-structure-within-convolutional-networks-for-efficient-evaluation target=_blank rel=noopener>Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation</a></li><li>2014-NIPS-<a href=http://papers.nips.cc/paper/5484-do-deep-nets-really-need-to-be-deep target=_blank rel=noopener>Do deep neural nets really need to be deep</a></li><li>2014.12-<a href=https://arxiv.org/abs/1412.1442 target=_blank rel=noopener>Memory bounded deep convolutional networks</a></li></ul><p><strong>2015</strong></p><ul><li>2015-ICLR-<a href=https://arxiv.org/abs/1412.6553 target=_blank rel=noopener>Speeding-up convolutional neural networks using fine-tuned cp-decomposition</a></li><li>2015-ICML-<a href=http://proceedings.mlr.press/v37/chenc15.pdf target=_blank rel=noopener>Compressing neural networks with the hashing trick</a></li><li>2015-INTERSPEECH-<a href=https://www.isca-speech.org/archive/interspeech_2015/papers/i15_3590.pdf target=_blank rel=noopener>A Diversity-Penalizing Ensemble Training Method for Deep Learning</a></li><li>2015-BMVC-<a href=https://arxiv.org/abs/1507.06149 target=_blank rel=noopener>Data-free parameter pruning for deep neural networks</a></li><li>2015-BMVC-<a href=http://www.bmva.org/bmvc/2015/papers/paper023/paper023.pdf target=_blank rel=noopener>Learning the structure of deep architectures using l1 regularization</a></li><li>2015-NIPS-<a href=http://papers.nips.cc/paper/5784-learning-both-weights-and-connections-for-efficient-neural-network target=_blank rel=noopener>Learning both Weights and Connections for Efficient Neural Network</a></li><li>2015-NIPS-<a href=http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-b target=_blank rel=noopener>Binaryconnect: Training deep neural networks with binary weights during propagations</a></li><li>2015-NIPS-<a href=http://papers.nips.cc/paper/5869-structured-transforms-for-small-footprint-deep-learning target=_blank rel=noopener>Structured Transforms for Small-Footprint Deep Learning</a></li><li>2015-NIPS-<a href=http://papers.nips.cc/paper/5787-tensorizing-neural-networks target=_blank rel=noopener>Tensorizing Neural Networks</a></li><li>2015-NIPSw-<a href=http://homepages.inf.ed.ac.uk/s1459647/papers/distilling_generative_models.pdf target=_blank rel=noopener>Distilling Intractable Generative Models</a></li><li>2015-NIPSw-<a href=https://arxiv.org/abs/1511.03575 target=_blank rel=noopener>Federated Optimization:Distributed Optimization Beyond the Datacenter</a></li><li>2015-CVPR-<a href=https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Zhang_Efficient_and_Accurate_2015_CVPR_paper.html target=_blank rel=noopener>Efficient and Accurate Approximations of Nonlinear Convolutional Networks</a> [2016 TPAMI version: <a href=https://ieeexplore.ieee.org/abstract/document/7332968 target=_blank rel=noopener>Accelerating Very Deep Convolutional Networks for Classification and Detection</a>]</li><li>2015-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2015/html/Liu_Sparse_Convolutional_Neural_2015_CVPR_paper.html target=_blank rel=noopener>Sparse Convolutional Neural Networks</a></li><li>2015-ICCV-<a href=https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Cheng_An_Exploration_of_ICCV_2015_paper.html target=_blank rel=noopener>An Exploration of Parameter Redundancy in Deep Networks with Circulant Projections</a></li><li>2015.12-<a href=https://arxiv.org/abs/1512.09194 target=_blank rel=noopener>Exploiting Local Structures with the Kronecker Layer in Convolutional Networks</a></li></ul><p><strong>2016</strong></p><ul><li>2016-ICLR-<a href=https://arxiv.org/abs/1510.00149 target=_blank rel=noopener>Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</a> [Best paper!]</li><li>2016-ICLR-<a href=https://arxiv.org/abs/1511.06422 target=_blank rel=noopener>All you need is a good init</a> [<a href=https://github.com/ducha-aiki/LSUVinit target=_blank rel=noopener>Code</a>]</li><li>2016-ICLR-<a href=https://arxiv.org/abs/1511.06856 target=_blank rel=noopener>Data-dependent Initializations of Convolutional Neural Networks</a> [<a href=https://github.com/philkr/magic_init target=_blank rel=noopener>Code</a>]</li><li>2016-ICLR-<a href=https://arxiv.org/abs/1511.06067 target=_blank rel=noopener>Convolutional neural networks with low-rank regularization</a> [<a href=https://github.com/chengtaipu/lowrankcnn target=_blank rel=noopener>Code</a>]</li><li>2016-ICLR-<a href=https://pdfs.semanticscholar.org/3f08/1a7d2dbdcd10d71d0340721e4857a73ed7ee.pdf target=_blank rel=noopener>Diversity networks</a></li><li>2016-ICLR-<a href=https://arxiv.org/abs/1510.03009 target=_blank rel=noopener>Neural networks with few multiplications</a></li><li>2016-ICLR-<a href=https://arxiv.org/abs/1511.06530 target=_blank rel=noopener>Compression of deep convolutional neural networks for fast and low power mobile applications</a></li><li>2016-ICLRw-<a href=https://arxiv.org/abs/1602.05931 target=_blank rel=noopener>Randomout: Using a convolutional gradient norm to win the filter lottery</a></li><li>2016-CVPR-<a href=https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Lavin_Fast_Algorithms_for_CVPR_2016_paper.html target=_blank rel=noopener>Fast algorithms for convolutional neural networks</a></li><li>2016-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2016/html/Lebedev_Fast_ConvNets_Using_CVPR_2016_paper.html target=_blank rel=noopener>Fast ConvNets Using Group-wise Brain Damage</a></li><li>2016-BMVC-<a href=https://arxiv.org/abs/1511.05497 target=_blank rel=noopener>Learning neural network architectures using backpropagation</a></li><li>2016-ECCV-<a href=http://users.umiacs.umd.edu/~hzhou/paper/zhou_ECCV2016.pdf target=_blank rel=noopener>Less is more: Towards compact cnns</a></li><li>2016-EMNLP-<a href=https://arxiv.org/abs/1606.07947 target=_blank rel=noopener>Sequence-Level Knowledge Distillation</a></li><li>2016-NIPS-<a href=https://proceedings.neurips.cc/paper/2016/hash/41bfd20a38bb1b0bec75acf0845530a7-Abstract.html target=_blank rel=noopener>Learning Structured Sparsity in Deep Neural Networks</a> [<a href=https://github.com/wenwei202/caffe target=_blank rel=noopener>Caffe Code</a>]</li><li>2016-NIPS-<a href=http://papers.nips.cc/paper/6165-dynamic-network-surgery-for-efficient-dnns target=_blank rel=noopener>Dynamic Network Surgery for Efficient DNNs</a> [<a href=https://github.com/yiwenguo/Dynamic-Network-Surgery target=_blank rel=noopener>Caffe Code</a>]</li><li>2016-NIPS-<a href=http://papers.nips.cc/paper/6372-learning-the-number-of-neurons-in-deep-networks target=_blank rel=noopener>Learning the Number of Neurons in Deep Neural Networks</a></li><li>2016-NIPS-<a href=http://papers.nips.cc/paper/6220-memory-efficient-backpropagation-through-time target=_blank rel=noopener>Memory-Efficient Backpropagation Through Time</a></li><li>2016-NIPS-<a href=http://papers.nips.cc/paper/6463-perforatedcnns-acceleration-through-elimination-of-redundant-convolutions target=_blank rel=noopener>PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions</a></li><li>2016-NIPS-<a href=http://papers.nips.cc/paper/6512-lightrnn-memory-and-computation-efficient-recurrent-neural-networks target=_blank rel=noopener>LightRNN: Memory and Computation-Efficient Recurrent Neural Networks</a></li><li>2016-NIPS-<a href=https://papers.nips.cc/paper/6390-cnnpack-packing-convolutional-neural-networks-in-the-frequency-domain.pdf target=_blank rel=noopener>CNNpack: packing convolutional neural networks in the frequency domain</a></li><li>2016-ISCA-<a href=https://people.csail.mit.edu/emer/papers/2016.06.isca.eyeriss_architecture.pdf target=_blank rel=noopener>Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks</a></li><li>2016-ICASSP-<a href=https://arxiv.org/abs/1604.02594 target=_blank rel=noopener>Learning compact recurrent neural networks</a></li><li>2016-CoNLL-<a href=https://arxiv.org/abs/1606.09274 target=_blank rel=noopener>Compression of Neural Machine Translation Models via Pruning</a></li><li>2016.03-<a href=https://arxiv.org/abs/1603.08983 target=_blank rel=noopener>Adaptive Computation Time for Recurrent Neural Networks</a></li><li>2016.06-<a href=https://arxiv.org/abs/1606.02407 target=_blank rel=noopener>Structured Convolution Matrices for Energy-efficient Deep learning</a></li><li>2016.06-<a href=https://arxiv.org/abs/1606.01981 target=_blank rel=noopener>Deep neural networks are robust to weight binarization and other non-linear distortions</a></li><li>2016.06-<a href=https://arxiv.org/abs/1609.09106 target=_blank rel=noopener>Hypernetworks</a></li><li>2016.07-IHT-<a href=https://arxiv.org/abs/1607.05423 target=_blank rel=noopener>Training skinny deep neural networks with iterative hard thresholding methods</a></li><li>2016.08-<a href=https://arxiv.org/abs/1608.06902 target=_blank rel=noopener>Recurrent Neural Networks With Limited Numerical Precision</a></li><li>2016.10-<a href=https://arxiv.org/abs/1610.09650 target=_blank rel=noopener>Deep model compression: Distilling knowledge from noisy teachers</a></li><li>2016.10-<a href=https://arxiv.org/abs/1610.02527 target=_blank rel=noopener>Federated Optimization: Distributed Machine Learning for On-Device Intelligence</a></li><li>2016.11-<a href=https://arxiv.org/abs/1611.01590 target=_blank rel=noopener>Alternating Direction Method of Multipliers for Sparse Convolutional Neural Networks</a></li></ul><p><strong>2017</strong></p><ul><li>2017-ICLR-<a href="https://openreview.net/forum?id=rJqFGTslg" target=_blank rel=noopener>Pruning Filters for Efficient ConvNets</a> [<a href=https://github.com/Eric-mingjie/rethinking-network-pruning/tree/master/imagenet/l1-norm-pruning target=_blank rel=noopener>PyTorch Reimpl. #1</a>] [<a href=https://github.com/MingSun-Tse/Regularization-Pruning target=_blank rel=noopener>PyTorch Reimpl. #2</a>]</li><li>2017-ICLR-<a href="https://openreview.net/forum?id=SJGCiw5gl&amp;noteId=SJGCiw5gl" target=_blank rel=noopener>Pruning Convolutional Neural Networks for Resource Efficient Inference</a></li><li>2017-ICLR-<a href=https://arxiv.org/abs/1702.03044 target=_blank rel=noopener>Incremental Network Quantization: Towards Lossless CNNs with Low-Precision Weights</a> [<a href=https://github.com/Mxbonn/INQ-pytorch target=_blank rel=noopener>Code</a>]</li><li>2017-ICLR-<a href=https://arxiv.org/abs/1603.05691 target=_blank rel=noopener>Do Deep Convolutional Nets Really Need to be Deep and Convolutional?</a></li><li>2017-ICLR-<a href=https://arxiv.org/abs/1607.04381 target=_blank rel=noopener>DSD: Dense-Sparse-Dense Training for Deep Neural Networks</a></li><li>2017-ICLR-<a href=https://arxiv.org/abs/1608.01409 target=_blank rel=noopener>Faster CNNs with Direct Sparse Convolutions and Guided Pruning</a></li><li>2017-ICLR-<a href="https://openreview.net/forum?id=rJ8uNptgl" target=_blank rel=noopener>Towards the Limit of Network Quantization</a></li><li>2017-ICLR-<a href="https://openreview.net/forum?id=S1oWlN9ll&amp;noteId=S1oWlN9ll" target=_blank rel=noopener>Loss-aware Binarization of Deep Networks</a></li><li>2017-ICLR-<a href="https://openreview.net/forum?id=S1_pAu9xl&amp;noteId=S1_pAu9xl" target=_blank rel=noopener>Trained Ternary Quantization</a> [<a href=https://github.com/czhu95/ternarynet target=_blank rel=noopener>Code</a>]</li><li>2017-ICLR-<a href="https://openreview.net/forum?id=BylSPv9gx&amp;noteId=BylSPv9gx" target=_blank rel=noopener>Exploring Sparsity in Recurrent Neural Networks</a></li><li>2017-ICLR-<a href="https://openreview.net/forum?id=HJGwcKclx" target=_blank rel=noopener>Soft Weight-Sharing for Neural Network Compression</a> [<a href=https://www.reddit.com/r/MachineLearning/comments/5u7h3l/r_compressing_nn_with_shannons_blessing/ target=_blank rel=noopener>Reddit discussion</a>] [<a href=https://github.com/KarenUllrich/Tutorial-SoftWeightSharingForNNCompression target=_blank rel=noopener>Code</a>]</li><li>2017-ICLR-<a href="https://openreview.net/forum?id=S1LVSrcge&amp;noteId=S1LVSrcge" target=_blank rel=noopener>Variable Computation in Recurrent Neural Networks</a></li><li>2017-ICLR-<a href="https://openreview.net/forum?id=Hku9NK5lx" target=_blank rel=noopener>Training Compressed Fully-Connected Networks with a Density-Diversity Penalty</a></li><li>2017-ICML-<a href=https://arxiv.org/abs/1703.00144 target=_blank rel=noopener>Theoretical Properties for Neural Networks with Weight Matrices of Low Displacement Rank</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/budden17a.html target=_blank rel=noopener>Deep Tensor Convolution on Multicores</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/neil17a.html target=_blank rel=noopener>Delta Networks for Optimized Recurrent Network Computation</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/wang17m.html target=_blank rel=noopener>Beyond Filters: Compact Feature Map for Portable Deep Model</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/yoon17a.html target=_blank rel=noopener>Combined Group and Exclusive Sparsity for Deep Neural Networks</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/cho17a.html target=_blank rel=noopener>MEC: Memory-efficient Convolution for Deep Neural Network</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/mcgill17a.html target=_blank rel=noopener>Deciding How to Decide: Dynamic Routing in Artificial Neural Networks</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/zhang17e.html target=_blank rel=noopener>ZipML: Training Models with End-to-End Low Precision: The Cans, the Cannots, and a Little Bit of Deep Learning</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/sakr17a.html target=_blank rel=noopener>Analytical Guarantees on Numerical Precision of Deep Neural Networks</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/bolukbasi17a.html target=_blank rel=noopener>Adaptive Neural Networks for Efficient Inference</a></li><li>2017-ICML-<a href=http://proceedings.mlr.press/v70/kim17b.html target=_blank rel=noopener>SplitNet: Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization</a></li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Zhang_Learning_Deep_CNN_CVPR_2017_paper.html target=_blank rel=noopener>Learning deep CNN denoiser prior for image restoration</a></li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Ioannou_Deep_Roots_Improving_CVPR_2017_paper.html target=_blank rel=noopener>Deep roots: Improving cnn efficiency with hierarchical filter groups</a></li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Dong_More_Is_Less_CVPR_2017_paper.html target=_blank rel=noopener>More is less: A more complicated network with less inference complexity</a> [<a href=https://github.com/D-X-Y/DXY-Projects/tree/master/LCCL target=_blank rel=noopener>PyTorch Code</a>]</li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Xie_All_You_Need_CVPR_2017_paper.html target=_blank rel=noopener>All You Need is Beyond a Good Init: Exploring Better Solution for Training Extremely Deep Convolutional Neural Networks with Orthonormality and Modulation</a></li><li>2017-CVPR-ResNeXt-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.html target=_blank rel=noopener>Aggregated Residual Transformations for Deep Neural Networks</a></li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Chollet_Xception_Deep_Learning_CVPR_2017_paper.html target=_blank rel=noopener>Xception: Deep learning with depthwise separable convolutions</a></li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Yang_Designing_Energy-Efficient_Convolutional_CVPR_2017_paper.html target=_blank rel=noopener>Designing Energy-Efficient CNN using Energy-aware Pruning</a></li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Figurnov_Spatially_Adaptive_Computation_CVPR_2017_paper.html target=_blank rel=noopener>Spatially Adaptive Computation Time for Residual Networks</a></li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Guo_Network_Sketching_Exploiting_CVPR_2017_paper.html target=_blank rel=noopener>Network Sketching: Exploiting Binary Structure in Deep CNNs</a></li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/html/Wu_A_Compact_DNN_CVPR_2017_paper.html target=_blank rel=noopener>A Compact DNN: Approaching GoogLeNet-Level Accuracy of Classification and Domain Adaptation</a></li><li>2017-ICCV-<a href=http://openaccess.thecvf.com/content_iccv_2017/html/He_Channel_Pruning_for_ICCV_2017_paper.html target=_blank rel=noopener>Channel pruning for accelerating very deep neural networks</a> [<a href=https://github.com/yihui-he/channel-pruning target=_blank rel=noopener>Caffe Code</a>]</li><li>2017-ICCV-<a href=http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Learning_Efficient_Convolutional_ICCV_2017_paper.html target=_blank rel=noopener>Learning efficient convolutional networks through network slimming</a> [<a href=https://github.com/liuzhuang13/slimming/ target=_blank rel=noopener>PyTorch Code</a>]</li><li>2017-ICCV-<a href=http://openaccess.thecvf.com/content_iccv_2017/html/Luo_ThiNet_A_Filter_ICCV_2017_paper.html target=_blank rel=noopener>ThiNet: A filter level pruning method for deep neural network compression</a> [<a href=http://lamda.nju.edu.cn/luojh/project/ThiNet_ICCV17/ThiNet_ICCV17.html target=_blank rel=noopener>Project</a>] [<a href=https://github.com/Roll920/ThiNet_Code target=_blank rel=noopener>Caffe Code</a>] [<a href=https://ieeexplore.ieee.org/document/8416559 target=_blank rel=noopener>2018 TPAMI version</a>]</li><li>2017-ICCV-<a href=http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Interleaved_Group_Convolutions_ICCV_2017_paper.html target=_blank rel=noopener>Interleaved group convolutions</a></li><li>2017-ICCV-<a href=http://openaccess.thecvf.com/content_iccv_2017/html/Wen_Coordinating_Filters_for_ICCV_2017_paper.html target=_blank rel=noopener>Coordinating Filters for Faster Deep Neural Networks</a> [<a href=https://github.com/wenwei202/caffe target=_blank rel=noopener>Caffe Code</a>]</li><li>2017-ICCV-<a href=http://openaccess.thecvf.com/content_iccv_2017/html/Li_Performance_Guaranteed_Network_ICCV_2017_paper.html target=_blank rel=noopener>Performance Guaranteed Network Acceleration via High-Order Residual Quantization</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6910-net-trim-convex-pruning-of-deep-neural-networks-with-performance-guarantee target=_blank rel=noopener>Net-trim: Convex pruning of deep neural networks with performance guarantee</a> [<a href=https://github.com/DNNToolBox/Net-Trim target=_blank rel=noopener>Code</a>] (Journal version: <a href=https://epubs.siam.org/doi/abs/10.1137/19M1246468 target=_blank rel=noopener>2020-SIAM-Fast Convex Pruning of Deep Neural Networks</a>)</li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6813-runtime-neural-pruning target=_blank rel=noopener>Runtime neural pruning</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/7071-learning-to-prune-deep-neural-networks-via-layer-wise-optimal-brain-surgeon target=_blank rel=noopener>Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain Surgeon</a> [<a href=https://github.com/csyhhu/L-OBS target=_blank rel=noopener>Code</a>]</li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/7029-federated-multi-task-learning target=_blank rel=noopener>Federated Multi-Task Learning</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6638-towards-accurate-binary-convolutional-neural-network target=_blank rel=noopener>Towards Accurate Binary Convolutional Neural Network</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6714-soft-to-hard-vector-quantization-for-end-to-end-learning-compressible-representations target=_blank rel=noopener>Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6749-terngrad-ternary-gradients-to-reduce-communication-in-distributed-deep-learning target=_blank rel=noopener>TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6771-flexpoint-an-adaptive-numerical-format-for-efficient-training-of-deep-neural-networks target=_blank rel=noopener>Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/7163-training-quantized-nets-a-deeper-understanding target=_blank rel=noopener>Training Quantized Nets: A Deeper Understanding</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6816-the-reversible-residual-network-backpropagation-without-storing-activations target=_blank rel=noopener>The Reversible Residual Network: Backpropagation Without Storing Activations</a> [<a href=https://github.com/renmengye/revnet-public target=_blank rel=noopener>Code</a>]</li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6687-compression-aware-training-of-deep-networks target=_blank rel=noopener>Compression-aware Training of Deep Networks</a></li><li>2017-FPGA-<a href=https://pdfs.semanticscholar.org/99d2/07c18ba48e41560f3081ea1b7c6fde98c1ce.pdf target=_blank rel=noopener>ESE: efficient speech recognition engine with compressed LSTM on FPGA</a> [Best paper!]</li><li>2017-AISTATS-<a href=https://arxiv.org/abs/1602.05629 target=_blank rel=noopener>Communication-Efficient Learning of Deep Networks from Decentralized Data</a></li><li>2017-ICASSP-<a href=https://arxiv.org/abs/1610.00324 target=_blank rel=noopener>Accelerating Deep Convolutional Networks using low-precision and sparsity</a></li><li>2017-NNs-<a href=https://www.sciencedirect.com/science/article/pii/S0893608017300928 target=_blank rel=noopener>Nonredundant sparse feature extraction using autoencoders with receptive fields clustering</a></li><li>2017.02-<a href=https://arxiv.org/abs/1702.06257 target=_blank rel=noopener>The Power of Sparsity in Convolutional Neural Networks</a></li><li>2017.07-<a href=https://arxiv.org/abs/1707.01155 target=_blank rel=noopener>Stochastic, Distributed and Federated Optimization for Machine Learning</a></li><li>2017.05-<a href=https://arxiv.org/abs/1705.07356 target=_blank rel=noopener>Structural Compression of Convolutional Neural Networks Based on Greedy Filter Pruning</a></li><li>2017.07-<a href=https://arxiv.org/abs/1707.09870 target=_blank rel=noopener>Extremely Low Bit Neural Network: Squeeze the Last Bit Out with ADMM</a></li><li>2017.11-<a href=https://openai.com/blog/block-sparse-gpu-kernels/ target=_blank rel=noopener>GPU Kernels for Block-Sparse Weights</a> [<a href=https://github.com/openai/blocksparse target=_blank rel=noopener>Code</a>] (OpenAI)</li><li>2017.11-<a href=https://arxiv.org/abs/1711.02782 target=_blank rel=noopener>Block-sparse recurrent neural networks</a></li></ul><p><strong>2018</strong></p><ul><li>2018-AAAI-<a href=https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16450/16263 target=_blank rel=noopener>Auto-balanced Filter Pruning for Efficient Convolutional Neural Networks</a></li><li>2018-AAAI-<a href=https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16479/16742 target=_blank rel=noopener>Deep Neural Network Compression with Single and Multiple Level Quantization</a></li><li>2018-AAAI-<a href=https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16291 target=_blank rel=noopener>Dynamic Deep Neural Networks_Optimizing Accuracy-Efficiency Trade-offs by Selective Execution</a></li><li>2018-ICLRo-<a href="https://openreview.net/forum?id=HJGXzmspb" target=_blank rel=noopener>Training and Inference with Integers in Deep Neural Networks</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=HJ94fqApW" target=_blank rel=noopener>Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=B1hcZZ-AW" target=_blank rel=noopener>N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=S1XolQbRW" target=_blank rel=noopener>Model compression via distillation and quantization</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=HkXWCMbRW" target=_blank rel=noopener>Towards Image Understanding from Deep Compression Without Decoding</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=SkhQHMW0W" target=_blank rel=noopener>Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=H135uzZ0-" target=_blank rel=noopener>Mixed Precision Training of Convolutional Neural Networks using Integer Operations</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=r1gs9JgRZ" target=_blank rel=noopener>Mixed Precision Training</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=B1ae1lZRb" target=_blank rel=noopener>Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=BkrSv0lA-" target=_blank rel=noopener>Loss-aware Weight Quantization of Deep Networks</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=S19dR9x0b" target=_blank rel=noopener>Alternating Multi-bit Quantization for Recurrent Neural Networks</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=SyOK1Sg0W" target=_blank rel=noopener>Adaptive Quantization of Neural Networks</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=ry-TW-WAb" target=_blank rel=noopener>Variational Network Quantization</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=Sk6fD5yCb&amp;noteId=Sk6fD5yCb" target=_blank rel=noopener>Espresso: Efficient Forward Propagation for Binary Deep Neural Networks</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=rypT3fb0b&amp;noteId=rkwxPE67M" target=_blank rel=noopener>Learning to share: Simultaneous parameter tying and sparsification in deep learning</a></li><li>2018-ICLR-<a href=https://arxiv.org/abs/1712.01312 target=_blank rel=noopener>Learning Sparse Neural Networks through L0 Regularization</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=B1ZvaaeAZ&amp;noteId=B1ZvaaeAZ" target=_blank rel=noopener>WRPN: Wide Reduced-Precision Networks</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=BJ_wN01C-&amp;noteId=BJ_wN01C-" target=_blank rel=noopener>Deep rewiring: Training very sparse deep networks</a></li><li>2018-ICLR-<a href=https://arxiv.org/pdf/1802.06367.pdf target=_blank rel=noopener>Efficient sparse-winograd convolutional neural networks</a> [<a href=https://github.com/xingyul/Sparse-Winograd-CNN target=_blank rel=noopener>Code</a>]</li><li>2018-ICLR-<a href=https://arxiv.org/pdf/1709.05027 target=_blank rel=noopener>Learning Intrinsic Sparse Structures within Long Short-term Memory</a></li><li>2018-ICLR-<a href=https://arxiv.org/abs/1703.09844 target=_blank rel=noopener>Multi-scale dense networks for resource efficient image classification</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=BJRZzFlRb&amp;noteId=BJRZzFlRb" target=_blank rel=noopener>Compressing Word Embedding via Deep Compositional Code Learning</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=BySRH6CpW" target=_blank rel=noopener>Learning Discrete Weights Using the Local Reparameterization Trick</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=rytNfI1AZ&amp;noteId=rytNfI1AZ" target=_blank rel=noopener>Training wide residual networks for deployment using a single bit for each weight</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=B1IDRdeCW&amp;noteId=B1IDRdeCW" target=_blank rel=noopener>The High-Dimensional Geometry of Binary Neural Networks</a></li><li>2018-ICLRw-<a href="https://openreview.net/forum?id=Sy1iIDkPM" target=_blank rel=noopener>To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression</a> (Similar topic: <a href="https://openreview.net/forum?id=r1lbgwFj5m" target=_blank rel=noopener>2018-NIPSw-nip in the bud</a>, <a href="https://openreview.net/forum?id=r1eLk2mKiX" target=_blank rel=noopener>2018-NIPSw-rethink</a>)</li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_Context-Aware_Deep_Feature_CVPR_2018_paper.pdf target=_blank rel=noopener>Context-Aware Deep Feature Compression for High-Speed Visual Tracking</a></li><li>2018-CVPR-<a href=https://arxiv.org/pdf/1711.05908.pdf target=_blank rel=noopener>NISP: Pruning Networks using Neuron Importance Score Propagation</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_CondenseNet_An_Efficient_CVPR_2018_paper.html target=_blank rel=noopener>Condensenet: An efficient densenet using learned group convolutions</a> [<a href=https://github.com/ShichenLiu/CondenseNet target=_blank rel=noopener>Code</a>]</li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Shift_A_Zero_CVPR_2018_paper.html target=_blank rel=noopener>Shift: A zero flop, zero parameter alternative to spatial convolutions</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Explicit_Loss-Error-Aware_Quantization_CVPR_2018_paper.html target=_blank rel=noopener>Explicit Loss-Error-Aware Quantization for Low-Bit Deep Neural Networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Interleaved_Structured_Sparse_CVPR_2018_paper.html target=_blank rel=noopener>Interleaved structured sparse convolutional neural networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhuang_Towards_Effective_Low-Bitwidth_CVPR_2018_paper.pdf target=_blank rel=noopener>Towards Effective Low-bitwidth Convolutional Neural Networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Tung_CLIP-Q_Deep_Network_CVPR_2018_paper.html target=_blank rel=noopener>CLIP-Q: Deep Network Compression Learning by In-Parallel Pruning-Quantization</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_BlockDrop_Dynamic_Inference_CVPR_2018_paper.html target=_blank rel=noopener>Blockdrop: Dynamic inference paths in residual networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_NestedNet_Learning_Nested_CVPR_2018_paper.html target=_blank rel=noopener>Nestednet: Learning nested sparse structures in deep neural networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Kuen_Stochastic_Downsampling_for_CVPR_2018_paper.html target=_blank rel=noopener>Stochastic downsampling for cost-adjustable inference and improved regularization in convolutional networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Wide_Compression_Tensor_CVPR_2018_paper.html target=_blank rel=noopener>Wide Compression: Tensor Ring Nets</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Ye_Learning_Compact_Recurrent_CVPR_2018_paper.html target=_blank rel=noopener>Learning Compact Recurrent Neural Networks With Block-Term Tensor Decomposition</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Veniat_Learning_TimeMemory-Efficient_Deep_CVPR_2018_paper.html target=_blank rel=noopener>Learning Time/Memory-Efficient Deep Architectures With Budgeted Super Networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Mullapudi_HydraNets_Specialized_Dynamic_CVPR_2018_paper.html target=_blank rel=noopener>HydraNets: Specialized Dynamic Architectures for Efficient Inference</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Faraone_SYQ_Learning_Symmetric_CVPR_2018_paper.html target=_blank rel=noopener>SYQ: Learning Symmetric Quantization for Efficient Deep Neural Networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Zhuang_Towards_Effective_Low-Bitwidth_CVPR_2018_paper.html target=_blank rel=noopener>Towards Effective Low-Bitwidth Convolutional Neural Networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Two-Step_Quantization_for_CVPR_2018_paper.html target=_blank rel=noopener>Two-Step Quantization for Low-Bit Neural Networks</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Jacob_Quantization_and_Training_CVPR_2018_paper.html target=_blank rel=noopener>Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/papers/Carreira-Perpinan_Learning-Compression_Algorithms_for_CVPR_2018_paper.pdf target=_blank rel=noopener>&ldquo;Learning-Compression&rdquo; Algorithms for Neural Net Pruning</a></li><li>2018-CVPR-<a href=https://arxiv.org/pdf/1711.05769v2.pdf target=_blank rel=noopener>PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning</a> [<a href=https://github.com/arunmallya/packnet target=_blank rel=noopener>Code</a>]</li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Gordon_MorphNet_Fast__CVPR_2018_paper.html target=_blank rel=noopener>MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks</a> [<a href=https://github.com/google-research/morph-net target=_blank rel=noopener>Code</a>]</li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.html target=_blank rel=noopener>ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</a></li><li>2018-CVPRw-<a href=http://openaccess.thecvf.com/content_cvpr_2018_workshops/w33/html/Gholami_SqueezeNext_Hardware-Aware_Neural_CVPR_2018_paper.html target=_blank rel=noopener>Squeezenext: Hardware-aware neural network design</a></li><li>2018-IJCAI-<a href=https://www.ijcai.org/proceedings/2018/0318.pdf target=_blank rel=noopener>Efficient DNN Neuron Pruning by Minimizing Layer-wise Nonlinear Reconstruction Error</a></li><li>2018-IJCAI-<a href=https://arxiv.org/abs/1808.06866 target=_blank rel=noopener>Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks</a> [<a href=https://github.com/he-y/soft-filter-pruning target=_blank rel=noopener>PyTorch Code</a>]</li><li>2018-IJCAI-<a href=https://www.ijcai.org/proceedings/2018/0445.pdf target=_blank rel=noopener>Where to Prune: Using LSTM to Guide End-to-end Pruning</a></li><li>2018-IJCAI-<a href=https://www.ijcai.org/proceedings/2018/0336.pdf target=_blank rel=noopener>Accelerating Convolutional Networks via Global & Dynamic Filter Pruning</a></li><li>2018-IJCAI-<a href=http://staff.ustc.edu.cn/~chaoqian/ijcai18-olmp.pdf target=_blank rel=noopener>Optimization based Layer-wise Magnitude-based Pruning for DNN Compression</a></li><li>2018-IJCAI-<a href=https://www.ijcai.org/proceedings/2018/0384.pdf target=_blank rel=noopener>Progressive Blockwise Knowledge Distillation for Neural Network Acceleration</a></li><li>2018-IJCAI-<a href=https://www.ijcai.org/proceedings/2018/0292.pdf target=_blank rel=noopener>Complementary Binary Quantization for Joint Multiple Indexing</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/dai18d.html target=_blank rel=noopener>Compressing Neural Networks using the Variational Information Bottleneck</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/qiu18a.html target=_blank rel=noopener>DCFNet: Deep Neural Network with Decomposed Convolutional Filters</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/wu18h.html target=_blank rel=noopener>Deep k-Means Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/wu18d.html target=_blank rel=noopener>Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/zhang18d.html target=_blank rel=noopener>High Performance Zero-Memory Overhead Direct Convolutions</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/jose18a.html target=_blank rel=noopener>Kronecker Recurrent Units</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/reagan18a.html target=_blank rel=noopener>Weightless: Lossy weight encoding for deep neural network compression</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/tschannen18a.html target=_blank rel=noopener>StrassenNets: Deep learning with a multiplication budget</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/oymak18a.html target=_blank rel=noopener>Learning Compact Neural Networks with Regularization</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/jin18d.html target=_blank rel=noopener>WSNet: Compact and Efficient Networks Through Weight Sampling</a></li><li>2018-ICML-<a href=https://arxiv.org/abs/1711.09280 target=_blank rel=noopener>Gradually Updated Neural Networks for Large-Scale Image Recognition</a> [<a href=https://github.com/joe-siyuan-qiao/GUNN target=_blank rel=noopener>Code</a>]</li><li>2018-ICML-<a href=https://arxiv.org/abs/1802.06509 target=_blank rel=noopener>On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization</a></li><li>2018-ICML-<a href=http://proceedings.mlr.press/v80/bender18a.html target=_blank rel=noopener>Understanding and simplifying one-shot architecture search</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Tianyun_Zhang_A_Systematic_DNN_ECCV_2018_paper.pdf target=_blank rel=noopener>A Systematic DNN Weight Pruning Framework using Alternating Direction Method of Multipliers</a> [<a href=https://github.com/KaiqiZhang/admm-pruning target=_blank rel=noopener>Code</a>]</li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Abhimanyu_Dubey_Coreset-Based_Convolutional_Neural_ECCV_2018_paper.pdf target=_blank rel=noopener>Coreset-Based Neural Network Compression</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Zehao_Huang_Data-Driven_Sparse_Structure_ECCV_2018_paper.pdf target=_blank rel=noopener>Data-Driven Sparse Structure Selection for Deep Neural Networks</a> [<a href=https://github.com/TuSimple/sparse-structure-selection target=_blank rel=noopener>MXNet Code</a>]</li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Qinghao_Hu_Training_Binary_Weight_ECCV_2018_paper.html target=_blank rel=noopener>Training Binary Weight Networks via Semi-Binary Decomposition</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Xiangyu_He_Learning_Compression_from_ECCV_2018_paper.html target=_blank rel=noopener>Learning Compression from Limited Unlabeled Data</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Changan_Chen_Constraints_Matter_in_ECCV_2018_paper.html target=_blank rel=noopener>Constraint-Aware Deep Neural Network Compression</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Ligeng_Zhu_Sparsely_Aggregated_Convolutional_ECCV_2018_paper.html target=_blank rel=noopener>Sparsely Aggregated Convolutional Networks</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Ameya_Prabhu_Deep_Expander_Networks_ECCV_2018_paper.html target=_blank rel=noopener>Deep Expander Networks: Efficient Deep Networks from Graph Theory</a> [<a href=https://github.com/DrImpossible/Deep-Expander-Networks target=_blank rel=noopener>Code</a>]</li><li>2018-ECCV-<a href=https://arxiv.org/abs/1801.05895 target=_blank rel=noopener>SparseNet-Sparsely Aggregated Convolutional Networks</a> [<a href=https://github.com/Lyken17/SparseNet target=_blank rel=noopener>Code</a>]</li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Konda_Reddy_Mopuri_Ask_Acquire_and_ECCV_2018_paper.html target=_blank rel=noopener>Ask, acquire, and attack: Data-free uap generation using class impressions</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Tien-Ju_Yang_NetAdapt_Platform-Aware_Neural_ECCV_2018_paper.html target=_blank rel=noopener>Netadapt: Platform-aware neural network adaptation for mobile applications</a></li><li>2018-ECCV-<a href=https://link.springer.com/content/pdf/10.1007%2F978-3-030-01237-3_14.pdf target=_blank rel=noopener>Clustering Convolutional Kernels to Compress Deep Neural Networks</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/zechun_liu_Bi-Real_Net_Enhancing_ECCV_2018_paper.html target=_blank rel=noopener>Bi-Real Net: Enhancing the Performance of 1-bit CNNs With Improved Representational Capability and Advanced Training Algorithm</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Bo_Peng_Extreme_Network_Compression_ECCV_2018_paper.html target=_blank rel=noopener>Extreme Network Compression via Filter Group Approximation</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Andreas_Veit_Convolutional_Networks_with_ECCV_2018_paper.html target=_blank rel=noopener>Convolutional Networks with Adaptive Inference Graphs</a></li><li>2018-ECCV-<a href=https://arxiv.org/abs/1711.09485 target=_blank rel=noopener>SkipNet: Learning Dynamic Routing in Convolutional Networks</a> [<a href=https://github.com/ucbdrive/skipnet target=_blank rel=noopener>Code</a>]</li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Eunhyeok_Park_Value-aware_Quantization_for_ECCV_2018_paper.html target=_blank rel=noopener>Value-aware Quantization for Training and Inference of Neural Networks</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Dongqing_Zhang_Optimized_Quantization_for_ECCV_2018_paper.html target=_blank rel=noopener>LQ-Nets: Learned Quantization for Highly Accurate and Compact Deep Neural Networks</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Yihui_He_AMC_Automated_Model_ECCV_2018_paper.html target=_blank rel=noopener>AMC: AutoML for Model Compression and Acceleration on Mobile Devices</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Arun_Mallya_Piggyback_Adapting_a_ECCV_2018_paper.html target=_blank rel=noopener>Piggyback: Adapting a single network to multiple tasks by learning to mask weights</a></li><li>2018-BMVCo-<a href=http://bmvc2018.org/contents/papers/0870.pdf target=_blank rel=noopener>Structured Probabilistic Pruning for Convolutional Neural Network Acceleration</a></li><li>2018-BMVC-<a href=http://bmvc2018.org/contents/papers/0291.pdf target=_blank rel=noopener>Efficient Progressive Neural Architecture Search</a></li><li>2018-BMVC-<a href=https://arxiv.org/abs/1806.00178 target=_blank rel=noopener>Igcv3: Interleaved lowrank group convolutions for efficient deep neural networks</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7367-discrimination-aware-channel-pruning-for-deep-neural-networks.pdf target=_blank rel=noopener>Discrimination-aware Channel Pruning for Deep Neural Networks</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7382-frequency-domain-dynamic-pruning-for-convolutional-neural-networks.pdf target=_blank rel=noopener>Frequency-Domain Dynamic Pruning for Convolutional Neural Networks</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7766-channelnets-compact-and-efficient-convolutional-neural-networks-via-channel-wise-convolutions.pdf target=_blank rel=noopener>ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/8271-dropblock-a-regularization-method-for-convolutional-networks target=_blank rel=noopener>DropBlock: A regularization method for convolutional networks</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7835-constructing-fast-network-through-deconstruction-of-convolution target=_blank rel=noopener>Constructing fast network through deconstruction of convolution</a></li><li>2018-NIPS-<a href=https://papers.nips.cc/paper/7433-learning-versatile-filters-for-efficient-convolutional-neural-networks target=_blank rel=noopener>Learning Versatile Filters for Efficient Convolutional Neural Networks</a> [<a href=https://github.com/NoahEC/Versatile-Filters target=_blank rel=noopener>Code</a>]</li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7553-moonshine-distilling-with-cheap-convolutions target=_blank rel=noopener>Moonshine: Distilling with cheap convolutions</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7341-hitnet-hybrid-ternary-recurrent-neural-network target=_blank rel=noopener>HitNet: hybrid ternary recurrent neural network</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/8116-fastgrnn-a-fast-accurate-stable-and-tiny-kilobyte-sized-gated-recurrent-neural-network target=_blank rel=noopener>FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7327-training-dnns-with-hybrid-block-floating-point target=_blank rel=noopener>Training DNNs with Hybrid Block Floating Point</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/8117-reversible-recurrent-neural-networks target=_blank rel=noopener>Reversible Recurrent Neural Networks</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/8218-synaptic-strength-for-convolutional-neural-network target=_blank rel=noopener>Synaptic Strength For Convolutional Neural Network</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7644-learning-sparse-neural-networks-via-sensitivity-driven-regularization target=_blank rel=noopener>Learning sparse neural networks via sensitivity-driven regularization</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7841-multi-task-zipping-via-layer-wise-neuron-sharing target=_blank rel=noopener>Multi-Task Zipping via Layer-wise Neuron Sharing</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7519-a-linear-speedup-analysis-of-distributed-deep-learning-with-sparse-and-quantized-communication target=_blank rel=noopener>A Linear Speedup Analysis of Distributed Deep Learning with Sparse and Quantized Communication</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7405-gradient-sparsification-for-communication-efficient-distributed-optimization target=_blank rel=noopener>Gradient Sparsification for Communication-Efficient Distributed Optimization</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7759-gradiveq-vector-quantization-for-bandwidth-efficient-gradient-aggregation-in-distributed-cnn-training target=_blank rel=noopener>GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/8191-atomo-communication-efficient-learning-via-atomic-sparsification target=_blank rel=noopener>ATOMO: Communication-efficient Learning via Atomic Sparsification</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7485-norm-matters-efficient-and-accurate-normalization-schemes-in-deep-networks target=_blank rel=noopener>Norm matters: efficient and accurate normalization schemes in deep networks</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7697-sparsified-sgd-with-memory target=_blank rel=noopener>Sparsified SGD with memory</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7466-pelee-a-real-time-object-detection-system-on-mobile-devices target=_blank rel=noopener>Pelee: A Real-Time Object Detection System on Mobile Devices</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7761-scalable-methods-for-8-bit-training-of-neural-networks target=_blank rel=noopener>Scalable methods for 8-bit training of neural networks</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7666-tetris-tile-matching-the-tremendous-irregular-sparsity target=_blank rel=noopener>TETRIS: TilE-matching the TRemendous Irregular Sparsity</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7994-training-deep-neural-networks-with-8-bit-floating-point-numbers target=_blank rel=noopener>Training deep neural networks with 8-bit floating point numbers</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/8292-multiple-instance-learning-for-efficient-sequential-data-classification-on-resource-constrained-devices target=_blank rel=noopener>Multiple instance learning for efficient sequential data classification on resource-constrained devices</a></li><li>2018-NIPS-<a href=https://papers.nips.cc/paper/2018/hash/4c5bde74a8f110656874902f07378009-Abstract.html target=_blank rel=noopener>Sparse dnns with improved adversarial robustness</a></li><li>2018-NIPSw-<a href="https://openreview.net/forum?id=r1lbgwFj5m" target=_blank rel=noopener>Pruning neural networks: is it time to nip it in the bud?</a></li><li>2018-NIPSw-<a href="https://openreview.net/forum?id=r1eLk2mKiX" target=_blank rel=noopener>Rethinking the Value of Network Pruning</a> [<a href="https://openreview.net/forum?id=rJlnB3C5Ym" target=_blank rel=noopener>2019 ICLR version</a>] [<a href=https://github.com/Eric-mingjie/rethinking-network-pruning target=_blank rel=noopener>PyTorch Code</a>]</li><li>2018-NIPSw-<a href="https://openreview.net/forum?id=S1e_xM7_iQ" target=_blank rel=noopener>Structured Pruning for Efficient ConvNets via Incremental Regularization</a> [<a href=https://arxiv.org/abs/1804.09461 target=_blank rel=noopener>2019 IJCNN version</a>] [<a href=https://github.com/MingSun-Tse/Caffe_IncReg target=_blank rel=noopener>Caffe Code</a>]</li><li>2018-NIPSw-<a href="https://openreview.net/forum?id=B1eHgu-Fim" target=_blank rel=noopener>Adaptive Mixture of Low-Rank Factorizations for Compact Neural Modeling</a></li><li>2018-NIPSw-<a href=https://arxiv.org/abs/1905.13678 target=_blank rel=noopener>Learning Sparse Networks Using Targeted Dropout</a> [<a href="https://openreview.net/forum?id=HkghWScuoQ" target=_blank rel=noopener>OpenReview</a>] [<a href=https://github.com/for-ai/TD target=_blank rel=noopener>Code</a>]</li><li>2018-WACV-<a href=https://arxiv.org/abs/1801.10447 target=_blank rel=noopener>Recovering from Random Pruning: On the Plasticity of Deep Convolutional Neural Networks</a></li><li>2018.05-<a href=https://arxiv.org/abs/1805.08303 target=_blank rel=noopener>Compression of Deep Convolutional Neural Networks under Joint Sparsity Constraints</a></li><li>2018.05-<a href=https://arxiv.org/abs/1805.08941 target=_blank rel=noopener>AutoPruner: An End-to-End Trainable Filter Pruning Method for Efficient Deep Model Inference</a></li><li>2018.10-<a href=https://arxiv.org/abs/1810.04622 target=_blank rel=noopener>A Closer Look at Structured Pruning for Neural Network Compression</a> [<a href=https://github.com/BayesWatch/pytorch-prunes target=_blank rel=noopener>Code</a>]</li><li>2018.11-<a href=https://arxiv.org/abs/1811.12019 target=_blank rel=noopener>Second-order Optimization Method for Large Mini-batch: Training ResNet-50 on ImageNet in 35 Epochs</a></li><li>2018.11-<a href=https://arxiv.org/abs/1811.07083 target=_blank rel=noopener>PydMobileNet: Improved Version of MobileNets with Pyramid Depthwise Separable Convolution</a></li></ul><p><strong>2019</strong></p><ul><li>2019-MLSys-<a href=https://arxiv.org/pdf/1902.01046.pdf target=_blank rel=noopener>Towards Federated Learning at Scale: System Design</a></li><li>2019-MLsys-<a href=https://arxiv.org/abs/1810.00208 target=_blank rel=noopener>To compress or not to compress: Understanding the Interactions between Adversarial Attacks and Neural Network Compression</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=H1gMCsAqY7" target=_blank rel=noopener>Slimmable Neural Networks</a> [<a href=https://github.com/JiahuiYu/slimmable_networks target=_blank rel=noopener>Code</a>]</li><li>2019-ICLR-<a href=https://arxiv.org/abs/1904.08444 target=_blank rel=noopener>Defensive Quantization: When Efficiency Meets Robustness</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=r1f0YiCctm" target=_blank rel=noopener>Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters</a> [<a href=https://github.com/cambridge-mlg/miracle target=_blank rel=noopener>Code</a>]</li><li>2019-ICLR-<a href=https://arxiv.org/abs/1812.00332 target=_blank rel=noopener>ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware</a> [<a href=https://github.com/MIT-HAN-LAB/ProxylessNAS target=_blank rel=noopener>Code</a>]</li><li>2019-ICLR-<a href="https://openreview.net/forum?id=B1VZqjAcYX" target=_blank rel=noopener>SNIP: Single-shot Network Pruning based on Connection Sensitivity</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=BJgqqsAct7" target=_blank rel=noopener>Non-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=BJxh2j0qYm" target=_blank rel=noopener>Dynamic Channel Pruning: Feature Boosting and Suppression</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=BylBr3C9K7" target=_blank rel=noopener>Energy-Constrained Compression for Deep Neural Networks via Weighted Sparse Projection and Layer Input Masking</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=H1gTEj09FX" target=_blank rel=noopener>RotDCF: Decomposition of Convolutional Filters for Rotation-Equivariant Deep Networks</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=H1goBoR9F7" target=_blank rel=noopener>Dynamic Sparse Graph for Efficient Deep Learning</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=HJMHpjC9Ym" target=_blank rel=noopener>Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=HJfwJ2A5KX" target=_blank rel=noopener>Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=HkNGYjR9FX" target=_blank rel=noopener>Learning Recurrent Binary/Ternary Weights</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=HkfYOoCcYX" target=_blank rel=noopener>Double Viterbi: Weight Encoding for High Compression Ratio and Fast On-Chip Reconstruction for Deep Neural Network</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=HkxjYoCqKX" target=_blank rel=noopener>Relaxed Quantization for Discretized Neural Networks</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=S1zz2i0cY7" target=_blank rel=noopener>Integer Networks for Data Compression with Latent-Variable Models</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=r1f0YiCctm" target=_blank rel=noopener>Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=ryM_IoAqYX" target=_blank rel=noopener>Analysis of Quantized Models</a></li><li>2019-ICLR-<a href=https://arxiv.org/abs/1806.09055 target=_blank rel=noopener>DARTS: Differentiable Architecture Search</a> [<a href=https://github.com/quark0/darts target=_blank rel=noopener>Code</a>]</li><li>2019-ICLR-<a href=https://arxiv.org/abs/1810.05749 target=_blank rel=noopener>Graph HyperNetworks for Neural Architecture Search</a></li><li>2019-ICLR-<a href="https://openreview.net/forum?id=S1xLN3C9YX" target=_blank rel=noopener>Learnable Embedding Space for Efficient Neural Architecture Compression</a> [<a href=https://github.com/Friedrich1006/ESNAC target=_blank rel=noopener>Code</a>]</li><li>2019-ICLR-<a href=https://arxiv.org/abs/1804.09081 target=_blank rel=noopener>Efficient Multi-Objective Neural Architecture Search via Lamarckian Evolution</a></li><li>2019-ICLR-<a href="https://openreview.net/pdf?id=rylqooRqK7" target=_blank rel=noopener>SNAS: stochastic neural architecture search</a></li><li>2019-AAAIo-<a href=https://arxiv.org/abs/1812.06611 target=_blank rel=noopener>A layer decomposition-recomposition framework for neuron pruning towards accurate lightweight networks</a></li><li>2019-AAAI-<a href=https://arxiv.org/abs/1811.00206 target=_blank rel=noopener>Balanced Sparsity for Efficient DNN Inference on GPU</a> [<a href=https://github.com/Howal/balanced-sparsity target=_blank rel=noopener>Code</a>]</li><li>2019-AAAI-<a href=https://arxiv.org/abs/1902.11268 target=_blank rel=noopener>CircConv: A Structured Convolution with Low Complexity</a></li><li>2019-AAAI-<a href=https://arxiv.org/pdf/1802.01548.pdf target=_blank rel=noopener>Regularized Evolution for Image Classifier Architecture Search</a></li><li>2019-AAAI-<a href=https://www.aaai.org/ojs/index.php/AAAI/article/view/4475 target=_blank rel=noopener>Universal Approximation Property and Equivalence of Stochastic Computing-Based Neural Networks and Binary Neural Networks</a></li><li>2019-WACV-<a href=https://arxiv.org/abs/1812.08374 target=_blank rel=noopener>DAC: Data-free Automatic Acceleration of Convolutional Networks</a></li><li>2019-ASPLOS-<a href=https://arxiv.org/abs/1811.04770 target=_blank rel=noopener>Packing Sparse Convolutional Neural Networks for Efficient Systolic Array Implementations: Column Combining Under Joint Optimization</a></li><li>2019-CVPRo-<a href=https://arxiv.org/pdf/1811.08886.pdf target=_blank rel=noopener>HAQ: hardware-aware automated quantization</a></li><li>2019-CVPRo-<a href=https://arxiv.org/abs/1811.00250 target=_blank rel=noopener>Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration</a> [<a href=https://github.com/he-y/filter-pruning-geometric-median target=_blank rel=noopener>Code</a>]</li><li>2019-CVPR-<a href=https://arxiv.org/abs/1903.05285 target=_blank rel=noopener>All You Need is a Few Shifts: Designing Efficient Convolutional Neural Networks for Image Classification</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Molchanov_Importance_Estimation_for_Neural_Network_Pruning_CVPR_2019_paper.html target=_blank rel=noopener>Importance Estimation for Neural Network Pruning</a> [<a href=https://github.com/NVlabs/Taylor_pruning target=_blank rel=noopener>Code</a>]</li><li>2019-CVPR-<a href=https://arxiv.org/abs/1903.04120 target=_blank rel=noopener>HetConv Heterogeneous Kernel-Based Convolutions for Deep CNNs</a></li><li>2019-CVPR-<a href=https://arxiv.org/abs/1904.00346 target=_blank rel=noopener>Fully Learnable Group Convolution for Acceleration of Deep Neural Networks</a></li><li>2019-CVPR-<a href=https://arxiv.org/abs/1903.09291 target=_blank rel=noopener>Towards Optimal Structured CNN Pruning via Generative Adversarial Learning</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/papers/Dai_ChamNet_Towards_Efficient_Network_Design_Through_Platform-Aware_Model_Adaptation_CVPR_2019_paper.pdf target=_blank rel=noopener>ChamNet: Towards Efficient Network Design through Platform-Aware Model Adaptation</a></li><li>2019-CVPR-<a href=https://arxiv.org/pdf/1903.03777.pdf target=_blank rel=noopener>Partial Order Pruning: for Best Speed/Accuracy Trade-off in Neural Architecture Search</a> [<a href=https://github.com/lixincn2015/Partial-Order-Pruning target=_blank rel=noopener>Code</a>]</li><li>2019-CVPR-<a href=https://arxiv.org/pdf/1901.02985.pdf target=_blank rel=noopener>Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation</a> [<a href=https://github.com/tensorflow/models/tree/master/research/deeplab target=_blank rel=noopener>Code</a>]</li><li>2019-CVPR-<a href=https://arxiv.org/abs/1807.11626 target=_blank rel=noopener>MnasNet: Platform-Aware Neural Architecture Search for Mobile</a> [<a href=https://github.com/AnjieZheng/MnasNet-PyTorch target=_blank rel=noopener>Code</a>]</li><li>2019-CVPR-<a href=https://arxiv.org/pdf/1903.06496.pdf target=_blank rel=noopener>MFAS: Multimodal Fusion Architecture Search</a></li><li>2019-CVPR-<a href=https://arxiv.org/pdf/1805.10726.pdf target=_blank rel=noopener>A Neurobiological Evaluation Metric for Neural Network Model Search</a></li><li>2019-CVPR-<a href=https://arxiv.org/abs/1810.10804 target=_blank rel=noopener>Fast Neural Architecture Search of Compact Semantic Segmentation Models via Auxiliary Cells</a></li><li>2019-CVPR-<a href=https://arxiv.org/abs/1811.12781 target=_blank rel=noopener>Efficient Neural Network Compression</a> [<a href=https://github.com/Hyeji-Kim/ENC target=_blank rel=noopener>Code</a>]</li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Kossaifi_T-Net_Parametrizing_Fully_Convolutional_Nets_With_a_Single_High-Order_Tensor_CVPR_2019_paper.html target=_blank rel=noopener>T-Net: Parametrizing Fully Convolutional Nets with a Single High-Order Tensor</a></li><li>2019-CVPR-<a href=https://arxiv.org/abs/1904.03837 target=_blank rel=noopener>Centripetal SGD for Pruning Very Deep Convolutional Networks with Complicated Structure</a> [<a href=https://github.com/ShawnDing1994/Centripetal-SGD target=_blank rel=noopener>Code</a>]</li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPRW_2019/html/SAIAD/Frickenstein_DSC_Dense-Sparse_Convolution_for_Vectorized_Inference_of_Convolutional_Neural_Networks_CVPRW_2019_paper.html target=_blank rel=noopener>DSC: Dense-Sparse Convolution for Vectorized Inference of Convolutional Neural Networks</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPRW_2019/html/EVW/Gao_DupNet_Towards_Very_Tiny_Quantized_CNN_With_Improved_Accuracy_for_CVPRW_2019_paper.html target=_blank rel=noopener>DupNet: Towards Very Tiny Quantized CNN With Improved Accuracy for Face Detection</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_ECC_Platform-Independent_Energy-Constrained_Deep_Neural_Network_Compression_via_a_Bilinear_CVPR_2019_paper.html target=_blank rel=noopener>ECC: Platform-Independent Energy-Constrained Deep Neural Network Compression via a Bilinear Regression Model</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Variational_Convolutional_Neural_Network_Pruning_CVPR_2019_paper.html target=_blank rel=noopener>Variational Convolutional Neural Network Pruning</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Georgiadis_Accelerating_Convolutional_Neural_Networks_via_Activation_Map_Compression_CVPR_2019_paper.html target=_blank rel=noopener>Accelerating Convolutional Neural Networks via Activation Map Compression</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Compressing_Convolutional_Neural_Networks_via_Factorized_Convolutional_Filters_CVPR_2019_paper.html target=_blank rel=noopener>Compressing Convolutional Neural Networks via Factorized Convolutional Filters</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Virtual_Networks_for_Memory_Efficient_Inference_of_Multiple_Tasks_CVPR_2019_paper.html target=_blank rel=noopener>Deep Virtual Networks for Memory Efficient Inference of Multiple Tasks</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Exploiting_Kernel_Sparsity_and_Entropy_for_Interpretable_CNN_Compression_CVPR_2019_paper.html target=_blank rel=noopener>Exploiting Kernel Sparsity and Entropy for Interpretable CNN Compression</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Lin_MBS_Macroblock_Scaling_for_CNN_Model_Reduction_CVPR_2019_paper.html target=_blank rel=noopener>MBS: Macroblock Scaling for CNN Model Reduction</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Mehta_On_Implicit_Filter_Level_Sparsity_in_Convolutional_Neural_Networks_CVPR_2019_paper.html target=_blank rel=noopener>On Implicit Filter Level Sparsity in Convolutional Neural Networks</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Lemaire_Structured_Pruning_of_Neural_Networks_With_Budget-Aware_Regularization_CVPR_2019_paper.html target=_blank rel=noopener>Structured Pruning of Neural Networks With Budget-Aware Regularization</a></li><li>2019-CVPRo-<a href=https://arxiv.org/abs/1812.00481 target=_blank rel=noopener>Neural Rejuvenation: Improving Deep Network Training by Enhancing Computational Resource Utilization</a> [<a href=https://github.com/joe-siyuan-qiao/NeuralRejuvenation-CVPR19 target=_blank rel=noopener>Code</a>]</li><li>2019-ICML-<a href=https://arxiv.org/abs/1905.04748 target=_blank rel=noopener>Approximated Oracle Filter Pruning for Destructive CNN Width Optimization</a> [<a href=https://github.com/ShawnDing1994/AOFP target=_blank rel=noopener>Code</a>]</li><li>2019-ICML-<a href=https://arxiv.org/abs/1905.05934 target=_blank rel=noopener>EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis</a> [<a href=https://github.com/alecwangcq/EigenDamage-Pytorch target=_blank rel=noopener>PyTorch Code</a>]</li><li>2019-ICML-<a href=https://arxiv.org/abs/1905.08114 target=_blank rel=noopener>Zero-Shot Knowledge Distillation in Deep Networks</a> [<a href=https://github.com/vcl-iisc/ZSKD target=_blank rel=noopener>Code</a>]</li><li>2019-ICML-<a href=http://proceedings.mlr.press/v97/yang19c.html target=_blank rel=noopener>LegoNet: Efficient Convolutional Neural Networks with Lego Filters</a> [<a href=https://github.com/zhaohui-yang/LegoNet_pytorch target=_blank rel=noopener>Code</a>]</li><li>2019-ICML-<a href=https://arxiv.org/abs/1905.11946 target=_blank rel=noopener>EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a> [<a href=https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet target=_blank rel=noopener>Code</a>]</li><li>2019-ICML-<a href=http://proceedings.mlr.press/v97/peng19c.html target=_blank rel=noopener>Collaborative Channel Pruning for Deep Networks</a></li><li>2019-ICML-<a href=http://proceedings.mlr.press/v97/jeong19c.html target=_blank rel=noopener>Training CNNs with Selective Allocation of Channels</a></li><li>2019-ICML-<a href=https://arxiv.org/abs/1902.09635 target=_blank rel=noopener>NAS-Bench-101: Towards Reproducible Neural Architecture Search</a> [<a href=https://github.com/google-research/nasbench target=_blank rel=noopener>Code</a>]</li><li>2019-ICML-<a href=https://arxiv.org/abs/1903.05895 target=_blank rel=noopener>Learning fast algorithms for linear transforms using butterfly factorizations</a></li><li>2019-ICMLw-<a href=https://arxiv.org/abs/1904.09872 target=_blank rel=noopener>Towards Learning of Filter-Level Heterogeneous Compression of Convolutional Neural Networks</a> [<a href=https://github.com/yochaiz/Slimmable target=_blank rel=noopener>Code</a>] (AutoML workshop)</li><li>2019-IJCAI-<a href=https://arxiv.org/abs/1905.04446 target=_blank rel=noopener>Play and Prune: Adaptive Filter Pruning for Deep Model Compression</a></li><li>2019-BigComp-<a href=https://ieeexplore.ieee.org/abstract/document/8679132 target=_blank rel=noopener>Towards Robust Compressed Convolutional Neural Networks</a></li><li>2019-ICCV-<a href=https://arxiv.org/abs/1811.08883 target=_blank rel=noopener>Rethinking ImageNet Pre-training</a></li><li>2019-ICCV-<a href=https://arxiv.org/abs/1903.05134 target=_blank rel=noopener>Universally Slimmable Networks and Improved Training Techniques</a></li><li>2019-ICCV-<a href=https://arxiv.org/abs/1903.10258 target=_blank rel=noopener>MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning</a> [<a href=https://github.com/liuzechun/MetaPruning target=_blank rel=noopener>Code</a>]</li><li>2019-ICCV-<a href=https://arxiv.org/abs/1904.12760 target=_blank rel=noopener>Progressive Differentiable Architecture Search: Bridging the Depth Gap between Search and Evaluation</a> [<a href=https://github.com/chenxin061/pdarts target=_blank rel=noopener>Code</a>]</li><li>2019-ICCV-<a href=https://arxiv.org/abs/1906.04721 target=_blank rel=noopener>Data-Free Quantization through Weight Equalization and Bias Correction</a></li><li>2019-ICCV-<a href=https://arxiv.org/abs/1908.03930 target=_blank rel=noopener>ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks</a></li><li>2019-ICCV-<a href=https://openaccess.thecvf.com/content_ICCV_2019/papers/Ye_Adversarial_Robustness_vs._Model_Compression_or_Both_ICCV_2019_paper.pdf target=_blank rel=noopener>Adversarial Robustness vs. Model Compression, or Both?</a> [<a href=https://github.com/yeshaokai/Robustness-Aware-Pruning-ADMM target=_blank rel=noopener>PyTorch Code</a>]</li><li>2019-NIPS-<a href=https://arxiv.org/abs/1909.12778 target=_blank rel=noopener>Global Sparse Momentum SGD for Pruning Very Deep Neural Networks</a></li><li>2019-NIPS-<a href=http://papers.nips.cc/paper/8410-model-compression-with-adversarial-robustness-a-unified-optimization-framework target=_blank rel=noopener>Model Compression with Adversarial Robustness: A Unified Optimization Framework</a></li><li>2019-NIPS-<a href="https://nips.cc/Conferences/2019/Schedule?showEvent=14303" target=_blank rel=noopener>AutoPrune: Automatic Network Pruning by Regularizing Auxiliary Parameters</a></li><li>2019-NIPS-<a href="https://nips.cc/Conferences/2019/Schedule?showEvent=13598" target=_blank rel=noopener>Double Quantization for Communication-Efficient Distributed Optimization</a></li><li>2019-NIPS-<a href="https://nips.cc/Conferences/2019/Schedule?showEvent=13686" target=_blank rel=noopener>Focused Quantization for Sparse CNNs</a></li><li>2019-NIPS-<a href=http://papers.nips.cc/paper/8757-e2-train-training-state-of-the-art-cnns-with-over-80-less-energy target=_blank rel=noopener>E2-Train: Training State-of-the-art CNNs with Over 80% Energy Savings</a></li><li>2019-NIPS-<a href=https://papers.nips.cc/paper/8647-metaquant-learning-to-quantize-by-learning-to-penetrate-non-differentiable-quantization target=_blank rel=noopener>MetaQuant: Learning to Quantize by Learning to Penetrate Non-differentiable Quantization</a></li><li>2019-NIPS-<a href=https://papers.nips.cc/paper/9268-random-projections-with-asymmetric-quantization target=_blank rel=noopener>Random Projections with Asymmetric Quantization</a></li><li>2019-NIPS-<a href=https://arxiv.org/abs/1905.09717 target=_blank rel=noopener>Network Pruning via Transformable Architecture Search</a> [<a href=https://github.com/D-X-Y/TAS target=_blank rel=noopener>Code</a>]</li><li>2019-NIPS-<a href=http://papers.nips.cc/paper/8382-point-voxel-cnn-for-efficient-3d-deep-learning target=_blank rel=noopener>Point-Voxel CNN for Efficient 3D Deep Learning</a> [<a href=https://github.com/mit-han-lab/pvcnn target=_blank rel=noopener>Code</a>]</li><li>2019-NIPS-<a href=https://arxiv.org/abs/1909.08174 target=_blank rel=noopener>Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks</a> [<a href=https://github.com/youzhonghui/gate-decorator-pruning target=_blank rel=noopener>PyTorch Code</a>]</li><li>2019-NIPS-<a href=https://papers.nips.cc/paper/8926-a-mean-field-theory-of-quantized-deep-networks-the-quantization-depth-trade-off target=_blank rel=noopener>A Mean Field Theory of Quantized Deep Networks: The Quantization-Depth Trade-Off</a></li><li>2019-NIPS-<a href=https://papers.nips.cc/paper/9610-qsparse-local-sgd-distributed-sgd-with-quantization-sparsification-and-local-computations target=_blank rel=noopener>Qsparse-local-SGD: Distributed SGD with Quantization, Sparsification and Local Computations</a></li><li>2019-NIPS-<a href=https://papers.nips.cc/paper/9008-post-training-4-bit-quantization-of-convolutional-networks-for-rapid-deployment target=_blank rel=noopener>Post training 4-bit quantization of convolutional networks for rapid-deployment</a></li><li>2019-PR-<a href=https://www.sciencedirect.com/science/article/abs/pii/S0031320319300640 target=_blank rel=noopener>Filter-in-Filter: Improve CNNs in a Low-cost Way by Sharing Parameters among the Sub-filters of a Filter</a></li><li>2019-PRL-<a href=https://www.sciencedirect.com/science/article/abs/pii/S0167865519301096 target=_blank rel=noopener>BDNN: Binary Convolution Neural Networks for Fast Object Detection</a></li><li>2019-TNNLS-<a href=https://arxiv.org/abs/1901.07827 target=_blank rel=noopener>Towards Compact ConvNets via Structure-Sparsity Regularized Filter Pruning</a> [<a href=https://github.com/ShaohuiLin/SSR target=_blank rel=noopener>Code</a>]</li><li>2019.03-<a href=https://arxiv.org/abs/1903.11728 target=_blank rel=noopener>Network Slimming by Slimmable Networks: Towards One-Shot Architecture Search for Channel Numbers</a> [<a href=https://github.com/JiahuiYu/slimmable_networks target=_blank rel=noopener>Code</a>]</li><li>2019.03-<a href=https://arxiv.org/abs/1904.00420 target=_blank rel=noopener>Single Path One-Shot Neural Architecture Search with Uniform Sampling</a></li><li>2019.04-<a href=https://arxiv.org/abs/1904.02422 target=_blank rel=noopener>Resource Efficient 3D Convolutional Neural Networks</a></li><li>2019.04-<a href=https://arxiv.org/abs/1904.03961 target=_blank rel=noopener>Meta Filter Pruning to Accelerate Deep Convolutional Neural Networks</a></li><li>2019.04-<a href=https://arxiv.org/abs/1904.05100 target=_blank rel=noopener>Knowledge Squeezed Adversarial Network Compression</a></li><li>2019.05-<a href=https://arxiv.org/abs/1905.06435 target=_blank rel=noopener>Dynamic Neural Network Channel Execution for Efficient Training</a></li><li>2019.06-<a href=https://arxiv.org/abs/1906.02909 target=_blank rel=noopener>AutoGrow: Automatic Layer Growing in Deep Convolutional Networks</a></li><li>2019.06-<a href=https://arxiv.org/abs/1906.04509 target=_blank rel=noopener>BasisConv: A method for compressed representation and learning in CNNs</a></li><li>2019.06-<a href=https://arxiv.org/abs/1906.04113 target=_blank rel=noopener>BlockSwap: Fisher-guided Block Substitution for Network Compression</a></li><li>2019.06-<a href=https://arxiv.org/abs/1906.00859 target=_blank rel=noopener>Separable Layers Enable Structured Efficient Linear Substitutions</a> [<a href=https://github.com/BayesWatch/deficient-efficient target=_blank rel=noopener>Code</a>]</li><li>2019.06-<a href=https://arxiv.org/abs/1906.02256 target=_blank rel=noopener>Butterfly Transform: An Efficient FFT Based Neural Architecture Design</a></li><li>2019.06-<a href=https://arxiv.org/abs/1906.04675 target=_blank rel=noopener>A Taxonomy of Channel Pruning Signals in CNNs</a></li><li>2019.08-<a href=https://arxiv.org/abs/1908.04355 target=_blank rel=noopener>Adversarial Neural Pruning with Latent Vulnerability Suppression</a></li><li>2019.09-<a href=https://arxiv.org/abs/1909.13063 target=_blank rel=noopener>Training convolutional neural networks with cheap convolutions and online distillation</a></li><li>2019.09-<a href=https://arxiv.org/abs/1909.12579 target=_blank rel=noopener>Pruning from Scratch</a></li><li>2019.11-<a href="https://openreview.net/forum?id=Syejj0NYvr" target=_blank rel=noopener>Adversarial Interpolation Training: A Simple Approach for Improving Model Robustness</a></li><li>2019.11-<a href=https://arxiv.org/abs/1911.02497 target=_blank rel=noopener>A Programmable Approach to Model Compression</a> [<a href=https://github.com/NVlabs/condensa target=_blank rel=noopener>Code</a>]</li></ul><p><strong>2020</strong></p><ul><li>2020-AAAI-<a href=https://arxiv.org/abs/1909.05073 target=_blank rel=noopener>Pconv: The missing but desirable sparsity in dnn weight pruning for real-time execution on mobile devices</a></li><li>2020-AAAI-<a href=https://arxiv.org/abs/2003.06757 target=_blank rel=noopener>Channel Pruning Guided by Classification Loss and Feature Importance</a></li><li>2020-AAAI-<a href="https://arxiv.org/abs/1909.12579?context=cs.CV" target=_blank rel=noopener>Pruning from Scratch</a></li><li>2020-AAAI-<a href=https://aaai.org/Papers/AAAI/2020GB/AAAI-YangL.9289.pdf target=_blank rel=noopener>Harmonious Coexistence of Structured Weight Pruning and Ternarization for Deep Neural Networks</a></li><li>2020-AAAI-<a href=https://arxiv.org/abs/1907.03141 target=_blank rel=noopener>AutoCompress: An Automatic DNN Structured Pruning Framework for Ultra-High Compression Rates</a></li><li>2020-AAAI-<a href=https://arxiv.org/abs/1911.08020 target=_blank rel=noopener>DARB: A Density-Adaptive Regular-Block Pruning for Deep Neural Networks</a></li><li>2020-AAAI-<a href=https://arxiv.org/abs/1911.11170 target=_blank rel=noopener>Real-Time Object Tracking via Meta-Learning: Efficient Model Adaptation and One-Shot Channel Pruning</a></li><li>2020-AAAI-<a href=https://aaai.org/ojs/index.php/AAAI/article/view/6098 target=_blank rel=noopener>Dynamic Network Pruning with Interpretable Layerwise Channel Selection</a></li><li>2020-AAAI-<a href=https://www.aaai.org/Papers/AAAI/2020GB/AAAI-TangY.1279.pdf target=_blank rel=noopener>Reborn Filters: Pruning Convolutional Neural Networks with Limited Data</a></li><li>2020-AAAI-<a href=https://aaai.org/ojs/index.php/AAAI/article/view/5927 target=_blank rel=noopener>Layerwise Sparse Coding for Pruned Deep Neural Networks with Extreme Compression Ratio</a></li><li>2020-AAAI-<a href=https://www.aaai.org/Papers/AAAI/2020GB/AAAI-WangP.1440.pdf target=_blank rel=noopener>Sparsity-inducing Binarized Neural Networks</a></li><li>2020-AAAI-<a href=https://www.aaai.org/Papers/AAAI/2020GB/AAAI-LobachevaE.8844.pdf target=_blank rel=noopener>Structured Sparsification of Gated Recurrent Neural Networks</a></li><li>2020-AAAI-<a href=https://www.aaai.org/Papers/AAAI/2020GB/AAAI-LiP.697.pdf target=_blank rel=noopener>Hierarchical Knowledge Squeezed Adversarial Network Compression</a></li><li>2020-AAAI-<a href=https://arxiv.org/abs/2001.05314 target=_blank rel=noopener>Embedding Compression with Isotropic Iterative Quantization</a></li><li>2020-ICLR-<a href="https://openreview.net/forum?id=S1gSj0NKvB" target=_blank rel=noopener>Comparing Rewinding and Fine-tuning in Neural Network Pruning</a> [<a href=https://github.com/lottery-ticket/rewinding-iclr20-public target=_blank rel=noopener>Code</a>]</li><li>2020-ICLR-<a href="https://openreview.net/forum?id=ryl3ygHYDB" target=_blank rel=noopener>Lookahead: A Far-sighted Alternative of Magnitude-based Pruning</a> [<a href=https://github.com/alinlab/lookahead_pruning target=_blank rel=noopener>Code</a>]</li><li>2020-ICLR-<a href="https://openreview.net/pdf?id=SJem8lSFwB" target=_blank rel=noopener>Dynamic Model Pruning with Feedback</a></li><li>2020-ICLR-<a href="https://openreview.net/forum?id=BJxkOlSYDH" target=_blank rel=noopener>Provable Filter Pruning for Efficient Neural Networks</a></li><li>2020-ICLR-<a href="https://openreview.net/forum?id=H1gmHaEKwB" target=_blank rel=noopener>Data-Independent Neural Pruning via Coresets</a></li><li>2020-ICLR-<a href="https://openreview.net/forum?id=S1xtORNFwH" target=_blank rel=noopener>FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary</a></li><li>2020-ICLR-<a href="https://openreview.net/forum?id=HJgCF0VFwr" target=_blank rel=noopener>Probabilistic Connection Importance Inference and Lossless Compression of Deep Neural Networks</a></li><li>2020-ICLR-<a href="https://openreview.net/forum?id=HyxjOyrKvr" target=_blank rel=noopener>Neural Epitome Search for Architecture-Agnostic Network Compression</a></li><li>2020-ICLR-<a href="https://openreview.net/forum?id=r1e9GCNKvH" target=_blank rel=noopener>One-Shot Pruning of Recurrent Neural Networks by Jacobian Spectrum Evaluation</a></li><li>2020-ICLR-<a href="https://openreview.net/forum?id=rylBK34FDS" target=_blank rel=noopener>DeepHoyer: Learning Sparser Neural Network with Differentiable Scale-Invariant Sparsity Measures</a> [<a href=https://github.com/yanghr/DeepHoyer target=_blank rel=noopener>Code</a>]</li><li>2020-ICLR-<a href="https://openreview.net/forum?id=SJlbGJrtDB" target=_blank rel=noopener>Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With Trainable Masked Layers</a></li><li>2020-ICLR-<a href="https://openreview.net/forum?id=HkgxW0EYDS" target=_blank rel=noopener>Scalable Model Compression by Entropy Penalized Reparameterization</a></li><li>2020-ICLR-<a href=https://arxiv.org/abs/1906.06307 target=_blank rel=noopener>A Signal Propagation Perspective for Pruning Neural Networks at Initialization</a></li><li>2020-CVPR-<a href=https://arxiv.org/abs/1911.11907 target=_blank rel=noopener>GhostNet: More Features from Cheap Operations</a> [<a href=https://github.com/huawei-noah/ghostnet target=_blank rel=noopener>Code</a>]</li><li>2020-CVPR-<a href=https://arxiv.org/pdf/2001.05868.pdf target=_blank rel=noopener>Filter Grafting for Deep Neural Networks</a></li><li>2020-CVPR-<a href=http://graduatestudent.ucmerced.edu/yidelbayev/papers/cvpr20/cvpr20a.pdf target=_blank rel=noopener>Low-rank Compression of Neural Nets: Learning the Rank of Each Layer</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Kwon_Structured_Compression_by_Weight_Encryption_for_Unstructured_Pruning_and_Quantization_CVPR_2020_paper.pdf target=_blank rel=noopener>Structured Compression by Weight Encryption for Unstructured Pruning and Quantization</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Learning_Filter_Pruning_Criteria_for_Deep_Convolutional_Neural_Networks_Acceleration_CVPR_2020_paper.pdf target=_blank rel=noopener>Learning Filter Pruning Criteria for Deep Convolutional Neural Networks Acceleration</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_APQ_Joint_Search_for_Network_Architecture_Pruning_and_Quantization_Policy_CVPR_2020_paper.pdf target=_blank rel=noopener>APQ: Joint Search for Network Architecture, Pruning and Quantization Policy</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Group_Sparsity_The_Hinge_Between_Filter_Pruning_and_Decomposition_for_CVPR_2020_paper.pdf target=_blank rel=noopener>Group Sparsity: The Hinge Between Filter Pruning and Decomposition for Network Compression</a> [<a href=https://github.com/ofsoundof/group_sparsity target=_blank rel=noopener>Code</a>]</li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Luo_Neural_Network_Pruning_With_Residual-Connections_and_Limited-Data_CVPR_2020_paper.pdf target=_blank rel=noopener>Neural Network Pruning With Residual-Connections and Limited-Data</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_Multi-Dimensional_Pruning_A_Unified_Framework_for_Model_Compression_CVPR_2020_paper.pdf target=_blank rel=noopener>Multi-Dimensional Pruning: A Unified Framework for Model Compression</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Gao_Discrete_Model_Compression_With_Resource_Constraint_for_Deep_Neural_Networks_CVPR_2020_paper.pdf target=_blank rel=noopener>Discrete Model Compression With Resource Constraint for Deep Neural Networks</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Automatic_Neural_Network_Compression_by_Sparsity-Quantization_Joint_Learning_A_Constrained_CVPR_2020_paper.pdf target=_blank rel=noopener>Automatic Neural Network Compression by Sparsity-Quantization Joint Learning: A Constrained Optimization-Based Approach</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Idelbayev_Low-Rank_Compression_of_Neural_Nets_Learning_the_Rank_of_Each_CVPR_2020_paper.pdf target=_blank rel=noopener>Low-Rank Compression of Neural Nets: Learning the Rank of Each Layer</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Haroush_The_Knowledge_Within_Methods_for_Data-Free_Model_Compression_CVPR_2020_paper.pdf target=_blank rel=noopener>The Knowledge Within: Methods for Data-Free Model Compression</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_GAN_Compression_Efficient_Architectures_for_Interactive_Conditional_GANs_CVPR_2020_paper.pdf target=_blank rel=noopener>GAN Compression: Efficient Architectures for Interactive Conditional GANs</a> [<a href=https://github.com/mit-han-lab/gan-compression target=_blank rel=noopener>Code</a>]</li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Few_Sample_Knowledge_Distillation_for_Efficient_Network_Compression_CVPR_2020_paper.pdf target=_blank rel=noopener>Few Sample Knowledge Distillation for Efficient Network Compression</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/html/Elsen_Fast_Sparse_ConvNets_CVPR_2020_paper.html target=_blank rel=noopener>Fast sparse convnets</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Eban_Structured_Multi-Hashing_for_Model_Compression_CVPR_2020_paper.pdf target=_blank rel=noopener>Structured Multi-Hashing for Model Compression</a></li><li>2020-CVPRo-<a href=https://arxiv.org/abs/1912.13200 target=_blank rel=noopener>AdderNet: Do We Really Need Multiplications in Deep Learning?</a> [<a href=https://github.com/huawei-noah/AdderNet target=_blank rel=noopener>Code</a>]</li><li>2020-CVPRo-<a href=https://arxiv.org/abs/1904.12368 target=_blank rel=noopener>Towards Efficient Model Compression via Learned Global Ranking</a> [<a href=https://github.com/cmu-enyac/LeGR target=_blank rel=noopener>Code</a>]</li><li>2020-CVPRo-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Lin_HRank_Filter_Pruning_Using_High-Rank_Feature_Map_CVPR_2020_paper.pdf target=_blank rel=noopener>HRank: Filter Pruning Using High-Rank Feature Map</a> [<a href=https://github.com/lmbxmu/HRank target=_blank rel=noopener>Code</a>]</li><li>2020-CVPRo-<a href=https://openaccess.thecvf.com/content_CVPR_2020/html/Zhou_DaST_Data-Free_Substitute_Training_for_Adversarial_Attacks_CVPR_2020_paper.html target=_blank rel=noopener>DaST: Data-free Substitute Training for Adversarial Attacks</a> [<a href=https://github.com/zhoumingyi/DaST target=_blank rel=noopener>Code</a>]</li><li>2020-ICML-<a href=https://arxiv.org/abs/2005.07133 target=_blank rel=noopener>PENNI: Pruned Kernel Sharing for Efficient CNN Inference</a> [<a href=https://github.com/timlee0212/PENNI target=_blank rel=noopener>Code</a>]</li><li>2020-ICML-<a href=https://arxiv.org/abs/2007.03938 target=_blank rel=noopener>Operation-Aware Soft Channel Pruning using Differentiable Masks</a></li><li>2020-ICML-<a href=https://proceedings.icml.cc/static/paper_files/icml/2020/2026-Paper.pdf target=_blank rel=noopener>DropNet: Reducing Neural Network Complexity via Iterative Pruning</a></li><li>2020-ICML-<a href=https://arxiv.org/abs/2003.01794 target=_blank rel=noopener>Network Pruning by Greedy Subnetwork Selection</a></li><li>2020-ICML-<a href=https://arxiv.org/abs/2006.08198 target=_blank rel=noopener>AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks</a></li><li>2020-ICML-<a href=https://arxiv.org/abs/2002.03231 target=_blank rel=noopener>Soft Threshold Weight Reparameterization for Learnable Sparsity</a> [<a href=https://github.com/RAIVNLab/STR target=_blank rel=noopener>PyTorch Code</a>]</li><li>2020-ICML-<a href=http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf target=_blank rel=noopener>Activation sparsity: Inducing and exploiting activation sparsity for fast inference on deep neural networks</a></li><li>2020-EMNLP-<a href=https://arxiv.org/abs/1910.04732 target=_blank rel=noopener>Structured Pruning of Large Language Models</a> [<a href=https://github.com/asappresearch/flop target=_blank rel=noopener>Code</a>]</li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/46a4378f835dc8040c8057beb6a2da52-Abstract.html target=_blank rel=noopener>Pruning neural networks without any data by iteratively conserving synaptic flow</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/703957b6dd9e3a7980e040bee50ded65-Abstract.html target=_blank rel=noopener>Neuron-level Structured Pruning using Polarization Regularizer</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/7bcdf75ad237b8e02e301f4091fb6bc8-Abstract.html target=_blank rel=noopener>SCOP: Scientific Control for Reliable Neural Network Pruning</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/a09e75c5c86a7bf6582d2b4d75aad615-Abstract.html target=_blank rel=noopener>Directional Pruning of Deep Neural Networks</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/a914ecef9c12ffdb9bede64bb703d877-Abstract.html target=_blank rel=noopener>Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/ccb1d45fb76f7c5a0bf619f979c6cf36-Abstract.html target=_blank rel=noopener>Pruning Filter in Filter</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/e3a72c791a69f87b05ea7742e04430ed-Abstract.html target=_blank rel=noopener>HYDRA: Pruning Adversarially Robust Neural Networks</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/eae15aabaa768ae4a5993a8a4f4fa6e4-Abstract.html target=_blank rel=noopener>Movement Pruning: Adaptive Sparsity by Fine-Tuning</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/eae27d77ca20db309e056e3d2dcd7d69-Abstract.html target=_blank rel=noopener>Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/eb1e78328c46506b46a4ac4a1e378b91-Abstract.html target=_blank rel=noopener>Position-based Scaled Gradient for Model Quantization and Pruning</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/ef2ee09ea9551de88bc11fd7eeea93b0-Abstract.html target=_blank rel=noopener>The Generalization-Stability Tradeoff In Neural Network Pruning</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/0e230b1a582d76526b7ad7fc62ae937d-Abstract.html target=_blank rel=noopener>FleXOR: Trainable Fractional Quantization</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/20b5e1cf8694af7a3c1ba4a87f073021-Abstract.html target=_blank rel=noopener>Adaptive Gradient Quantization for Data-Parallel SGD</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/3948ead63a9f2944218de038d8934305-Abstract.html target=_blank rel=noopener>Robust Quantization: One Model to Rule Them All</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/d77c703536718b95308130ff2e5cf9ee-Abstract.html target=_blank rel=noopener>HAWQ-V2: Hessian Aware trace-Weighted Quantization of Neural Networks</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/1385974ed5904a438616ff7bdb3f7439-Abstract.html target=_blank rel=noopener>Efficient Exact Verification of Binarized Neural Networks</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/13b919438259814cd5be8cb45877d577-Abstract.html target=_blank rel=noopener>Ultra-Low Precision 4-bit Training of Deep Neural Networks</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/96fca94df72984fc97ee5095410d4dec-Abstract.html target=_blank rel=noopener>Path Sample-Analytic Gradient Estimators for Stochastic Binary Networks</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/2fd5d41ec6cfab47e32164d5624269b1-Abstract.html target=_blank rel=noopener>Fast fourier convolution</a></li></ul><p><strong>2021</strong></p><ul><li>2021-WACV-<a href=https://openaccess.thecvf.com/content/WACV2021/papers/He_CAP_Context-Aware_Pruning_for_Semantic_Segmentation_WACV_2021_paper.pdf target=_blank rel=noopener>CAP: Context-Aware Pruning for Semantic Segmentation</a> [<a href=https://github.com/erichhhhho/CAP-Context-Aware-Pruning-for-Semantic-Segmentation target=_blank rel=noopener>Code</a>]</li><li>2021-AAAI-<a href=https://arxiv.org/abs/1911.09450 target=_blank rel=noopener>Few Shot Network Compression via Cross Distillation</a></li><li>2021-AAAI-<a href target=_blank rel=noopener>Conditional Channel Pruning for Automated Model Compression</a> [<a href=https://github.com/liuyixin-louis/CAMC-hanlab target=_blank rel=noopener>Code</a>]</li><li>2021-ICLR-<a href="https://openreview.net/forum?id=o966_Is_nPA" target=_blank rel=noopener>Neural Pruning via Growing Regularization</a> [<a href=https://github.com/MingSun-Tse/Regularization-Pruning target=_blank rel=noopener>PyTorch Code</a>]</li><li>2021-ICLR-<a href="https://openreview.net/forum?id=Cb54AMqHQFP" target=_blank rel=noopener>Network Pruning That Matters: A Case Study on Retraining Variants</a></li><li>2021-ICLR-<a href="https://openreview.net/forum?id=xCxXwTzx4L1" target=_blank rel=noopener>ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations</a></li><li>2021-ICLR-<a href="https://openreview.net/forum?id=rumv7QmLUue" target=_blank rel=noopener>A Gradient Flow Framework For Analyzing Network Pruning</a> (Spotlight)</li><li>2021-CVPR-<a href=https://arxiv.org/abs/2105.11228 target=_blank rel=noopener>Towards Compact CNNs via Collaborative Compression</a></li><li>2021-CVPR-<a href=https://arxiv.org/abs/2103.05861 target=_blank rel=noopener>Manifold Regularized Dynamic Network Pruning</a></li><li>2021-CVPR-<a href=https://arxiv.org/abs/2103.07156 target=_blank rel=noopener>Learnable Companding Quantization for Accurate Low-bit Neural Networks</a></li><li>2021-CVPR-<a href=https://arxiv.org/abs/2103.01049 target=_blank rel=noopener>Diversifying Sample Generation for Accurate Data-Free Quantization</a></li><li>2021-CVPR-<a href=https://arxiv.org/abs/2103.15263 target=_blank rel=noopener>Zero-shot Adversarial Quantization</a> [Oral] [<a href=https://github.com/FLHonker/ZAQ-code target=_blank rel=noopener>Code</a>]</li><li>2021-CVPR-<a href=https://arxiv.org/abs/2104.00903 target=_blank rel=noopener>Network Quantization with Element-wise Gradient Scaling</a> [<a href=https://cvlab.yonsei.ac.kr/projects/EWGS/ target=_blank rel=noopener>Project</a>]</li><li>2021-ICML-<a href=http://proceedings.mlr.press/v139/liu21ab.html target=_blank rel=noopener>Group Fisher Pruning for Practical Network Compression</a> [<a href=https://github.com/jshilong/FisherPruning target=_blank rel=noopener>Code</a>]</li><li>2021-ICML-<a href=http://proceedings.mlr.press/v139/wang21e.html target=_blank rel=noopener>Accelerate CNNs from Three Dimensions: A Comprehensive Pruning Framework</a></li><li>2021-ICML-<a href=https://arxiv.org/abs/2105.10065 target=_blank rel=noopener>A Probabilistic Approach to Neural Network Pruning</a></li><li>2021-ICML-<a href=http://proceedings.mlr.press/v139/rosenfeld21a.html target=_blank rel=noopener>On the Predictability of Pruning Across Scales</a></li><li>2021-ICML-<a href=http://proceedings.mlr.press/v139/verma21b.html target=_blank rel=noopener>Sparsifying Networks via Subdifferential Inclusion</a></li><li>2021-ICML-<a href=https://arxiv.org/abs/2101.09048 target=_blank rel=noopener>Selfish Sparse RNN Training</a> [<a href=https://github.com/Shiweiliuiiiiiii/Selfish-RNN target=_blank rel=noopener>Code</a>]</li><li>2021-ICML-<a href=https://arxiv.org/abs/2102.02887 target=_blank rel=noopener>Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training</a> [<a href=https://github.com/Shiweiliuiiiiiii/In-Time-Over-Parameterization target=_blank rel=noopener>Code</a>]</li><li>2021-ICML-<a href=http://proceedings.mlr.press/v139/ozdenizci21a.html target=_blank rel=noopener>Training Adversarially Robust Sparse Networks via Bayesian Connectivity Sampling</a></li><li>2021-ICML-<a href=https://arxiv.org/abs/2104.14129 target=_blank rel=noopener>ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training</a></li><li>2021-ICML-<a href=https://arxiv.org/abs/2105.04857 target=_blank rel=noopener>Leveraging Sparse Linear Layers for Debuggable Deep Networks</a></li><li>2021-ICML-<a href=http://proceedings.mlr.press/v139/patil21a.html target=_blank rel=noopener>PHEW: Constructing Sparse Networks that Learn Fast and Generalize Well without Training Data</a></li><li>2021-ICML-<a href=https://arxiv.org/abs/2103.16716 target=_blank rel=noopener>BASE Layers: Simplifying Training of Large, Sparse Models</a> [<a href=https://github.com/pytorch/fairseq/ target=_blank rel=noopener>Code</a>]</li><li>2021-ICML-<a href=https://arxiv.org/abs/2102.07655 target=_blank rel=noopener>Dense for the Price of Sparse: Improved Performance of Sparsely Initialized Networks via a Subspace Offset</a></li><li>2021-ICML-<a href=https://arxiv.org/abs/2101.01321 target=_blank rel=noopener>I-BERT: Integer-only BERT Quantization</a></li><li>2021-ICML-<a href=https://arxiv.org/abs/2105.01420 target=_blank rel=noopener>Training Quantized Neural Networks to Global Optimality via Semidefinite Programming</a></li><li>2021-ICML-<a href=https://arxiv.org/abs/2106.02295 target=_blank rel=noopener>Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution</a></li><li>2021-ICML-<a href=https://arxiv.org/abs/2102.07214 target=_blank rel=noopener>Communication-Efficient Distributed Optimization with Quantized Preconditioners</a></li><li>2021-NIPS-<a href=https://papers.nips.cc/paper/2021/file/15de21c670ae7c3f6f3f1f37029303c9-Paper.pdf target=_blank rel=noopener>Aligned Structured Sparsity Learning for Efficient Image Super-Resolution</a> [<a href=https://github.com/MingSun-Tse/ASSL target=_blank rel=noopener>Code</a>] (Spotlight!)</li><li>2021-NIPS-<a href=https://arxiv.org/abs/2110.15343 target=_blank rel=noopener>Scatterbrain: Unifying Sparse and Low-rank Attention</a> [<a href=https://github.com/HazyResearch/scatterbrain target=_blank rel=noopener>Code</a>]</li><li>2021-NIPS-<a href=https://proceedings.neurips.cc/paper/2021/file/a376033f78e144f494bfc743c0be3330-Paper.pdf target=_blank rel=noopener>Only Train Once: A One-Shot Neural Network Training And Pruning Framework</a> [<a href=https://github.com/tianyic/only_train_once target=_blank rel=noopener>Code</a>]</li><li>2021.5-<a href=https://arxiv.org/abs/2105.05916 target=_blank rel=noopener>Dynamical Isometry: The Missing Ingredient for Neural Network Pruning</a></li></ul><h4 id=2022>2022</h4><ul><li>2022-ICLR-<a href=https://arxiv.org/abs/2112.00029 target=_blank rel=noopener>Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=11nMVZK0WYM" target=_blank rel=noopener>Pruning has a disparate impact on model accuracy</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=btpIaJiRx6z" target=_blank rel=noopener>Pruning Neural Networks via Coresets and Convex Geometry: Towards No Assumptions</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=ksVGCOlOEba" target=_blank rel=noopener>Optimal Brain Compression: A Framework for Accurate Post-Training Quantization and Pruning</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=K2QGzyLwpYG" target=_blank rel=noopener>Data-Efficient Structured Pruning via Submodular Optimization</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=0GRBKLBjJE" target=_blank rel=noopener>A Fast Post-Training Pruning Framework for Transformers</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=w5DacXWzQ-Q" target=_blank rel=noopener>SAViT: Structure-Aware Vision Transformer Pruning via Collaborative Optimization</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=5hgYi4r5MDp" target=_blank rel=noopener>Recall Distortion in Neural Network Pruning and the Undecayed Pruning Algorithm</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=cUOR-_VsavA" target=_blank rel=noopener>Structural Pruning via Latency-Saliency Knapsack</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=KieCChVB6mN" target=_blank rel=noopener>Sparse Probabilistic Circuits via Pruning and Growing</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=mTXQIpXPDbh" target=_blank rel=noopener>Back Razor: Memory-Efficient Transfer Learning by Self-Sparsified Backpropogation</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=oQIJsMlyaW_" target=_blank rel=noopener>SInGE: Sparsity via Integrated Gradients Estimation of Neuron Relevance</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=HuiLIB6EaOk" target=_blank rel=noopener>VTC-LFC: Vision Transformer Compression with Low-Frequency Components</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=UQJoGBNRX4" target=_blank rel=noopener>Weighted Mutual Learning with Diversity-Driven Model Compression</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=wfel7CjOYk" target=_blank rel=noopener>Resource-Adaptive Federated Learning with All-In-One Neural Composition</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=XUvSYc6TqDF" target=_blank rel=noopener>Controlled Sparsity via Constrained Optimization or: How I Learned to Stop Tuning Penalties and Love Constraints</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=l2CVt1ySC2Q" target=_blank rel=noopener>On Measuring Excess Capacity in Neural Networks</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=2OpRgzLhoPQ" target=_blank rel=noopener>Prune and distill: similar reformatting of image information along rat visual cortex and deep neural networks</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=EZQnauHn-77" target=_blank rel=noopener>Deep Compression of Pre-trained Transformer Models</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=HZ20IYYAwah" target=_blank rel=noopener>Sparsity in Continuous-Depth Neural Networks</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=u4KagP_FjB" target=_blank rel=noopener>Spartan: Differentiable Sparsity via Regularized Transportation</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=0Z0xltoU1q" target=_blank rel=noopener>Accelerated Projected Gradient Algorithms for Sparsity Constrained Optimization Problems</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=kK200QKfvjB" target=_blank rel=noopener>Feature Learning in L2-regularized DNNs: Attraction/Repulsion and Sparsity</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=tbdk6XLYmZj" target=_blank rel=noopener>Learning Best Combination for Efficient N:M Sparsity</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=Q5kXC6hCr1" target=_blank rel=noopener>Accelerating Sparse Convolution with Column Vector-Wise Sparsity</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=68EuccCtO5i" target=_blank rel=noopener>Differentially Private Model Compression</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=w_jvWzNXd6n" target=_blank rel=noopener>Transformers meet Stochastic Block Models: Attention with Data-Adaptive Sparsity and Cost</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=UmaiVbwN1v" target=_blank rel=noopener>A Win-win Deal: Towards Sparse and Robust Pre-trained Language Models</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=88_wNI6ZBDZ" target=_blank rel=noopener>Make Sharpness-Aware Minimization Stronger: A Sparsified Perturbation Approach</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=dZEZu7zxJBF" target=_blank rel=noopener>Learning sparse features can lead to overfitting in neural networks</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=edgCBcwZxgd" target=_blank rel=noopener>Deep Architecture Connectivity Matters for Its Convergence: A Fine-Grained Analysis</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=NXHXoYMLIG" target=_blank rel=noopener>EfficientFormer: Vision Transformers at MobileNet Speed</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=INzRLBAA4JX" target=_blank rel=noopener>Revisiting Sparse Convolutional Model for Visual Recognition</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=AUz5Oig77OS" target=_blank rel=noopener>Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=AODVskSug8" target=_blank rel=noopener>A Theoretical View on Sparsely Activated Networks</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=ZxOO5jfqSYw" target=_blank rel=noopener>Dynamic Sparse Network for Time Series Classification: Learning What to “See”</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=QqWqFLbllZh" target=_blank rel=noopener>Spatial Pruned Sparse Convolution for Efficient 3D Object Detection</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=oOte_397Q4P" target=_blank rel=noopener>Sparse Structure Search for Delta Tuning</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=n0dD3d54Wgf" target=_blank rel=noopener>Beyond L1: Faster and Better Sparse Models with skglm</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=mWaYC6CZf5" target=_blank rel=noopener>On the Representation Collapse of Sparse Mixture of Experts</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=cFOhdl1cyU-" target=_blank rel=noopener>M³ViT: Mixture-of-Experts Vision Transformer for Efficient Multi-task Learning with Model-Accelerator Co-design</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=zGvRdBW06F5" target=_blank rel=noopener>On-Device Training Under 256KB Memory</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=rBCvMG-JsPd" target=_blank rel=noopener>Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning</a></li></ul><h4 id=2023>2023</h4><ul><li>2023-ICLR-<a href=https://arxiv.org/abs/2207.12534 target=_blank rel=noopener>Trainability Preserving Neural Pruning</a> [<a href=https://github.com/MingSun-Tse/TPP target=_blank rel=noopener>Code</a>]</li><li>2023-ICLR-<a href="https://openreview.net/forum?id=-5EWhW_4qWP" target=_blank rel=noopener>NTK-SAP: Improving neural network pruning by aligning training dynamics</a> [<a href=https://github.com/YiteWang/NTK-SAP target=_blank rel=noopener>Code</a>]</li><li>2023-CVPR-<a href=https://arxiv.org/abs/2301.12900 target=_blank rel=noopener>DepGraph: Towards Any Structural Pruning</a>[<a href=https://github.com/VainF/Torch-Pruning target=_blank rel=noopener>code</a>]</li><li>2023-CVPR-<a href=https://arxiv.org/abs/2303.13097 target=_blank rel=noopener>CP3: Channel Pruning Plug-in for Point-based Networks</a></li></ul><hr><h3 id=papers-actual-acceleration-via-sparsity>Papers [Actual Acceleration via Sparsity]</h3><ul><li>2018-ICML-<a href=https://arxiv.org/abs/1802.08435 target=_blank rel=noopener>Efficient Neural Audio Synthesis</a></li><li>2018-NIPS-<a href=https://papers.nips.cc/paper/2018/hash/89885ff2c83a10305ee08bd507c1049c-Abstract.html target=_blank rel=noopener>Tetris: Tile-matching the tremendous irregular sparsity</a></li><li>2021.4-<a href=https://arxiv.org/abs/2104.08378 target=_blank rel=noopener>Accelerating Sparse Deep Neural Networks</a> (White paper from NVIDIA)</li><li>2021-ICLR-<a href="https://openreview.net/forum?id=K9bw7vqp_s" target=_blank rel=noopener>Learning N:M Fine-grained Structured Sparse Neural Networks From Scratch</a> [<a href=https://github.com/NM-sparsity/NM-sparsity target=_blank rel=noopener>Code</a>]</li><li>2021-NIPS-<a href=https://proceedings.neurips.cc/paper/2021/hash/6e8404c3b93a9527c8db241a1846599a-Abstract.html target=_blank rel=noopener>Channel Permutations for N: M Sparsity</a> [<a href=https://github.com/NVIDIA/apex/tree/master/apex/contrib/sparsity target=_blank rel=noopener>Code: NVIDIA ASP</a>]</li><li>2021-NIPS-<a href="https://openreview.net/forum?id=vRWZsBLKqA" target=_blank rel=noopener>Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks</a></li><li>2021-ICLR-<a href=https://arxiv.org/abs/2102.04010 target=_blank rel=noopener>Learning N:M fine-grained structured sparse neural networks from scratch</a> [<a href=https://github.com/NM-sparsity/NM-sparsity target=_blank rel=noopener>Code</a>] [<a href=https://iclr.cc/media/iclr-2021/Slides/3174.pdf target=_blank rel=noopener>Slides</a>]</li><li>2022-NIPS-<a href="https://openreview.net/forum?id=ZJe-XahpyBf" target=_blank rel=noopener>UDC: Unified DNAS for Compressible TinyML Models for Neural Processing Units</a></li></ul><hr><h3 id=papers-lottery-ticket-hypothesis-lth>Papers [Lottery Ticket Hypothesis (LTH)]</h3><p>For LTH and other <em>Pruning at Initialization</em> papers, please refer to <a href=https://github.com/MingSun-Tse/Awesome-Pruning-at-Initialization target=_blank rel=noopener>Awesome-Pruning-at-Initialization</a>.</p><hr><h3 id=papers-bayesian-compression>Papers [Bayesian Compression]</h3><ul><li>1995-Neural Computation-<a href=https://www.researchgate.net/profile/Peter_Williams19/publication/2719575_Bayesian_Regularisation_and_Pruning_using_a_Laplace_Prior/links/58fde123aca2728fa70f6aab/Bayesian-Regularisation-and-Pruning-using-a-Laplace-Prior.pdf target=_blank rel=noopener>Bayesian Regularisation and Pruning using a Laplace Prior</a></li><li>1997-Neural Networks-<a href="https://www.sciencedirect.com/science/article/pii/S0893608097000270?casa_token=sLb4dFBnyH8AAAAA:a9WwAAoYl5CgLepZGXjZ5DKQ4YBEjINgGd7Jl2bPHqrbhIWZHso-uC_gpL-85JmdxG7g8x71" target=_blank rel=noopener>Regularization with a Pruning Prior</a></li><li>2015-NIPS-<a href=http://papers.nips.cc/paper/5965-bayesian-dark-knowledge.pdf target=_blank rel=noopener>Bayesian dark knowledge</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6921-bayesian-compression-for-deep-learning target=_blank rel=noopener>Bayesian Compression for Deep Learning</a> [<a href=https://github.com/KarenUllrich/Tutorial_BayesianCompressionForDL target=_blank rel=noopener>Code</a>]</li><li>2017-ICML-<a href=https://arxiv.org/pdf/1701.05369.pdf target=_blank rel=noopener>Variational dropout sparsifies deep neural networks</a></li><li>2017-NIPSo-<a href=http://papers.nips.cc/paper/7254-structured-bayesian-pruning-via-log-normal-multiplicative-noise target=_blank rel=noopener>Structured Bayesian Pruning via Log-Normal Multiplicative Noise</a></li><li>2017-ICMLw-<a href=https://arxiv.org/abs/1708.00077 target=_blank rel=noopener>Bayesian Sparsification of Recurrent Neural Networks</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/3f13cf4ddf6fc50c0d39a1d5aeb57dd8-Abstract.html target=_blank rel=noopener>Bayesian Bits: Unifying Quantization and Pruning</a></li></ul><h2 id=papers-knowledge-distillation-kd>Papers [Knowledge Distillation (KD)]</h2><p><strong>Before 2014</strong></p><ul><li>1996-<a href=ftp://ftp.stat.berkeley.edu/pub/users/breiman/BAtrees.ps target=_blank rel=noopener>Born again trees</a> (proposed compressing neural networks and multipletree predictors by approximating them with a single tree)</li><li>2006-SIGKDD-<a href="https://dl.acm.org/citation.cfm?id=1150464" target=_blank rel=noopener>Model compression</a></li><li>2010-ML-<a href=https://link.springer.com/content/pdf/10.1007%2Fs10994-009-5152-4.pdf target=_blank rel=noopener>A theory of learning from different domains</a></li></ul><p><strong>2014</strong></p><ul><li>2014-NIPS-<a href=https://arxiv.org/abs/1312.6184 target=_blank rel=noopener>Do deep nets really need to be deep?</a></li><li>2014-NIPSw-<a href=https://arxiv.org/pdf/1503.02531.pdf target=_blank rel=noopener>Distilling the Knowledge in a Neural Network</a> [<a href=https://github.com/peterliht/knowledge-distillation-pytorch target=_blank rel=noopener>Code</a>]</li></ul><p><strong>2016</strong></p><ul><li>2016-ICLR-<a href=https://arxiv.org/abs/1511.05641 target=_blank rel=noopener>Net2net: Accelerating learning via knowledge transfer</a></li><li>2016-ECCV-<a href=https://www.researchgate.net/publication/308277663_Accelerating_Convolutional_Neural_Networks_with_Dominant_Convolutional_Kernel_and_Knowledge_Pre-regression target=_blank rel=noopener>Accelerating convolutional neural networks with dominant convolutional kernel and knowledge pre-regression</a></li></ul><p><strong>2017</strong></p><ul><li>2017-ICLR-<a href=http://arxiv.org/abs/1612.03928 target=_blank rel=noopener>Paying more attention to attention: Improving the performance of convolutional neural networksvia attention transfer</a></li><li>2017-ICLR-<a href=https://arxiv.org/pdf/1603.05691.pdf target=_blank rel=noopener>Do deep convolutional nets really need to be deep and convolutional?</a></li><li>2017-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2017/papers/Yim_A_Gift_From_CVPR_2017_paper.pdf target=_blank rel=noopener>A gift from knowledge distillation: Fast optimization, network minimization and transfer learning</a></li><li>2017-BMVC-<a href=https://arxiv.org/abs/1604.00433 target=_blank rel=noopener>Adapting models to signal degradation using distillation</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/7015-sobolev-training-for-neural-networks.pdf target=_blank rel=noopener>Sobolev training for neural networks</a></li><li>2017-NIPS-<a href=http://papers.nips.cc/paper/6676-learning-efficient-object-detection-models-with-knowledge-distillation target=_blank rel=noopener>Learning efficient object detection models with knowledge distillation</a></li><li>2017-NIPSw-<a href=https://arxiv.org/abs/1710.07535 target=_blank rel=noopener>Data-Free Knowledge Distillation for Deep Neural Networks</a> [<a href=https://github.com/iRapha/replayed_distillation target=_blank rel=noopener>Code</a>]</li><li>2017.07-<a href=https://arxiv.org/pdf/1707.01219.pdf target=_blank rel=noopener>Like What You Like: Knowledge Distill via Neuron Selectivity Transfer</a></li><li>2017.10-<a href=https://arxiv.org/abs/1710.09505 target=_blank rel=noopener>Knowledge Projection for Deep Neural Networks</a></li><li>2017.11-<a href=https://arxiv.org/abs/1711.09784 target=_blank rel=noopener>Distilling a Neural Network Into a Soft Decision Tree</a></li><li>2017.12-<a href=https://arxiv.org/abs/1712.04440 target=_blank rel=noopener>Data Distillation: Towards Omni-Supervised Learning</a></li></ul><p><strong>2018</strong></p><ul><li>2018-AAAI-<a href=https://arxiv.org/abs/1707.01220 target=_blank rel=noopener>DarkRank: Accelerating Deep Metric Learning via Cross Sample Similarities Transfer</a></li><li>2018-AAAI-<a href=https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16291/16575 target=_blank rel=noopener>Dynamic deep neural networks: Optimizing accuracy-efficiency trade-offs by selective execution</a></li><li>2018-AAAI-<a href=https://arxiv.org/abs/1708.04106 target=_blank rel=noopener>Rocket Launching: A Universal and Efficient Framework for Training Well-performing Light Net</a></li><li>2018-AAAI-<a href=https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16509 target=_blank rel=noopener>Adversarial Learning of Portable Student Networks</a></li><li>2018-AAAI-<a href=https://arxiv.org/abs/1805.05551 target=_blank rel=noopener>Knowledge Distillation in Generations: More Tolerant Teachers Educate Better Students</a></li><li>2018-ICLR-<a href="https://openreview.net/forum?id=rkr1UDeC-" target=_blank rel=noopener>Large scale distributed neural network training through online distillation</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Deep_Mutual_Learning_CVPR_2018_paper.html target=_blank rel=noopener>Deep mutual learning</a></li><li>2018-ICML-<a href=https://arxiv.org/pdf/1805.04770.pdf target=_blank rel=noopener>Born-Again Neural Networks</a></li><li>2018-IJCAI-<a href=https://arxiv.org/abs/1804.10069 target=_blank rel=noopener>Better and Faster: Knowledge Transfer from Multiple Self-supervised Learning Tasks via Graph Distillation for Video Classification</a></li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Nikolaos_Passalis_Learning_Deep_Representations_ECCV_2018_paper.html target=_blank rel=noopener>2018-ECCV-Learning deep representations with probabilistic knowledge transfer</a> [<a href=https://github.com/passalis/probabilistic_kt target=_blank rel=noopener>Code</a>]</li><li>2018-ECCV-<a href=http://openaccess.thecvf.com/content_ECCV_2018/html/Zhengming_Ding_Graph_Adaptive_Knowledge_ECCV_2018_paper.html target=_blank rel=noopener>Graph adaptive knowledge transfer for unsupervised domain adaptation</a></li><li>2018-SIGKDD-<a href=https://www.researchgate.net/profile/Yunhe_Wang3/publication/326502551_Towards_Evolutionary_Compression/links/5b7e9304a6fdcc5f8b5e4fe5/Towards-Evolutionary-Compression.pdf target=_blank rel=noopener>Towards Evolutionary Compression</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7358-kdgan-knowledge-distillation-with-generative-adversarial-networks target=_blank rel=noopener>KDGAN: knowledge distillation with generative adversarial networks</a> [<a href=https://ieeexplore.ieee.org/abstract/document/8845633 target=_blank rel=noopener>2019 TPAMI version</a>]</li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7980-knowledge-distillation-by-on-the-fly-native-ensemble target=_blank rel=noopener>Knowledge Distillation by On-the-Fly Native Ensemble</a></li><li>2018-NIPS-<a href=http://papers.nips.cc/paper/7541-paraphrasing-complex-network-network-compression-via-factor-transfer target=_blank rel=noopener>Paraphrasing Complex Network: Network Compression via Factor Transfer</a></li><li>2018-NIPSw-<a href=http://hushell.github.io/papers/nips18_cl.pdf target=_blank rel=noopener>Variational Mutual Information Distillation for Transfer Learning</a> <a href=https://sites.google.com/view/continual2018/ target=_blank rel=noopener>workshop: continual learning</a></li><li>2018-NIPSw-<a href=https://arxiv.org/pdf/1801.08640.pdf target=_blank rel=noopener>Transparent Model Distillation</a></li><li>2018.03-<a href=https://arxiv.org/abs/1803.04042 target=_blank rel=noopener>Interpreting Deep Classifier by Visual Distillation of Dark Knowledge</a></li><li>2018.11-<a href=https://arxiv.org/abs/1811.10959 target=_blank rel=noopener>Dataset Distillation</a> [<a href=https://github.com/SsnL/dataset-distillation target=_blank rel=noopener>Code</a>]</li><li>2018.12-<a href=https://arxiv.org/abs/1812.06597 target=_blank rel=noopener>Learning Student Networks via Feature Embedding</a></li><li>2018.12-<a href=https://arxiv.org/abs/1812.01839 target=_blank rel=noopener>Few Sample Knowledge Distillation for Efficient Network Compression</a></li></ul><p><strong>2019</strong></p><ul><li>2019-AAAI-<a href=https://arxiv.org/abs/1805.05532 target=_blank rel=noopener>Knowledge Distillation with Adversarial Samples Supporting Decision Boundary</a></li><li>2019-AAAI-<a href=https://arxiv.org/abs/1811.03233 target=_blank rel=noopener>Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons</a> [<a href=https://github.com/bhheo/AB_distillation target=_blank rel=noopener>Code</a>]</li><li>2019-AAAI-<a href=https://arxiv.org/abs/1811.02759 target=_blank rel=noopener>Learning to Steer by Mimicking Features from Heterogeneous Auxiliary Networks</a> [<a href=https://github.com/cardwing/Codes-for-Steering-Control target=_blank rel=noopener>Code</a>]</li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPRW_2019/html/CEFRL/Liu_Knowledge_Representing_Efficient_Sparse_Representation_of_Prior_Knowledge_for_Knowledge_CVPRW_2019_paper.html target=_blank rel=noopener>Knowledge Representing: Efficient, Sparse Representation of Prior Knowledge for Knowledge Distillation</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Knowledge_Distillation_via_Instance_Relationship_Graph_CVPR_2019_paper.html target=_blank rel=noopener>Knowledge Distillation via Instance Relationship Graph</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Ahn_Variational_Information_Distillation_for_Knowledge_Transfer_CVPR_2019_paper.html target=_blank rel=noopener>Variational Information Distillation for Knowledge Transfer</a></li><li>2019-CVPR-<a href=http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Learning_Metrics_From_Teachers_Compact_Networks_for_Image_Embedding_CVPR_2019_paper.html target=_blank rel=noopener>Learning Metrics from Teachers Compact Networks for Image Embedding</a> [<a href=https://github.com/yulu0724/EmbeddingDistillation target=_blank rel=noopener>Code</a>]</li><li>2019-ICCV-<a href=http://openaccess.thecvf.com/content_ICCV_2019/html/Heo_A_Comprehensive_Overhaul_of_Feature_Distillation_ICCV_2019_paper.html target=_blank rel=noopener>A Comprehensive Overhaul of Feature Distillation</a></li><li>2019-ICCV-<a href=https://arxiv.org/abs/1907.09682 target=_blank rel=noopener>Similarity-Preserving Knowledge Distillation</a></li><li>2019-ICCV-<a href=https://arxiv.org/abs/1904.01802 target=_blank rel=noopener>Correlation Congruence for Knowledge Distillation</a></li><li>2019-ICCV-<a href=https://arxiv.org/abs/1904.01186 target=_blank rel=noopener>Data-Free Learning of Student Networks</a></li><li>2019-ICCV-<a href=https://arxiv.org/abs/1908.00821 target=_blank rel=noopener>Learning Lightweight Lane Detection CNNs by Self Attention Distillation</a> [<a href=https://github.com/cardwing/Codes-for-Lane-Detection target=_blank rel=noopener>Code</a>]</li><li>2019-ICCV-<a href=http://openaccess.thecvf.com/content_ICCV_2019/html/Li_Attention_Bridging_Network_for_Knowledge_Transfer_ICCV_2019_paper.html target=_blank rel=noopener>Attention bridging network for knowledge transfer</a></li><li>2019-NIPS-<a href=https://papers.nips.cc/paper/9151-zero-shot-knowledge-transfer-via-adversarial-belief-matching target=_blank rel=noopener>Zero-shot Knowledge Transfer via Adversarial Belief Matching</a> [<a href=https://github.com/polo5/ZeroShotKnowledgeTransfer target=_blank rel=noopener>Code</a>] (spotlight)</li><li>2019.05-<a href=https://arxiv.org/abs/1905.03465 target=_blank rel=noopener>DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs</a></li></ul><p><strong>2020</strong></p><ul><li>2020-ICLR-<a href=https://arxiv.org/abs/1910.10699 target=_blank rel=noopener>Contrastive Representation Distillation</a> [<a href=https://github.com/HobbitLong/RepDistiller target=_blank rel=noopener>Code</a>]</li><li>2020-AAAI-<a href target=_blank rel=noopener>A Knowledge Transfer Framework for Differentially Private Sparse Learning</a></li><li>2020-AAAI-<a href target=_blank rel=noopener>Uncertainty-aware Multi-shot Knowledge Distillation for Image-based Object Re-identification</a></li><li>2020-AAAI-<a href target=_blank rel=noopener>Improved Knowledge Distillation via Teacher Assistant</a></li><li>2020-AAAI-<a href target=_blank rel=noopener>Knowledge Distillation from Internal Representations</a></li><li>2020-AAAI-<a href target=_blank rel=noopener>Distilling Knowledge from Well-informed Soft Labels for Neural Relation Extraction</a></li><li>2020-AAAI-<a href=https://arxiv.org/abs/1912.00350 target=_blank rel=noopener>Online Knowledge Distillation with Diverse Peers</a></li><li>2020-AAAI-<a href=https://arxiv.org/abs/1904.04449 target=_blank rel=noopener>Ultrafast Video Attention Prediction with Coupled Knowledge Distillation</a></li><li>2020-AAAI-<a href target=_blank rel=noopener>Graph Few-shot Learning via Knowledge Transfer</a></li><li>2020-AAAI-<a href target=_blank rel=noopener>Diversity Transfer Network for Few-Shot Learning</a></li><li>2020-AAAI-<a href=https://arxiv.org/abs/1911.09450 target=_blank rel=noopener>Few Shot Network Compression via Cross Distillation</a></li><li>2020-ICLR-<a href="https://openreview.net/pdf?id=BJeS62EtwH" target=_blank rel=noopener>Knowledge Consistency between Neural Networks and Beyond</a></li><li>2020-ICLR-<a href="https://openreview.net/pdf?id=SkgpBJrtvS" target=_blank rel=noopener>Contrastive Representation Distillation</a> [<a href=http://github.com/HobbitLong/RepDistiller target=_blank rel=noopener>Code</a>]</li><li>2020-ICLR-<a href="https://openreview.net/forum?id=SklkDkSFPB" target=_blank rel=noopener>BlockSwap: Fisher-guided Block Substitution for Network Compression on a Budget</a></li><li>2020-ICLR-<a href="https://openreview.net/pdf?id=BygSP6Vtvr" target=_blank rel=noopener>Ensemble Distribution Distillation</a></li><li>2020-CVPR-<a href=https://arxiv.org/abs/2003.08436 target=_blank rel=noopener>Collaborative Distillation for Ultra-Resolution Universal Style Transfer</a> [<a href=https://github.com/MingSun-Tse/Collaborative-Distillation target=_blank rel=noopener>Code</a>]</li><li>2020-CVPR-<a href=https://arxiv.org/abs/2003.03622 target=_blank rel=noopener>Explaining Knowledge Distillation by Quantifying the Knowledge</a></li><li>2020-CVPR-<a href=https://arxiv.org/abs/1911.04252 target=_blank rel=noopener>Self-training with Noisy Student improves ImageNet classification</a> [<a href=https://github.com/google-research/noisystudent target=_blank rel=noopener>Code</a>]</li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Neural_Networks_Are_More_Productive_Teachers_Than_Human_Raters_Active_CVPR_2020_paper.pdf target=_blank rel=noopener>Neural Networks Are More Productive Teachers Than Human Raters: Active Mixup for Data-Efficient Knowledge Distillation From a Blackbox Model</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Passalis_Heterogeneous_Knowledge_Distillation_Using_Information_Flow_Modeling_CVPR_2020_paper.pdf target=_blank rel=noopener>Heterogeneous Knowledge Distillation Using Information Flow Modeling</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Hu_Creating_Something_From_Nothing_Unsupervised_Knowledge_Distillation_for_Cross-Modal_Hashing_CVPR_2020_paper.pdf target=_blank rel=noopener>Creating Something From Nothing: Unsupervised Knowledge Distillation for Cross-Modal Hashing</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Yuan_Revisiting_Knowledge_Distillation_via_Label_Smoothing_Regularization_CVPR_2020_paper.pdf target=_blank rel=noopener>Revisiting Knowledge Distillation via Label Smoothing Regularization</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Distilling_Knowledge_From_Graph_Convolutional_Networks_CVPR_2020_paper.pdf target=_blank rel=noopener>Distilling Knowledge From Graph Convolutional Networks</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_MineGAN_Effective_Knowledge_Transfer_From_GANs_to_Target_Domains_With_CVPR_2020_paper.pdf target=_blank rel=noopener>MineGAN: Effective Knowledge Transfer From GANs to Target Domains With Few Images</a> [<a href=https://github.com/yaxingwang/MineGAN target=_blank rel=noopener>Code</a>]</li><li>2020-CVPRo-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Yin_Dreaming_to_Distill_Data-Free_Knowledge_Transfer_via_DeepInversion_CVPR_2020_paper.pdf target=_blank rel=noopener>Dreaming to Distill: Data-Free Knowledge Transfer via DeepInversion</a> [<a href=https://github.com/NVlabs/DeepInversion target=_blank rel=noopener>Code</a>]</li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_Online_Knowledge_Distillation_via_Collaborative_Learning_CVPR_2020_paper.pdf target=_blank rel=noopener>Online Knowledge Distillation via Collaborative Learning</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Ye_Distilling_Cross-Task_Knowledge_via_Relationship_Matching_CVPR_2020_paper.pdf target=_blank rel=noopener>Distilling Cross-Task Knowledge via Relationship Matching</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Ye_Data-Free_Knowledge_Amalgamation_via_Group-Stack_Dual-GAN_CVPR_2020_paper.pdf target=_blank rel=noopener>Data-Free Knowledge Amalgamation via Group-Stack Dual-GAN</a></li><li>2020-CVPR-<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Yun_Regularizing_Class-Wise_Predictions_via_Self-Knowledge_Distillation_CVPR_2020_paper.pdf target=_blank rel=noopener>Regularizing Class-Wise Predictions via Self-Knowledge Distillation</a></li><li>2020-ICML-<a href=https://arxiv.org/abs/2002.01775 target=_blank rel=noopener>Feature-map-level Online Adversarial Knowledge Distillation</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/1731592aca5fb4d789c4119c65c10b4b-Abstract.html target=_blank rel=noopener>Self-Distillation as Instance-Specific Label Smoothing</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/18df51b97ccd68128e994804f3eccc87-Abstract.html target=_blank rel=noopener>Ensemble Distillation for Robust Model Fusion in Federated Learning</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/2288f691b58edecadcc9a8691762b4fd-Abstract.html target=_blank rel=noopener>Self-Distillation Amplifies Regularization in Hilbert Space</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html target=_blank rel=noopener>MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/657b96f0592803e25a4f07166fff289a-Abstract.html target=_blank rel=noopener>Residual Distillation: Towards Portable Deep Neural Networks without Shortcuts</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/912d2b1c7b2826caf99687388d2e8f7c-Abstract.html target=_blank rel=noopener>Kernel Based Progressive Distillation for Adder Neural Networks</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/91c77393975889bd08f301c9e13a44b7-Abstract.html target=_blank rel=noopener>Agree to Disagree: Adaptive Ensemble Knowledge Distillation in Gradient Space</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/a96b65a721e561e1e3de768ac819ffbb-Abstract.html target=_blank rel=noopener>Task-Oriented Feature Distillation</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/c3535febaff29fcb7c0d20cbe94391c7-Abstract.html target=_blank rel=noopener>Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/fef6f971605336724b5e6c0c12dc2534-Abstract.html target=_blank rel=noopener>Distributed Distillation for On-Device Learning</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/ef0d3930a7b6c95bd2b32ed45989c61f-Abstract.html target=_blank rel=noopener>Knowledge Distillation in Wide Neural Networks: Risk Bound, Data Efficiency and Imperfect Teacher</a></li><li>2020.12-<a href=https://arxiv.org/abs/2012.02909 target=_blank rel=noopener>Knowledge Distillation Thrives on Data Augmentation</a></li><li>2020.12-<a href=https://arxiv.org/abs/2012.02911 target=_blank rel=noopener>Multi-head Knowledge Distillation for Model Compression</a></li></ul><p><strong>2021</strong></p><ul><li>2021-AAAI-<a href=https://arxiv.org/abs/2012.03236 target=_blank rel=noopener>Cross-Layer Distillation with Semantic Calibration</a> [<a href=https://github.com/DefangChen/SemCKD target=_blank rel=noopener>Code</a>]</li><li>2021-ICLR-<a href="https://openreview.net/forum?id=NTEz-6wysdb" target=_blank rel=noopener>Distilling Knowledge from Reader to Retriever for Question Answering</a></li><li>2021-ICLR-<a href="https://openreview.net/forum?id=uKhGRvM8QNH" target=_blank rel=noopener>Improve Object Detection with Feature-based Knowledge Distillation: Towards Accurate and Efficient Detectors</a></li><li>2021-ICLR-<a href="https://openreview.net/forum?id=ZzwDy_wiWv" target=_blank rel=noopener>Knowledge distillation via softmax regression representation learning</a> [<a href=https://github.com/jingyang2017/KD_SRRL target=_blank rel=noopener>Code</a>]</li><li>2021-ICLR-<a href="https://openreview.net/forum?id=m4UCf24r0Y" target=_blank rel=noopener>Knowledge Distillation as Semiparametric Inference</a></li><li>2021-ICLR-<a href="https://openreview.net/forum?id=PObuuGVrGaZ" target=_blank rel=noopener>Is Label Smoothing Truly Incompatible with Knowledge Distillation: An Empirical Study</a></li><li>2021-ICLR-<a href="https://openreview.net/forum?id=gIHd-5X324" target=_blank rel=noopener>Rethinking Soft Labels for Knowledge Distillation: A Bias–Variance Tradeoff Perspective</a></li><li>2021-CVPR-<a href=https://arxiv.org/abs/2103.08273 target=_blank rel=noopener>Refine Myself by Teaching Myself: Feature Refinement via Self-Knowledge Distillation</a> [<a href=https://github.com/MingiJi/FRSKD target=_blank rel=noopener>PyTorch Code</a>]</li><li>2021-CVPR-<a href=https://arxiv.org/abs/2103.16367 target=_blank rel=noopener>Complementary Relation Contrastive Distillation</a></li><li>2021-CVPR-<a href=https://arxiv.org/abs/2104.09044 target=_blank rel=noopener>Distilling Knowledge via Knowledge Review</a> [<a href=https://github.com/dvlab-research/ReviewKD target=_blank rel=noopener>Code</a>]</li><li>2021-ICML-<a href target=_blank rel=noopener>KD3A: Unsupervised Multi-Source Decentralized Domain Adaptation via Knowledge Distillation</a></li><li>2021-ICML-<a href target=_blank rel=noopener>A statistical perspective on distillation</a></li><li>2021-ICML-<a href target=_blank rel=noopener>Training data-efficient image transformers & distillation through attention</a></li><li>2021-ICML-<a href target=_blank rel=noopener>Zero-Shot Knowledge Distillation from a Decision-Based Black-Box Model</a></li><li>2021-ICML-<a href target=_blank rel=noopener>Data-Free Knowledge Distillation for Heterogeneous Federated Learning</a></li><li>2021-ICML-<a href target=_blank rel=noopener>Simultaneous Similarity-based Self-Distillation for Deep Metric Learning</a></li><li>2021-NIPS-<a href=https://papers.nips.cc/paper/2021/file/75fc093c0ee742f6dddaa13fff98f104-Paper.pdf target=_blank rel=noopener>Slow Learning and Fast Inference: Efficient Graph Similarity Computation via Knowledge Distillation</a> [<a href=https://github.com/canqin001/Efficient_Graph_Similarity_Computation target=_blank rel=noopener>Code</a>]</li></ul><h4 id=2022-1>2022</h4><ul><li>2022-ECCV-<a href=https://arxiv.org/abs/2203.17261 target=_blank rel=noopener>R2L: Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View Synthesis</a> <a href=https://github.com/snap-research/R2L target=_blank rel=noopener>Code</a></li><li>2022-NIPS-<a href="https://openreview.net/forum?id=4d_tnQ_agHI" target=_blank rel=noopener>An Analytical Theory of Curriculum Learning in Teacher-Student Networks</a></li></ul><h2 id=papers-automl-nas-etc>Papers [AutoML (NAS etc.)]</h2><ul><li>2016.11-<a href=https://arxiv.org/abs/1611.01578 target=_blank rel=noopener>Neural architecture search with reinforcement learning</a></li><li>2019-CVPR-<a href=https://github.com/D-X-Y/GDAS/blob/master/data/GDAS.pdf target=_blank rel=noopener>Searching for A Robust Neural Architecture in Four GPU Hours</a> [<a href=https://github.com/D-X-Y/GDAS target=_blank rel=noopener>Code</a>]</li><li>2019-CVPR-<a href=https://arxiv.org/abs/1812.03443 target=_blank rel=noopener>FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search</a></li><li>2019-CVPR-<a href=https://arxiv.org/abs/1808.00193 target=_blank rel=noopener>RENAS: Reinforced Evolutionary Neural Architecture Search</a></li><li>2019-NIPS-<a href=https://papers.nips.cc/paper/9301-meta-architecture-search target=_blank rel=noopener>Meta Architecture Search</a></li><li>2019-NIPS-<a href=https://papers.nips.cc/paper/8743-sparse-sparse-architecture-search-for-cnns-on-resource-constrained-microcontrollers target=_blank rel=noopener>SpArSe: Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/62d75fb2e3075506e8837d8f55021ab1-Abstract.html target=_blank rel=noopener>Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/d072677d210ac4c03ba046120f0802ec-Abstract.html target=_blank rel=noopener>Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural Architecture Search</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/5e1b18c4c6a6d31695acbae3fd70ecc6-Abstract.html target=_blank rel=noopener>Theory-Inspired Path-Regularized Differential Network Architecture Search</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/76cf99d3614e23eabab16fb27e944bf9-Abstract.html target=_blank rel=noopener>ISTA-NAS: Efficient and Consistent Neural Architecture Search by Sparse Coding</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/77305c2f862ad1d353f55bf38e5a5183-Abstract.html target=_blank rel=noopener>Semi-Supervised Neural Architecture Search</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/13d4635deccc230c944e4ff6e03404b5-Abstract.html target=_blank rel=noopener>Bridging the Gap between Sample-based and One-shot Neural Architecture Search with BONAS</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/937936029af671cf479fa893db91cbdd-Abstract.html target=_blank rel=noopener>Does Unsupervised Architecture Representation Learning Help Neural Architecture Search?</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/9a96a2c73c0d477ff2a6da3bf538f4f4-Abstract.html target=_blank rel=noopener>Differentiable Neural Architecture Search in Equivalent Space with Exploration Enhancement</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/c6e81542b125c36346d9167691b8bd09-Abstract.html target=_blank rel=noopener>CLEARER: Multi-Scale Neural Architecture Search for Image Restoration</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/ea4eb49329550caaa1d2044105223721-Abstract.html target=_blank rel=noopener>A Study on Encodings for Neural Architecture Search</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/ec1f764517b7ffb52057af6df18142b7-Abstract.html target=_blank rel=noopener>Auto-Panoptic: Cooperative Multi-Component Architecture Search for Panoptic Segmentation</a></li><li>2020-NIPS-<a href=https://papers.nips.cc/paper/2020/hash/fc146be0b230d7e0a92e66a6114b840d-Abstract.html target=_blank rel=noopener>Hierarchical Neural Architecture Search for Deep Stereo Matching</a></li></ul><p>*</p><h2 id=papers-interpretability>Papers [Interpretability]</h2><ul><li>2010-JMLR-<a href=http://www.jmlr.org/papers/v11/baehrens10a.html target=_blank rel=noopener>How to explain individual classification decisions</a></li><li>2015-PLOS ONE-<a href=http://heatmapping.org/ target=_blank rel=noopener>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</a></li><li>2015-CVPR-<a href=https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf target=_blank rel=noopener>Learning to generate chairs with convolutional neural networks</a></li><li>2015-CVPR-<a href=https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Mahendran_Understanding_Deep_Image_2015_CVPR_paper.html target=_blank rel=noopener>Understanding deep image representations by inverting them</a> [2016 IJCV version: <a href=https://link.springer.com/content/pdf/10.1007%2Fs11263-016-0911-8.pdf target=_blank rel=noopener>Visualizing deep convolutional neural networks using natural pre-images</a>]</li><li>2016-CVPR-<a href=https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Dosovitskiy_Inverting_Visual_Representations_CVPR_2016_paper.html target=_blank rel=noopener>Inverting Visual Representations with Convolutional Networks</a></li><li>2016-KDD-<a href=https://arxiv.org/abs/1602.04938 target=_blank rel=noopener>&ldquo;Why Should I Trust You?&rdquo;: Explaining the Predictions of Any Classifier</a></li><li>2016-ICMLw-<a href=https://arxiv.org/abs/1606.03490 target=_blank rel=noopener>The Mythos of Model Interpretability</a></li><li>2017-NIPSw-<a href=https://arxiv.org/abs/1711.00867 target=_blank rel=noopener>The (Un)reliability of saliency methods</a></li><li>2017-DSP-<a href=https://arxiv.org/abs/1706.07979 target=_blank rel=noopener>Methods for interpreting and understanding deep neural networks</a></li><li>2018-ICML-<a href=https://arxiv.org/abs/1711.11279 target=_blank rel=noopener>Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors</a></li><li>2018-CVPR-<a href=http://openaccess.thecvf.com/content_cvpr_2018/html/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.html target=_blank rel=noopener>Deep Image Prior</a> [<a href=https://dmitryulyanov.github.io/deep_image_prior target=_blank rel=noopener>Code</a>]</li><li>2018-NIPSs-<a href=https://arxiv.org/abs/1810.03292 target=_blank rel=noopener>Sanity Checks for Saliency Maps</a></li><li>2018-NIPSs-<a href=https://arxiv.org/abs/1805.11571 target=_blank rel=noopener>Human-in-the-Loop Interpretability Prior</a></li><li>2018-NIPS-<a href=https://arxiv.org/abs/1805.11783 target=_blank rel=noopener>To Trust Or Not To Trust A Classifier</a> [<a href=https://github.com/google/TrustScore target=_blank rel=noopener>Code</a>]</li><li>2019-AISTATS-<a href=https://arxiv.org/abs/1810.10118 target=_blank rel=noopener>Interpreting Black Box Predictions using Fisher Kernels</a></li><li>2019.05-<a href=https://arxiv.org/pdf/1905.13405.pdf target=_blank rel=noopener>Luck Matters: Understanding Training Dynamics of Deep ReLU Networks</a></li><li>2019.05-<a href=https://arxiv.org/abs/1905.02175 target=_blank rel=noopener>Adversarial Examples Are Not Bugs, They Are Features</a></li><li>2019.06-<a href=https://arxiv.org/abs/1906.03728 target=_blank rel=noopener>The Generalization-Stability Tradeoff in Neural Network Pruning</a></li><li>2019.06-<a href=https://arxiv.org/abs/1906.02773 target=_blank rel=noopener>One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers</a></li><li>2019-Book-<a href=https://christophm.github.io/interpretable-ml-book/index.html target=_blank rel=noopener>Interpretable Machine Learning</a></li></ul><h2 id=workshops>Workshops</h2><ul><li><a href=http://people.csail.mit.edu/beenkim/icml_tutorial.html target=_blank rel=noopener>2017-ICML Tutorial</a>: interpretable machine learning</li><li><a href="https://openreview.net/group?id=ICML.cc/2018/ECA" target=_blank rel=noopener>2018-ICML Workshop</a>: Efficient Credit Assignment in Deep Learning and Reinforcement Learning</li><li>CDNNRIA Workshop (Compact Deep Neural Network Representation with Industrial Applications): <a href="https://openreview.net/group?id=NIPS.cc/2018/Workshop/CDNNRIA" target=_blank rel=noopener>1st-2018-NIPSw</a>, <a href=https://sites.google.com/view/icml2019-on-device-compact-dnn target=_blank rel=noopener>2nd-2019-ICMLw</a></li><li>LLD Workshop (Learning with Limited Data): <a href=https://lld-workshop.github.io/2017/ target=_blank rel=noopener>1st-2017-NIPSw</a>, <a href=https://lld-workshop.github.io/ target=_blank rel=noopener>2nd-2019-ICLRw</a></li><li>WHI (Worshop on Human Interpretability in Machine Learning): <a href=https://sites.google.com/site/2016whi/ target=_blank rel=noopener>1st-2016-ICMLw</a>, <a href=https://sites.google.com/view/whi2017/home target=_blank rel=noopener>2nd-2017-ICMLw</a>, <a href=https://sites.google.com/view/whi2018 target=_blank rel=noopener>3rd-2018-ICMLw</a></li><li><a href=http://learningsys.org/nips18/schedule.html target=_blank rel=noopener>NIPS-18 Workshop on Systems for ML and Open Source Software</a></li><li>MLPCD Workshop (Machine Learning on the Phone and other Consumer Devices): <a href=https://sites.google.com/view/nips-2018-on-device-ml/home target=_blank rel=noopener>2nd-2018-NIPSw</a></li><li><a href=http://bayesiandeeplearning.org/ target=_blank rel=noopener>Workshop on Bayesian Deep Learning</a></li><li><a href=https://sites.google.com/view/cvpr20-nas/program target=_blank rel=noopener>2020 CVPR Workshop on NAS</a></li></ul><h2 id=books--courses>Books & Courses</h2><ul><li><a href=https://efficientml.ai/ target=_blank rel=noopener>TinyML and Efficient Deep Learning</a> @MIT by Prof. Song Han</li></ul><h2 id=lightweight-dnn-enginesapis>Lightweight DNN Engines/APIs</h2><ul><li><a href=https://github.com/Maratyszcza/NNPACK target=_blank rel=noopener>NNPACK</a></li><li>DMLC: <a href=https://github.com/dmlc/tvm target=_blank rel=noopener>Tensor Virtual Machine (TVM): Open Deep Learning Compiler Stack</a></li><li>Tencent: <a href=https://github.com/Tencent/ncnn target=_blank rel=noopener>NCNN</a></li><li>Xiaomi: <a href=https://github.com/XiaoMi/mace target=_blank rel=noopener>MACE</a>, <a href=https://github.com/XiaoMi/mobile-ai-bench target=_blank rel=noopener>Mobile AI Benchmark</a></li><li>Alibaba: <a href=https://github.com/alibaba/MNN target=_blank rel=noopener>MNN</a> <a href="https://yq.aliyun.com/articles/707014?spm=a2c4e.11153940.0.0.696d586bavHos1" target=_blank rel=noopener>blog (in Chinese)</a></li><li>Baidu: <a href=https://github.com/PaddlePaddle/models/tree/v1.4/PaddleSlim target=_blank rel=noopener>Paddle-Slim</a>, <a href=https://github.com/PaddlePaddle/paddle-mobile target=_blank rel=noopener>Paddle-Mobile</a>, <a href=https://github.com/PaddlePaddle/Anakin target=_blank rel=noopener>Anakin</a></li><li>Microsoft: <a href=https://microsoft.github.io/ELL/ target=_blank rel=noopener>ELL</a>, AutoML tool <a href=https://github.com/microsoft/nni target=_blank rel=noopener>NNI</a></li><li>Facebook: <a href=https://caffe2.ai/ target=_blank rel=noopener>Caffe2/PyTorch</a></li><li>Apple: <a href=https://developer.apple.com/documentation/coreml target=_blank rel=noopener>CoreML</a> (iOS 11+)</li><li>Google: <a href=https://developers.google.cn/ml-kit/ target=_blank rel=noopener>ML-Kit</a>, <a href=https://developer.android.google.cn/ndk/guides/neuralnetworks/index.html target=_blank rel=noopener>NNAPI</a> (Android 8.1+), <a href=https://tensorflow.google.cn/lite target=_blank rel=noopener>TF-Lite</a></li><li>Qualcomm: <a href=https://developer.qualcomm.com/software/adreno-gpu-sdk/gpu target=_blank rel=noopener>Snapdragon Neural Processing Engine (SNPE)</a>, <a href=https://developer.qualcomm.com/software/adreno-gpu-sdk/gpu target=_blank rel=noopener>Adreno GPU SDK</a></li><li>Huawei: <a href=https://developer.huawei.com/consumer/cn/hiai target=_blank rel=noopener>HiAI</a></li><li>ARM: <a href=https://github.com/OAID/Tengine/ target=_blank rel=noopener>Tengine</a></li><li>Related: <a href=https://dawn.cs.stanford.edu//benchmark/index.html target=_blank rel=noopener>DAWNBench: An End-to-End Deep Learning Benchmark and Competition</a></li></ul><h2 id=related-repos-and-websites>Related Repos and Websites</h2><ul><li><a href=https://github.com/D-X-Y/Awesome-NAS target=_blank rel=noopener>Awesome-NAS</a></li><li><a href=https://github.com/he-y/Awesome-Pruning target=_blank rel=noopener>Awesome-Pruning</a></li><li><a href=https://github.com/FLHonker/Awesome-Knowledge-Distillation target=_blank rel=noopener>Awesome-Knowledge-Distillation</a></li><li><a href=https://github.com/microsoft/AI-System/tree/main/Lectures target=_blank rel=noopener>MS AI-System open course</a></li><li><a href=https://github.com/BUG1989/caffe-int8-convert-tools target=_blank rel=noopener>caffe-int8-convert-tools</a></li><li><a href=https://github.com/fengbintu/Neural-Networks-on-Silicon target=_blank rel=noopener>Neural-Networks-on-Silicon</a></li><li><a href=https://github.com/ZhishengWang/Embedded-Neural-Network target=_blank rel=noopener>Embedded-Neural-Network</a></li><li><a href=https://github.com/j-marple-dev/model_compression target=_blank rel=noopener>model_compression</a></li><li><a href=https://github.com/666DZY666/model-compression target=_blank rel=noopener>model-compression</a> (in Chinese)</li><li><a href=https://github.com/xiaoyufenfei/Efficient-Segmentation-Networks target=_blank rel=noopener>Efficient-Segmentation-Networks</a></li><li><a href=https://www.automl.org/automl/literature-on-neural-architecture-search/ target=_blank rel=noopener>AutoML NAS Literature</a></li><li><a href=https://paperswithcode.com/task/network-pruning target=_blank rel=noopener>Papers with code</a></li><li><a href=https://paperswithcode.com/sota/image-classification-on-imagenet target=_blank rel=noopener>ImageNet Benckmark</a></li><li><a href=https://paperswithcode.com/sota/self-supervised-image-classification-on target=_blank rel=noopener>Self-supervised ImageNet Benckmark</a></li><li><a href=https://developer.nvidia.com/blog/tag/sparsity/ target=_blank rel=noopener>NVIDIA Blog with Sparsity Tag</a></li></ul></article></div><div class="card card-body mb-3 shadow-sm border-0 markdown"><blockquote class=mb-0>本站内容采用 CC BY-NC-SA 4.0 许可，请注明出处；商业转载请联系作者授权。</blockquote></div><div class="card card-body shadow-sm border-0"><script async crossorigin=anonymous src=https://giscus.app/client.js data-repo=villsi/villsi.github.io data-repo-id=R_kgDOLG5awg data-category=Announcements data-category-id=DIC_kwDOLG5aws4CcvEE data-mapping=title data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy></script></div></div></div><div class="col-xl-2 col-lg-0 col-md-0 px-0 d-none d-xl-block"><aside class="sticky-top fix-sidebar-top"><section class="d-none d-sm-block"><div class="card shadow-sm border-0 mb-3"><div class="card-header bg-white d-flex justify-content-center border-light-subtle"><span class="text-uppercase fw-medium">This Page</span></div><div class="card-body small"><nav id=TableOfContents><ul><li><a href=#surveys>Surveys</a></li><li><a href=#papers-pruning-and-quantization>Papers [Pruning and Quantization]</a><ul><li></li><li><a href=#papers-actual-acceleration-via-sparsity>Papers [Actual Acceleration via Sparsity]</a></li><li><a href=#papers-lottery-ticket-hypothesis-lth>Papers [Lottery Ticket Hypothesis (LTH)]</a></li><li><a href=#papers-bayesian-compression>Papers [Bayesian Compression]</a></li></ul></li><li><a href=#papers-knowledge-distillation-kd>Papers [Knowledge Distillation (KD)]</a><ul><li></li></ul></li><li><a href=#papers-automl-nas-etc>Papers [AutoML (NAS etc.)]</a></li><li><a href=#papers-interpretability>Papers [Interpretability]</a></li><li><a href=#workshops>Workshops</a></li><li><a href=#books--courses>Books & Courses</a></li><li><a href=#lightweight-dnn-enginesapis>Lightweight DNN Engines/APIs</a></li><li><a href=#related-repos-and-websites>Related Repos and Websites</a></li></ul></nav></div></div><script src=https://cdn.jsdelivr.net/npm/gumshoejs@5.1.2/dist/gumshoe.min.js></script><script>var header=document.querySelector("#my-header"),spy=new Gumshoe("#TableOfContents a",{reflow:!0,nested:!0,nestedClass:"active",offset:function(){return header.getBoundingClientRect().height}})</script></section><section class="d-none d-sm-block"></section></aside></div></div></div></main><footer class="footer pt-3"><nav class="navbar navbar-expand-lg navbar-dark bg-dark"><div class="container fw-light small"><div class=navbar-text>Copyright &copy; 2018 - 2024
<a class="text-reset text-decoration-none" href=https://villsi.net target=_blank rel=noopener>上海红茶馆
</a>|
<a class="text-reset text-decoration-none" href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank rel=noopener>CC BY-NC-SA 4.0</a></div><div class="navbar-text ms-auto"><a class="text-reset text-decoration-none" href=https://github.com/villsi/ target=_blank rel=noopener>Power by Cloudflare Page</a></div></div></nav><button button type=button class="btn btn-dark btn-sm scrollupBtn" title=返回顶部>
<i class="bi bi-chevron-up"></i></button></footer></body></html>